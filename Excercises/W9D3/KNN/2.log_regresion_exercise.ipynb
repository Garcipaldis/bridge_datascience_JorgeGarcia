{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "674dfd6ded4398e0679ff4f65e9a10a54ff0d14801bec0126172cfc3973d1cf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "(X_train=80%)\n",
    "(X_test=20%)\n",
    "\n",
    "A partir del archivo \"iris.csv\" que se corresponde con datos relacionados con tres tipos de plantas (el target es el tipo de planta):\n",
    "\n",
    "- Mediante regresión logística, predice qué planta se corresponde con los ejemplos: [[15.7,2.8,9.5,0.1]] y [[1.7,3.8,4.5,11.3]]\n",
    "- ¿Qué acierto tiene tu modelo? (score)\n",
    "- Utiliza un conjunto de test con el 40% de los datos: ¿cambian los resultados anteriores? ¿por qué?\n",
    "- Elimina la clase \"Virginica\" de tus datos. Repite el proceso anterior, ¿cambian los resultados?\n",
    "- ¿Consideras la regresión logística un buen algoritmo para estos datos? ¿por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal.length</th>\n      <th>sepal.width</th>\n      <th>petal.length</th>\n      <th>petal.width</th>\n      <th>variety</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('iris.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "source": [
    "### Parte I y II"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.loc[:, :'petal.width'])\n",
    "y = np.array(df['variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "logReg = LogisticRegression(max_iter=1000)\n",
    "logReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = np.array([15.7,2.8,9.5,0.1])\n",
    "var2 = np.array([1.7,3.8,4.5,11.3])\n",
    "variables = [var1, var2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction 1: Virginica\nPrediction 1: Virginica\n---------------------\nTrain Score: 0.975\nTest Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Prediction 1:', logReg.predict([var1])[0])\n",
    "print('Prediction 1:', logReg.predict([var2])[0])\n",
    "print('---------------------')\n",
    "print('Train Score:', logReg.score(X_train, y_train))\n",
    "print('Test Score:', logReg.score(X_test, y_test))"
   ]
  },
  {
   "source": [
    "### Parte III"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = model_selection.train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "logReg2 = LogisticRegression(max_iter=1000)\n",
    "logReg2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction 1: Virginica\nPrediction 1: Virginica\n---------------------\nTrain Score: 0.9555555555555556\nTest Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Prediction 1:', logReg2.predict([var1])[0])\n",
    "print('Prediction 1:', logReg2.predict([var2])[0])\n",
    "print('---------------------')\n",
    "print('Train Score:', logReg2.score(X_train2, y_train2))\n",
    "print('Test Score:', logReg2.score(X_test2, y_test2))"
   ]
  },
  {
   "source": [
    "Ligera pérdida de precisión en el conjunto de entrenamiento al tener menos datos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Parte IV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df.variety != 'Virginica']\n",
    "Xf = np.array(filtered_df.loc[:, :'petal.width'])\n",
    "yf = np.array(filtered_df.variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train, Xf_test, yf_train, yf_test = model_selection.train_test_split(Xf, yf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "logReg_F = LogisticRegression(max_iter=1000)\n",
    "logReg_F.fit(Xf_train, yf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction 1: Versicolor\nPrediction 1: Versicolor\n---------------------\nTrain Score: 1.0\nTest Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Prediction 1:', logReg_F.predict([var1])[0])\n",
    "print('Prediction 1:', logReg_F.predict([var2])[0])\n",
    "print('---------------------')\n",
    "print('Train Score:', logReg_F.score(Xf_train, yf_train))\n",
    "print('Test Score:', logReg_F.score(Xf_test, yf_test))"
   ]
  },
  {
   "source": [
    "Los resultados han pasado a tener una precisión del 100% eliminando \"Virginica\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Parte V\n",
    "Considero la Regresión Logística como un buen algoritmo para este conjunto de datos dada la precisión obtenida."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}