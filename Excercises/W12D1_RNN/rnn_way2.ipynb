{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "674dfd6ded4398e0679ff4f65e9a10a54ff0d14801bec0126172cfc3973d1cf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1\n",
    "\n",
    "#### En el ejemplo de teoría hemos visto la forma de entrenar utilizando un trozo de datos como en la imagen \"way1.png\". \n",
    "\n",
    "(Básicamente, tener en cuenta más datos de entrenamiento [[20% de test]])\n",
    "\n",
    "Investiga la forma de realizar el ejercicio a partir del gif \"way3_sliding_window.gif\":\n",
    "\n",
    "- ¿Da mejores resultados entrenar el modelo así?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Algo muy típico en el trabajo de data scientist\n",
    "\n",
    "![](../rnn/sliding_windows_google.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Data\n",
       "0 -0.144808\n",
       "1  1.169739\n",
       "2 -0.282285\n",
       "3  0.415015\n",
       "4 -0.818219"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.144808</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.169739</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.282285</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.415015</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.818219</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Total time points\n",
    "N = 3000\n",
    "# Time point to partition train/test splits\n",
    "Tp = 750   \n",
    "\n",
    "t=np.arange(0,N)\n",
    "x=(2*np.sin(0.02*t)*np.sin(0.003*t))+0.5*np.random.normal(size=N)\n",
    "df = pd.DataFrame(x, columns=['Data'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 500\n",
    "\n",
    "def moving_window(df, window_length):\n",
    "    # Retorna una lista de arrays de longitud variable.\n",
    "    window_list = []\n",
    "    for i in range(0, len(df)+1-window_length, window_length):\n",
    "        window_list.append(np.array(df.values[:i+window_length]))\n",
    "    return window_list\n",
    "\n",
    "def window_split(data, train_size=0.8):\n",
    "    # Divide cada array de la lista en una lista de tuplas con array de train y array de test.\n",
    "    train_test_tuple_list = []\n",
    "\n",
    "    for array in data:\n",
    "        Tp = round(len(array)*train_size)\n",
    "        train = array[:Tp, :]\n",
    "        test = array[Tp:len(array), :]\n",
    "        train_test_tuple_list.append((train, test))\n",
    "\n",
    "    return train_test_tuple_list\n",
    "\n",
    "def add_step(train_test_tuple_list, step=4):\n",
    "    # Añade los elementos extra del step a cada conjunto de arrays de la lista\n",
    "    added_step = []\n",
    "\n",
    "    for train, test in train_test_tuple_list:\n",
    "        test = np.append(test,np.repeat(test[-1,],step))\n",
    "        train = np.append(train,np.repeat(train[-1,],step))\n",
    "        added_step.append((train, test))\n",
    "\n",
    "    return added_step\n",
    "\n",
    "def convertToMatrix(data, step):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data)-step):\n",
    "        d=i+step  \n",
    "        X.append(data[i:d,])\n",
    "        Y.append(data[d,])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def convertToWindowMatrix(train_test_tuple_list, step=4):\n",
    "    # Retorna 4 listas de arrays.\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(data)):\n",
    "        tra_x, tra_y = convertToMatrix(train_test_tuple_list[i][0], step)\n",
    "        trainX.append(tra_x)\n",
    "        trainY.append(tra_y)\n",
    "        tes_x, tes_y = convertToMatrix(train_test_tuple_list[i][1], step)\n",
    "        testX.append(tes_x)\n",
    "        testY.append(tes_y)\n",
    "\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def add_dimension(arrays):\n",
    "    for i in range(len(arrays)):\n",
    "        arrays[i] = np.reshape(arrays[i], (arrays[i].shape[0], 1, arrays[i].shape[1]))\n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, window_length=500, train_size=0.8, step=4):\n",
    "\n",
    "    # lista de arrays de longitud variable. Se crean las ventanas\n",
    "    data = moving_window(df, window_length)\n",
    "\n",
    "    # Divide cada array de la lista en una lista de tuplas con array de train y array de test.\n",
    "    train_test_tuple_list = window_split(data)\n",
    "\n",
    "    # Añade los elementos extra del step a cada conjunto de arrays de la lista.\n",
    "    train_test_tuple_list = add_step(train_test_tuple_list, step=step)\n",
    "    \n",
    "    # Se crean los 4 conjuntos de arrays.\n",
    "    trainX, trainY, testX, testY = convertToWindowMatrix(train_test_tuple_list, step=step)\n",
    "\n",
    "    # Se redimensionan los arrays X.\n",
    "    trainX = add_dimension(trainX)\n",
    "    testX = add_dimension(testX)\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "\n",
    "def build_simple_rnn(num_units=128, embedding=4, num_dense=32,lr=0.001):\n",
    "    \"\"\"\n",
    "    Builds and compiles a simple RNN model\n",
    "    Arguments:\n",
    "              num_units: Number of units of a the simple RNN layer\n",
    "              embedding: Embedding length\n",
    "              num_dense: Number of neurons in the dense layer followed by the RNN layer\n",
    "              lr: Learning rate (uses RMSprop optimizer)\n",
    "    Returns:\n",
    "              A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # Long short term memory\n",
    "    model.add(LSTM(units=num_units, input_shape=(1,embedding), activation=\"relu\"))\n",
    "    model.add(Dense(num_dense, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=RMSprop(learning_rate=lr),metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_simple_rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch+1) % 50 == 0 and epoch>0:\n",
    "            print(\"Epoch number {} done\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting for Window: 0\n",
      "Epoch number 50 done\n",
      "Epoch number 100 done\n",
      "Epoch number 150 done\n",
      "Epoch number 200 done\n",
      "Epoch number 250 done\n",
      "Epoch number 300 done\n",
      "Epoch number 350 done\n",
      "Epoch number 400 done\n",
      "Epoch number 450 done\n",
      "Epoch number 500 done\n",
      "Epoch number 550 done\n",
      "Epoch number 600 done\n",
      "Epoch number 650 done\n",
      "Epoch number 700 done\n",
      "Epoch number 750 done\n",
      "Epoch number 800 done\n",
      "Epoch number 850 done\n",
      "Epoch number 900 done\n",
      "Epoch number 950 done\n",
      "Epoch number 1000 done\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5806 - mse: 0.5806\n",
      "Score: [0.5805737376213074, 0.5805737376213074]\n",
      "Fitting for Window: 1\n",
      "Epoch number 50 done\n",
      "Epoch number 100 done\n",
      "Epoch number 150 done\n",
      "Epoch number 200 done\n",
      "Epoch number 250 done\n",
      "Epoch number 300 done\n",
      "Epoch number 350 done\n",
      "Epoch number 400 done\n",
      "Epoch number 450 done\n",
      "Epoch number 500 done\n",
      "Epoch number 550 done\n",
      "Epoch number 600 done\n",
      "Epoch number 650 done\n",
      "Epoch number 700 done\n",
      "Epoch number 750 done\n",
      "Epoch number 800 done\n",
      "Epoch number 850 done\n",
      "Epoch number 900 done\n",
      "Epoch number 950 done\n",
      "Epoch number 1000 done\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9160 - mse: 0.9160\n",
      "Score: [0.9160163998603821, 0.9160163998603821]\n",
      "Fitting for Window: 2\n",
      "Epoch number 50 done\n",
      "Epoch number 100 done\n",
      "Epoch number 150 done\n",
      "Epoch number 200 done\n",
      "Epoch number 250 done\n",
      "Epoch number 300 done\n",
      "Epoch number 350 done\n",
      "Epoch number 400 done\n",
      "Epoch number 450 done\n",
      "Epoch number 500 done\n",
      "Epoch number 550 done\n",
      "Epoch number 600 done\n",
      "Epoch number 650 done\n",
      "Epoch number 700 done\n",
      "Epoch number 750 done\n",
      "Epoch number 800 done\n",
      "Epoch number 850 done\n",
      "Epoch number 900 done\n",
      "Epoch number 950 done\n",
      "Epoch number 1000 done\n",
      "10/10 [==============================] - 0s 888us/step - loss: 0.6607 - mse: 0.6607\n",
      "Score: [0.660723865032196, 0.660723865032196]\n",
      "Fitting for Window: 3\n",
      "Epoch number 50 done\n",
      "Epoch number 100 done\n",
      "Epoch number 150 done\n",
      "Epoch number 200 done\n",
      "Epoch number 250 done\n",
      "Epoch number 300 done\n",
      "Epoch number 350 done\n",
      "Epoch number 400 done\n",
      "Epoch number 450 done\n",
      "Epoch number 500 done\n",
      "Epoch number 550 done\n",
      "Epoch number 600 done\n",
      "Epoch number 650 done\n",
      "Epoch number 700 done\n",
      "Epoch number 750 done\n",
      "Epoch number 800 done\n",
      "Epoch number 850 done\n",
      "Epoch number 900 done\n",
      "Epoch number 950 done\n",
      "Epoch number 1000 done\n",
      "13/13 [==============================] - 0s 831us/step - loss: 0.9334 - mse: 0.9334\n",
      "Score: [0.9333981871604919, 0.9333981871604919]\n",
      "Fitting for Window: 4\n",
      "Epoch number 50 done\n",
      "Epoch number 100 done\n",
      "Epoch number 150 done\n",
      "Epoch number 200 done\n",
      "Epoch number 250 done\n",
      "Epoch number 300 done\n",
      "Epoch number 350 done\n",
      "Epoch number 400 done\n",
      "Epoch number 450 done\n",
      "Epoch number 500 done\n",
      "Epoch number 550 done\n",
      "Epoch number 600 done\n",
      "Epoch number 650 done\n",
      "Epoch number 700 done\n",
      "Epoch number 750 done\n",
      "Epoch number 800 done\n",
      "Epoch number 850 done\n",
      "Epoch number 900 done\n",
      "Epoch number 950 done\n",
      "Epoch number 1000 done\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7952 - mse: 0.7952\n",
      "Score: [0.7951686382293701, 0.7951686382293701]\n",
      "Fitting for Window: 5\n",
      "Epoch number 50 done\n",
      "Epoch number 100 done\n",
      "Epoch number 150 done\n",
      "Epoch number 200 done\n",
      "Epoch number 250 done\n",
      "Epoch number 300 done\n",
      "Epoch number 350 done\n",
      "Epoch number 400 done\n",
      "Epoch number 450 done\n",
      "Epoch number 500 done\n",
      "Epoch number 550 done\n",
      "Epoch number 600 done\n",
      "Epoch number 650 done\n",
      "Epoch number 700 done\n",
      "Epoch number 750 done\n",
      "Epoch number 800 done\n",
      "Epoch number 850 done\n",
      "Epoch number 900 done\n",
      "Epoch number 950 done\n",
      "Epoch number 1000 done\n",
      "19/19 [==============================] - 0s 776us/step - loss: 0.7561 - mse: 0.7561\n",
      "Score: [0.756119430065155, 0.756119430065155]\n"
     ]
    }
   ],
   "source": [
    "dic = {'Window':[], 'MSE_Score':[]}\n",
    "\n",
    "for i in range(len(trainX)):\n",
    "    print('Fitting for Window:', i)\n",
    "    model.fit(trainX[i],trainY[i], \n",
    "            epochs=num_epochs, \n",
    "            batch_size=batch_size, \n",
    "            callbacks=[MyCallback()],verbose=0)\n",
    "    loss, mae = model.evaluate(testX[i], testY[i])\n",
    "    print('Score:', score)\n",
    "    dic['Window'].append(i)\n",
    "    dic['MSE_Score'].append(mae)\n",
    "\n",
    "results = pd.DataFrame(dic, index=range(len(dic['Window'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'loss'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-6e8019468546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RMSE loss over epochs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epochs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"RMSE loss over epochs\",fontsize=16)\n",
    "plt.plot(np.sqrt(model.history.history['loss']),c='k',lw=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epochs\",fontsize=14)\n",
    "plt.ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Window     Score\n",
       "0       0  0.580574\n",
       "1       1  0.916016\n",
       "2       2  0.660724\n",
       "3       3  0.933398\n",
       "4       4  0.795169\n",
       "5       5  0.756119"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Window</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.580574</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.916016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.660724</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.933398</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.795169</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.756119</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}