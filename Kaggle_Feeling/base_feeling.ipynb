{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "674dfd6ded4398e0679ff4f65e9a10a54ff0d14801bec0126172cfc3973d1cf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 6176 files belonging to 2 classes.\n",
      "Using 4941 files for training.\n",
      "Found 6176 files belonging to 2 classes.\n",
      "Using 1235 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "data_dir = \"D:\\Documentos\\TheBridge\\\\bridge_datascience_JorgeGarcia\\Kaggle_Feeling\\\\train\"\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 48, 48, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "source": [
    "## 1. Primer Modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (img_height, img_height, 3),\n",
    "                  include_top=False,\n",
    "                  weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "155/155 [==============================] - 28s 179ms/step - loss: 3.3152 - acc: 0.5802 - val_loss: 0.6770 - val_acc: 0.6543\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 36s 233ms/step - loss: 0.9201 - acc: 0.6414 - val_loss: 0.6390 - val_acc: 0.6534\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 33s 215ms/step - loss: 0.6845 - acc: 0.6596 - val_loss: 0.6212 - val_acc: 0.6696\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 33s 215ms/step - loss: 0.5959 - acc: 0.6995 - val_loss: 0.6111 - val_acc: 0.6866\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 33s 211ms/step - loss: 0.5759 - acc: 0.7090 - val_loss: 0.6036 - val_acc: 0.6858\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 32s 209ms/step - loss: 0.5691 - acc: 0.7227 - val_loss: 0.5952 - val_acc: 0.6955\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 37s 237ms/step - loss: 0.5477 - acc: 0.7264 - val_loss: 0.5827 - val_acc: 0.6939\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 32s 204ms/step - loss: 0.5230 - acc: 0.7438 - val_loss: 0.5769 - val_acc: 0.7028\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 34s 220ms/step - loss: 0.5124 - acc: 0.7472 - val_loss: 0.5780 - val_acc: 0.7045\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 35s 229ms/step - loss: 0.4895 - acc: 0.7636 - val_loss: 0.5905 - val_acc: 0.7142\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_ds,\n",
    "                    validation_data = val_ds,\n",
    "                    epochs = 10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "source": [
    "## 2. Segundo Modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 46, 46, 100)       2800      \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 23, 23, 100)       0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 23, 23, 100)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 23, 23, 48)        43248     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 11, 11, 48)        0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 11, 11, 48)        0         \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 5808)              0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                185888    \n_________________________________________________________________\ndense_11 (Dense)             (None, 1)                 33        \n=================================================================\nTotal params: 231,969\nTrainable params: 231,969\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=100,\n",
    "                        kernel_size=(3, 3),\n",
    "                        input_shape=(48, 48, 3),\n",
    "                        padding='valid'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Conv2D(filters=48,\n",
    "                        kernel_size=(3, 3),\n",
    "                        padding='same'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1 , activation='sigmoid')\n",
    "])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "155/155 [==============================] - 17s 110ms/step - loss: 2.6826 - accuracy: 0.5355 - val_loss: 0.6927 - val_accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 0.6919 - accuracy: 0.5349 - val_loss: 0.6924 - val_accuracy: 0.5198\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 0.6913 - accuracy: 0.5349 - val_loss: 0.6924 - val_accuracy: 0.5198\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 18s 117ms/step - loss: 0.6910 - accuracy: 0.5349 - val_loss: 0.6925 - val_accuracy: 0.5198\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 17s 112ms/step - loss: 0.6909 - accuracy: 0.5349 - val_loss: 0.6926 - val_accuracy: 0.5190\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2518f5ec808>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "model_2.fit(train_ds, validation_data = val_ds, epochs = 5, verbose=1)"
   ]
  },
  {
   "source": [
    "## 3. Predicciones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1\n",
    "test_df = pd.read_csv('test_set.csv')\n",
    "test_df.path = test_df.path.apply(lambda x: x[5:])\n",
    "list_dir = list(test_df.path)\n",
    "\n",
    "# Parte 2\n",
    "test_dir = \"D:\\Documentos\\TheBridge\\\\bridge_datascience_JorgeGarcia\\Kaggle_Feeling\\\\test\"\n",
    "\n",
    "images = [tf.keras.preprocessing.image.load_img(test_dir + os.sep + filename, target_size=(img_height, img_width)) for filename in list_dir]\n",
    "test_ds = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in images])\n",
    "test_ds = tf.data.Dataset.from_tensors(test_ds)\n",
    "\n",
    "# Parte 3\n",
    "predictions = model.predict(test_ds)\n",
    "results = np.array([np.max(predictions[i]) for i in range(len(predictions))])\n",
    "\n",
    "id_col = test_df['id_img']\n",
    "\n",
    "submission = pd.DataFrame({'id_img':id_col, 'label':results}, index=range(len(id_col)))\n",
    "submission.label = submission.label.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "submission.label = submission.label.apply(lambda x: 'happy' if x == 0 else 'sadness')\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1\n",
    "test_df = pd.read_csv('test_set.csv')\n",
    "test_df.path = test_df.path.apply(lambda x: x[5:])\n",
    "list_dir = list(test_df.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"D:\\Documentos\\TheBridge\\\\bridge_datascience_JorgeGarcia\\Kaggle_Feeling\\\\test\"\n",
    "\n",
    "images = [tf.keras.preprocessing.image.load_img(test_dir + os.sep + filename, target_size=(img_height, img_width)) for filename in list_dir]\n",
    "test_ds = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in images])\n",
    "test_ds = tf.data.Dataset.from_tensors(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id_img    label\n",
       "0   18341    happy\n",
       "1   13176  sadness\n",
       "2   23945  sadness\n",
       "3   15968    happy\n",
       "4   18382    happy"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_img</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18341</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23945</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15968</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18382</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "predictions = model.predict(test_ds)\n",
    "results = np.array([np.max(predictions[i]) for i in range(len(predictions))])\n",
    "\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "id_col = sample['id_img']\n",
    "\n",
    "submission = pd.DataFrame({'id_img':id_col, 'label':results}, index=range(len(id_col)))\n",
    "submission.label = submission.label.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "submission.label = submission.label.apply(lambda x: 'happy' if x == 0 else 'sadness')\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['happy', 'sadness'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "submission.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_20Epochs.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('VGG16_Adamax_10Epochs.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aún no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\n",
    "    \"\"\"\n",
    "    sample = pd.read_csv(\"sample_submission.csv\")\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id_img.all() == sample.id_img.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                df_to_submit.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}