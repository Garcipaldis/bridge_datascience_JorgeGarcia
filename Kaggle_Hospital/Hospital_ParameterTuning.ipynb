{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "674dfd6ded4398e0679ff4f65e9a10a54ff0d14801bec0126172cfc3973d1cf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Base Transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hospital_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         1  2   3  4  5           6  7  8    9      10    11         12  \\\n",
       "0                                                                         \n",
       "161528   6  a   6  X  2  gynecology  R  F  4.0   45810   2.0     Urgent   \n",
       "159472  23  a   6  X  4  gynecology  Q  F  2.0  128565  15.0     Trauma   \n",
       "309765   2  c   5  Z  2  anesthesia  S  F  3.0   46565   5.0     Urgent   \n",
       "279614  32  f   9  Y  3  gynecology  S  B  4.0  124546   6.0  Emergency   \n",
       "147791  14  a   1  X  3  gynecology  S  E  2.0   22729   8.0     Urgent   \n",
       "...     .. ..  .. .. ..         ... .. ..  ...     ...   ...        ...   \n",
       "237869  12  a   9  Y  3  gynecology  R  B  3.0   82914   3.0  Emergency   \n",
       "254763  28  b  11  X  2  gynecology  R  F  2.0   40026   5.0     Urgent   \n",
       "69788    6  a   6  X  3  gynecology  Q  F  3.0   92346   2.0     Trauma   \n",
       "204442  32  f   9  Y  2  gynecology  S  B  4.0  113798  15.0     Trauma   \n",
       "69647   25  e   1  X  3  gynecology  Q  E  2.0  109237   8.0  Emergency   \n",
       "\n",
       "              13  14     15      16                  17  \n",
       "0                                                        \n",
       "161528  Moderate   2  21-30  2817.0                0-10  \n",
       "159472  Moderate   4  51-60  4498.0               21-30  \n",
       "309765  Moderate   2  71-80  4573.0               11-20  \n",
       "279614  Moderate   4  11-20  7202.0               51-60  \n",
       "147791  Moderate   2  51-60  3398.0               51-60  \n",
       "...          ...  ..    ...     ...                 ...  \n",
       "237869  Moderate   6  51-60  3966.0  More than 100 Days  \n",
       "254763  Moderate   3  21-30  4005.0               51-60  \n",
       "69788      Minor   2  31-40  5215.0               31-40  \n",
       "204442  Moderate   3  41-50  5092.0               11-20  \n",
       "69647   Moderate   2  41-50  3390.0               41-50  \n",
       "\n",
       "[100000 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n    </tr>\n    <tr>\n      <th>0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>161528</th>\n      <td>6</td>\n      <td>a</td>\n      <td>6</td>\n      <td>X</td>\n      <td>2</td>\n      <td>gynecology</td>\n      <td>R</td>\n      <td>F</td>\n      <td>4.0</td>\n      <td>45810</td>\n      <td>2.0</td>\n      <td>Urgent</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>21-30</td>\n      <td>2817.0</td>\n      <td>0-10</td>\n    </tr>\n    <tr>\n      <th>159472</th>\n      <td>23</td>\n      <td>a</td>\n      <td>6</td>\n      <td>X</td>\n      <td>4</td>\n      <td>gynecology</td>\n      <td>Q</td>\n      <td>F</td>\n      <td>2.0</td>\n      <td>128565</td>\n      <td>15.0</td>\n      <td>Trauma</td>\n      <td>Moderate</td>\n      <td>4</td>\n      <td>51-60</td>\n      <td>4498.0</td>\n      <td>21-30</td>\n    </tr>\n    <tr>\n      <th>309765</th>\n      <td>2</td>\n      <td>c</td>\n      <td>5</td>\n      <td>Z</td>\n      <td>2</td>\n      <td>anesthesia</td>\n      <td>S</td>\n      <td>F</td>\n      <td>3.0</td>\n      <td>46565</td>\n      <td>5.0</td>\n      <td>Urgent</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>71-80</td>\n      <td>4573.0</td>\n      <td>11-20</td>\n    </tr>\n    <tr>\n      <th>279614</th>\n      <td>32</td>\n      <td>f</td>\n      <td>9</td>\n      <td>Y</td>\n      <td>3</td>\n      <td>gynecology</td>\n      <td>S</td>\n      <td>B</td>\n      <td>4.0</td>\n      <td>124546</td>\n      <td>6.0</td>\n      <td>Emergency</td>\n      <td>Moderate</td>\n      <td>4</td>\n      <td>11-20</td>\n      <td>7202.0</td>\n      <td>51-60</td>\n    </tr>\n    <tr>\n      <th>147791</th>\n      <td>14</td>\n      <td>a</td>\n      <td>1</td>\n      <td>X</td>\n      <td>3</td>\n      <td>gynecology</td>\n      <td>S</td>\n      <td>E</td>\n      <td>2.0</td>\n      <td>22729</td>\n      <td>8.0</td>\n      <td>Urgent</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>51-60</td>\n      <td>3398.0</td>\n      <td>51-60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237869</th>\n      <td>12</td>\n      <td>a</td>\n      <td>9</td>\n      <td>Y</td>\n      <td>3</td>\n      <td>gynecology</td>\n      <td>R</td>\n      <td>B</td>\n      <td>3.0</td>\n      <td>82914</td>\n      <td>3.0</td>\n      <td>Emergency</td>\n      <td>Moderate</td>\n      <td>6</td>\n      <td>51-60</td>\n      <td>3966.0</td>\n      <td>More than 100 Days</td>\n    </tr>\n    <tr>\n      <th>254763</th>\n      <td>28</td>\n      <td>b</td>\n      <td>11</td>\n      <td>X</td>\n      <td>2</td>\n      <td>gynecology</td>\n      <td>R</td>\n      <td>F</td>\n      <td>2.0</td>\n      <td>40026</td>\n      <td>5.0</td>\n      <td>Urgent</td>\n      <td>Moderate</td>\n      <td>3</td>\n      <td>21-30</td>\n      <td>4005.0</td>\n      <td>51-60</td>\n    </tr>\n    <tr>\n      <th>69788</th>\n      <td>6</td>\n      <td>a</td>\n      <td>6</td>\n      <td>X</td>\n      <td>3</td>\n      <td>gynecology</td>\n      <td>Q</td>\n      <td>F</td>\n      <td>3.0</td>\n      <td>92346</td>\n      <td>2.0</td>\n      <td>Trauma</td>\n      <td>Minor</td>\n      <td>2</td>\n      <td>31-40</td>\n      <td>5215.0</td>\n      <td>31-40</td>\n    </tr>\n    <tr>\n      <th>204442</th>\n      <td>32</td>\n      <td>f</td>\n      <td>9</td>\n      <td>Y</td>\n      <td>2</td>\n      <td>gynecology</td>\n      <td>S</td>\n      <td>B</td>\n      <td>4.0</td>\n      <td>113798</td>\n      <td>15.0</td>\n      <td>Trauma</td>\n      <td>Moderate</td>\n      <td>3</td>\n      <td>41-50</td>\n      <td>5092.0</td>\n      <td>11-20</td>\n    </tr>\n    <tr>\n      <th>69647</th>\n      <td>25</td>\n      <td>e</td>\n      <td>1</td>\n      <td>X</td>\n      <td>3</td>\n      <td>gynecology</td>\n      <td>Q</td>\n      <td>E</td>\n      <td>2.0</td>\n      <td>109237</td>\n      <td>8.0</td>\n      <td>Emergency</td>\n      <td>Moderate</td>\n      <td>2</td>\n      <td>41-50</td>\n      <td>3390.0</td>\n      <td>41-50</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalEncoder:\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_admission(x):\n",
    "        data = {'Urgent': 2, 'Trauma': 1, 'Emergency': 3}\n",
    "        return data[x]\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_severity(x):\n",
    "        data = {'Moderate': 2, 'Extreme': 3, 'Minor': 1}\n",
    "        return data[x]\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_age(x):\n",
    "        data = {'21-30': 2, '51-60': 5, '71-80': 7, '11-20': 1, \n",
    "        '31-40': 3, '0-10': 0, '61-70': 6, '41-50': 4, '81-90': 4, '91-100': 9}\n",
    "        return data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos las columnas no relevantes\n",
    "filtered = df.drop(['1', '3', '4', '7', '8','9', '10', '11','14','16'], axis=1)\n",
    "\n",
    "# Quitamos las filas donde la columna 9 tiene valor nan (33 registros)\n",
    "#filtered.dropna(inplace=True)\n",
    "\n",
    "# Aplicamos los encoders\n",
    "filtered['12'] = filtered['12'].apply(HospitalEncoder.encode_admission)\n",
    "filtered['13'] = filtered['13'].apply(HospitalEncoder.encode_severity)\n",
    "filtered['15'] = filtered['15'].apply(HospitalEncoder.encode_age)\n",
    "\n",
    "# Get dummies\n",
    "features = filtered[['2', '6']]\n",
    "features = pd.get_dummies(features)\n",
    "filtered.drop(['2', '6'], axis=1, inplace=True)\n",
    "train = pd.concat([filtered, features], axis=1)\n",
    "\n",
    "# Creamos X e y\n",
    "X = np.array(train.drop(['17'], axis=1))\n",
    "y = np.array(train['17'])\n",
    "\n",
    "# Conjuntos train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "source": [
    "## 1. Gradient Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer()),\n",
    "    ('standard', StandardScaler()),\n",
    "    ('grad', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "grad_params = {\n",
    "    'grad__random_state': [42, 1, 10, 18122003],\n",
    "    'grad__loss': ['deviance', 'exponential'],\n",
    "    'grad__learning_rate': [0.1, 0.01, 0.05, 0.2],\n",
    "    'grad__n_estimators': [100, 200, 500, 1000],\n",
    "    'grad__min_samples_split': [2, 3, 5],\n",
    "    'grad__min_samples_leaf': [1, 2],\n",
    "    'grad__max_depth': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(grad,\n",
    "                    grad_params,\n",
    "                    cv=5,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer()),\n",
    "    ('grad', GradientBoostingClassifier(learning_rate=0.01, n_estimators=200, verbose=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.9029            3.92m\n",
      "         2           1.9020            3.71m\n",
      "         3           1.9011            3.56m\n",
      "         4           1.9003            3.60m\n",
      "         5           1.8995            3.44m\n",
      "         6           1.8987            3.31m\n",
      "         7           1.8979            3.24m\n",
      "         8           1.8971            3.20m\n",
      "         9           1.8964            3.25m\n",
      "        10           1.8956            3.23m\n",
      "        11           1.8949            3.21m\n",
      "        12           1.8942            3.19m\n",
      "        13           1.8935            3.17m\n",
      "        14           1.8928            3.15m\n",
      "        15           1.8922            3.13m\n",
      "        16           1.8915            3.11m\n",
      "        17           1.8909            3.10m\n",
      "        18           1.8903            3.09m\n",
      "        19           1.8897            3.07m\n",
      "        20           1.8891            3.05m\n",
      "        21           1.8885            3.03m\n",
      "        22           1.8879            3.02m\n",
      "        23           1.8873            3.00m\n",
      "        24           1.8868            2.99m\n",
      "        25           1.8862            2.97m\n",
      "        26           1.8857            2.95m\n",
      "        27           1.8851            2.94m\n",
      "        28           1.8846            2.93m\n",
      "        29           1.8841            2.91m\n",
      "        30           1.8836            2.89m\n",
      "        31           1.8831            2.88m\n",
      "        32           1.8826            2.86m\n",
      "        33           1.8821            2.84m\n",
      "        34           1.8817            2.82m\n",
      "        35           1.8812            2.81m\n",
      "        36           1.8807            2.79m\n",
      "        37           1.8803            2.77m\n",
      "        38           1.8798            2.75m\n",
      "        39           1.8794            2.73m\n",
      "        40           1.8790            2.72m\n",
      "        41           1.8785            2.70m\n",
      "        42           1.8781            2.68m\n",
      "        43           1.8777            2.66m\n",
      "        44           1.8773            2.64m\n",
      "        45           1.8769            2.63m\n",
      "        46           1.8765            2.61m\n",
      "        47           1.8761            2.59m\n",
      "        48           1.8758            2.58m\n",
      "        49           1.8754            2.56m\n",
      "        50           1.8750            2.54m\n",
      "        51           1.8747            2.52m\n",
      "        52           1.8743            2.51m\n",
      "        53           1.8740            2.49m\n",
      "        54           1.8736            2.47m\n",
      "        55           1.8733            2.46m\n",
      "        56           1.8730            2.44m\n",
      "        57           1.8726            2.42m\n",
      "        58           1.8723            2.41m\n",
      "        59           1.8720            2.39m\n",
      "        60           1.8717            2.37m\n",
      "        61           1.8714            2.35m\n",
      "        62           1.8711            2.34m\n",
      "        63           1.8708            2.32m\n",
      "        64           1.8705            2.31m\n",
      "        65           1.8702            2.29m\n",
      "        66           1.8699            2.27m\n",
      "        67           1.8697            2.26m\n",
      "        68           1.8694            2.24m\n",
      "        69           1.8691            2.22m\n",
      "        70           1.8688            2.21m\n",
      "        71           1.8685            2.19m\n",
      "        72           1.8683            2.17m\n",
      "        73           1.8680            2.16m\n",
      "        74           1.8678            2.14m\n",
      "        75           1.8675            2.12m\n",
      "        76           1.8672            2.10m\n",
      "        77           1.8670            2.09m\n",
      "        78           1.8667            2.07m\n",
      "        79           1.8665            2.05m\n",
      "        80           1.8663            2.03m\n",
      "        81           1.8660            2.02m\n",
      "        82           1.8658            2.00m\n",
      "        83           1.8656            1.98m\n",
      "        84           1.8654            1.96m\n",
      "        85           1.8651            1.95m\n",
      "        86           1.8649            1.93m\n",
      "        87           1.8647            1.91m\n",
      "        88           1.8645            1.90m\n",
      "        89           1.8643            1.88m\n",
      "        90           1.8641            1.86m\n",
      "        91           1.8639            1.84m\n",
      "        92           1.8637            1.83m\n",
      "        93           1.8635            1.81m\n",
      "        94           1.8633            1.79m\n",
      "        95           1.8631            1.78m\n",
      "        96           1.8629            1.76m\n",
      "        97           1.8627            1.74m\n",
      "        98           1.8625            1.73m\n",
      "        99           1.8623            1.71m\n",
      "       100           1.8621            1.69m\n",
      "       101           1.8620            1.67m\n",
      "       102           1.8618            1.66m\n",
      "       103           1.8616            1.64m\n",
      "       104           1.8614            1.62m\n",
      "       105           1.8613            1.61m\n",
      "       106           1.8611            1.59m\n",
      "       107           1.8609            1.57m\n",
      "       108           1.8608            1.56m\n",
      "       109           1.8606            1.54m\n",
      "       110           1.8605            1.52m\n",
      "       111           1.8603            1.51m\n",
      "       112           1.8601            1.49m\n",
      "       113           1.8600            1.48m\n",
      "       114           1.8598            1.46m\n",
      "       115           1.8597            1.44m\n",
      "       116           1.8595            1.43m\n",
      "       117           1.8594            1.41m\n",
      "       118           1.8593            1.39m\n",
      "       119           1.8591            1.38m\n",
      "       120           1.8590            1.36m\n",
      "       121           1.8588            1.34m\n",
      "       122           1.8587            1.32m\n",
      "       123           1.8586            1.31m\n",
      "       124           1.8584            1.29m\n",
      "       125           1.8583            1.27m\n",
      "       126           1.8582            1.26m\n",
      "       127           1.8580            1.24m\n",
      "       128           1.8579            1.22m\n",
      "       129           1.8578            1.21m\n",
      "       130           1.8577            1.19m\n",
      "       131           1.8575            1.17m\n",
      "       132           1.8574            1.16m\n",
      "       133           1.8573            1.14m\n",
      "       134           1.8572            1.12m\n",
      "       135           1.8571            1.10m\n",
      "       136           1.8569            1.09m\n",
      "       137           1.8568            1.07m\n",
      "       138           1.8567            1.05m\n",
      "       139           1.8566            1.04m\n",
      "       140           1.8565            1.02m\n",
      "       141           1.8564            1.00m\n",
      "       142           1.8563           59.16s\n",
      "       143           1.8562           58.15s\n",
      "       144           1.8561           57.13s\n",
      "       145           1.8559           56.12s\n",
      "       146           1.8558           55.11s\n",
      "       147           1.8557           54.09s\n",
      "       148           1.8556           53.07s\n",
      "       149           1.8555           52.05s\n",
      "       150           1.8554           51.03s\n",
      "       151           1.8553           50.01s\n",
      "       152           1.8552           48.99s\n",
      "       153           1.8551           47.98s\n",
      "       154           1.8550           46.96s\n",
      "       155           1.8549           45.95s\n",
      "       156           1.8548           44.93s\n",
      "       157           1.8547           43.90s\n",
      "       158           1.8547           42.88s\n",
      "       159           1.8546           41.87s\n",
      "       160           1.8545           40.85s\n",
      "       161           1.8544           39.83s\n",
      "       162           1.8543           38.81s\n",
      "       163           1.8542           37.79s\n",
      "       164           1.8541           36.77s\n",
      "       165           1.8540           35.75s\n",
      "       166           1.8539           34.73s\n",
      "       167           1.8539           33.71s\n",
      "       168           1.8538           32.69s\n",
      "       169           1.8537           31.67s\n",
      "       170           1.8536           30.65s\n",
      "       171           1.8535           29.62s\n",
      "       172           1.8534           28.60s\n",
      "       173           1.8534           27.59s\n",
      "       174           1.8533           26.57s\n",
      "       175           1.8532           25.55s\n",
      "       176           1.8531           24.53s\n",
      "       177           1.8530           23.51s\n",
      "       178           1.8530           22.50s\n",
      "       179           1.8529           21.48s\n",
      "       180           1.8528           20.46s\n",
      "       181           1.8527           19.44s\n",
      "       182           1.8526           18.42s\n",
      "       183           1.8526           17.40s\n",
      "       184           1.8525           16.38s\n",
      "       185           1.8524           15.35s\n",
      "       186           1.8523           14.33s\n",
      "       187           1.8523           13.31s\n",
      "       188           1.8522           12.29s\n",
      "       189           1.8521           11.27s\n",
      "       190           1.8520           10.25s\n",
      "       191           1.8520            9.22s\n",
      "       192           1.8519            8.20s\n",
      "       193           1.8518            7.18s\n",
      "       194           1.8518            6.15s\n",
      "       195           1.8517            5.13s\n",
      "       196           1.8516            4.10s\n",
      "       197           1.8515            3.08s\n",
      "       198           1.8515            2.05s\n",
      "       199           1.8514            1.03s\n",
      "       200           1.8513            0.00s\n",
      "Test: 0.30735\n",
      "Train: 0.302775\n"
     ]
    }
   ],
   "source": [
    "grad.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grad.predict(X_test)\n",
    "print('Test:', accuracy_score(y_test, y_pred))\n",
    "y_pred_train = grad.predict(X_train)\n",
    "print('Train:', accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test: 0.30735\nTrain: 0.302775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Test:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('Train:', accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'hospital_grad_final.model'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(grad, archivo_salida)"
   ]
  },
  {
   "source": [
    "## 2. Cat Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildcat = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer()),\n",
    "    ('grad', CatBoostClassifier(depth=6, learning_rate=0.1, l2_leaf_reg=5, iterations=1200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "l: 44.7s\tremaining: 21s\n",
      "817:\tlearn: 1.7291348\ttotal: 44.8s\tremaining: 20.9s\n",
      "818:\tlearn: 1.7290584\ttotal: 44.8s\tremaining: 20.9s\n",
      "819:\tlearn: 1.7289881\ttotal: 44.9s\tremaining: 20.8s\n",
      "820:\tlearn: 1.7289280\ttotal: 44.9s\tremaining: 20.7s\n",
      "821:\tlearn: 1.7288317\ttotal: 45s\tremaining: 20.7s\n",
      "822:\tlearn: 1.7287742\ttotal: 45.1s\tremaining: 20.6s\n",
      "823:\tlearn: 1.7286936\ttotal: 45.1s\tremaining: 20.6s\n",
      "824:\tlearn: 1.7286019\ttotal: 45.2s\tremaining: 20.5s\n",
      "825:\tlearn: 1.7285196\ttotal: 45.2s\tremaining: 20.5s\n",
      "826:\tlearn: 1.7284575\ttotal: 45.3s\tremaining: 20.4s\n",
      "827:\tlearn: 1.7283746\ttotal: 45.4s\tremaining: 20.4s\n",
      "828:\tlearn: 1.7283021\ttotal: 45.4s\tremaining: 20.3s\n",
      "829:\tlearn: 1.7282188\ttotal: 45.5s\tremaining: 20.3s\n",
      "830:\tlearn: 1.7281640\ttotal: 45.5s\tremaining: 20.2s\n",
      "831:\tlearn: 1.7280733\ttotal: 45.6s\tremaining: 20.2s\n",
      "832:\tlearn: 1.7279583\ttotal: 45.6s\tremaining: 20.1s\n",
      "833:\tlearn: 1.7278547\ttotal: 45.7s\tremaining: 20.1s\n",
      "834:\tlearn: 1.7277705\ttotal: 45.8s\tremaining: 20s\n",
      "835:\tlearn: 1.7276851\ttotal: 45.8s\tremaining: 19.9s\n",
      "836:\tlearn: 1.7275815\ttotal: 45.9s\tremaining: 19.9s\n",
      "837:\tlearn: 1.7274873\ttotal: 45.9s\tremaining: 19.8s\n",
      "838:\tlearn: 1.7273559\ttotal: 46s\tremaining: 19.8s\n",
      "839:\tlearn: 1.7272660\ttotal: 46.1s\tremaining: 19.7s\n",
      "840:\tlearn: 1.7272140\ttotal: 46.1s\tremaining: 19.7s\n",
      "841:\tlearn: 1.7271330\ttotal: 46.2s\tremaining: 19.6s\n",
      "842:\tlearn: 1.7271033\ttotal: 46.2s\tremaining: 19.6s\n",
      "843:\tlearn: 1.7270310\ttotal: 46.3s\tremaining: 19.5s\n",
      "844:\tlearn: 1.7269776\ttotal: 46.4s\tremaining: 19.5s\n",
      "845:\tlearn: 1.7269194\ttotal: 46.4s\tremaining: 19.4s\n",
      "846:\tlearn: 1.7268354\ttotal: 46.5s\tremaining: 19.4s\n",
      "847:\tlearn: 1.7266822\ttotal: 46.5s\tremaining: 19.3s\n",
      "848:\tlearn: 1.7266109\ttotal: 46.6s\tremaining: 19.3s\n",
      "849:\tlearn: 1.7265313\ttotal: 46.7s\tremaining: 19.2s\n",
      "850:\tlearn: 1.7264516\ttotal: 46.7s\tremaining: 19.2s\n",
      "851:\tlearn: 1.7263893\ttotal: 46.8s\tremaining: 19.1s\n",
      "852:\tlearn: 1.7263264\ttotal: 46.8s\tremaining: 19.1s\n",
      "853:\tlearn: 1.7262320\ttotal: 46.9s\tremaining: 19s\n",
      "854:\tlearn: 1.7261433\ttotal: 47s\tremaining: 18.9s\n",
      "855:\tlearn: 1.7260323\ttotal: 47s\tremaining: 18.9s\n",
      "856:\tlearn: 1.7259375\ttotal: 47.1s\tremaining: 18.8s\n",
      "857:\tlearn: 1.7258502\ttotal: 47.1s\tremaining: 18.8s\n",
      "858:\tlearn: 1.7257846\ttotal: 47.2s\tremaining: 18.7s\n",
      "859:\tlearn: 1.7257320\ttotal: 47.2s\tremaining: 18.7s\n",
      "860:\tlearn: 1.7256840\ttotal: 47.3s\tremaining: 18.6s\n",
      "861:\tlearn: 1.7256315\ttotal: 47.4s\tremaining: 18.6s\n",
      "862:\tlearn: 1.7255382\ttotal: 47.4s\tremaining: 18.5s\n",
      "863:\tlearn: 1.7254572\ttotal: 47.5s\tremaining: 18.5s\n",
      "864:\tlearn: 1.7253875\ttotal: 47.5s\tremaining: 18.4s\n",
      "865:\tlearn: 1.7252963\ttotal: 47.6s\tremaining: 18.4s\n",
      "866:\tlearn: 1.7252345\ttotal: 47.7s\tremaining: 18.3s\n",
      "867:\tlearn: 1.7251502\ttotal: 47.7s\tremaining: 18.3s\n",
      "868:\tlearn: 1.7250493\ttotal: 47.8s\tremaining: 18.2s\n",
      "869:\tlearn: 1.7250014\ttotal: 47.8s\tremaining: 18.1s\n",
      "870:\tlearn: 1.7249044\ttotal: 47.9s\tremaining: 18.1s\n",
      "871:\tlearn: 1.7248355\ttotal: 48s\tremaining: 18s\n",
      "872:\tlearn: 1.7247419\ttotal: 48s\tremaining: 18s\n",
      "873:\tlearn: 1.7246293\ttotal: 48.1s\tremaining: 17.9s\n",
      "874:\tlearn: 1.7245665\ttotal: 48.1s\tremaining: 17.9s\n",
      "875:\tlearn: 1.7245011\ttotal: 48.2s\tremaining: 17.8s\n",
      "876:\tlearn: 1.7244674\ttotal: 48.2s\tremaining: 17.8s\n",
      "877:\tlearn: 1.7243564\ttotal: 48.3s\tremaining: 17.7s\n",
      "878:\tlearn: 1.7243063\ttotal: 48.4s\tremaining: 17.7s\n",
      "879:\tlearn: 1.7242424\ttotal: 48.4s\tremaining: 17.6s\n",
      "880:\tlearn: 1.7241756\ttotal: 48.5s\tremaining: 17.6s\n",
      "881:\tlearn: 1.7241073\ttotal: 48.5s\tremaining: 17.5s\n",
      "882:\tlearn: 1.7240226\ttotal: 48.6s\tremaining: 17.4s\n",
      "883:\tlearn: 1.7239590\ttotal: 48.7s\tremaining: 17.4s\n",
      "884:\tlearn: 1.7238781\ttotal: 48.7s\tremaining: 17.3s\n",
      "885:\tlearn: 1.7238121\ttotal: 48.8s\tremaining: 17.3s\n",
      "886:\tlearn: 1.7237313\ttotal: 48.8s\tremaining: 17.2s\n",
      "887:\tlearn: 1.7236719\ttotal: 48.9s\tremaining: 17.2s\n",
      "888:\tlearn: 1.7235870\ttotal: 48.9s\tremaining: 17.1s\n",
      "889:\tlearn: 1.7235163\ttotal: 49s\tremaining: 17.1s\n",
      "890:\tlearn: 1.7234357\ttotal: 49.1s\tremaining: 17s\n",
      "891:\tlearn: 1.7233794\ttotal: 49.1s\tremaining: 17s\n",
      "892:\tlearn: 1.7233115\ttotal: 49.2s\tremaining: 16.9s\n",
      "893:\tlearn: 1.7232249\ttotal: 49.2s\tremaining: 16.9s\n",
      "894:\tlearn: 1.7231485\ttotal: 49.3s\tremaining: 16.8s\n",
      "895:\tlearn: 1.7230707\ttotal: 49.4s\tremaining: 16.7s\n",
      "896:\tlearn: 1.7229850\ttotal: 49.4s\tremaining: 16.7s\n",
      "897:\tlearn: 1.7228900\ttotal: 49.5s\tremaining: 16.6s\n",
      "898:\tlearn: 1.7227879\ttotal: 49.5s\tremaining: 16.6s\n",
      "899:\tlearn: 1.7226675\ttotal: 49.6s\tremaining: 16.5s\n",
      "900:\tlearn: 1.7226212\ttotal: 49.6s\tremaining: 16.5s\n",
      "901:\tlearn: 1.7225713\ttotal: 49.7s\tremaining: 16.4s\n",
      "902:\tlearn: 1.7225050\ttotal: 49.8s\tremaining: 16.4s\n",
      "903:\tlearn: 1.7224370\ttotal: 49.8s\tremaining: 16.3s\n",
      "904:\tlearn: 1.7223881\ttotal: 49.9s\tremaining: 16.3s\n",
      "905:\tlearn: 1.7223244\ttotal: 49.9s\tremaining: 16.2s\n",
      "906:\tlearn: 1.7222043\ttotal: 50s\tremaining: 16.2s\n",
      "907:\tlearn: 1.7221384\ttotal: 50.1s\tremaining: 16.1s\n",
      "908:\tlearn: 1.7220677\ttotal: 50.1s\tremaining: 16s\n",
      "909:\tlearn: 1.7220030\ttotal: 50.2s\tremaining: 16s\n",
      "910:\tlearn: 1.7219552\ttotal: 50.2s\tremaining: 15.9s\n",
      "911:\tlearn: 1.7218739\ttotal: 50.3s\tremaining: 15.9s\n",
      "912:\tlearn: 1.7218247\ttotal: 50.3s\tremaining: 15.8s\n",
      "913:\tlearn: 1.7217312\ttotal: 50.4s\tremaining: 15.8s\n",
      "914:\tlearn: 1.7216498\ttotal: 50.5s\tremaining: 15.7s\n",
      "915:\tlearn: 1.7215393\ttotal: 50.5s\tremaining: 15.7s\n",
      "916:\tlearn: 1.7215046\ttotal: 50.6s\tremaining: 15.6s\n",
      "917:\tlearn: 1.7214580\ttotal: 50.6s\tremaining: 15.6s\n",
      "918:\tlearn: 1.7214387\ttotal: 50.7s\tremaining: 15.5s\n",
      "919:\tlearn: 1.7213451\ttotal: 50.8s\tremaining: 15.4s\n",
      "920:\tlearn: 1.7212791\ttotal: 50.8s\tremaining: 15.4s\n",
      "921:\tlearn: 1.7212143\ttotal: 50.9s\tremaining: 15.3s\n",
      "922:\tlearn: 1.7211231\ttotal: 50.9s\tremaining: 15.3s\n",
      "923:\tlearn: 1.7210209\ttotal: 51s\tremaining: 15.2s\n",
      "924:\tlearn: 1.7209699\ttotal: 51.1s\tremaining: 15.2s\n",
      "925:\tlearn: 1.7208792\ttotal: 51.1s\tremaining: 15.1s\n",
      "926:\tlearn: 1.7208175\ttotal: 51.2s\tremaining: 15.1s\n",
      "927:\tlearn: 1.7207413\ttotal: 51.2s\tremaining: 15s\n",
      "928:\tlearn: 1.7206728\ttotal: 51.3s\tremaining: 15s\n",
      "929:\tlearn: 1.7206013\ttotal: 51.4s\tremaining: 14.9s\n",
      "930:\tlearn: 1.7205357\ttotal: 51.4s\tremaining: 14.9s\n",
      "931:\tlearn: 1.7204407\ttotal: 51.5s\tremaining: 14.8s\n",
      "932:\tlearn: 1.7203978\ttotal: 51.5s\tremaining: 14.7s\n",
      "933:\tlearn: 1.7202886\ttotal: 51.6s\tremaining: 14.7s\n",
      "934:\tlearn: 1.7202520\ttotal: 51.7s\tremaining: 14.6s\n",
      "935:\tlearn: 1.7202305\ttotal: 51.7s\tremaining: 14.6s\n",
      "936:\tlearn: 1.7201805\ttotal: 51.8s\tremaining: 14.5s\n",
      "937:\tlearn: 1.7201309\ttotal: 51.8s\tremaining: 14.5s\n",
      "938:\tlearn: 1.7200684\ttotal: 51.9s\tremaining: 14.4s\n",
      "939:\tlearn: 1.7200070\ttotal: 51.9s\tremaining: 14.4s\n",
      "940:\tlearn: 1.7199636\ttotal: 52s\tremaining: 14.3s\n",
      "941:\tlearn: 1.7198966\ttotal: 52.1s\tremaining: 14.3s\n",
      "942:\tlearn: 1.7198355\ttotal: 52.1s\tremaining: 14.2s\n",
      "943:\tlearn: 1.7197721\ttotal: 52.2s\tremaining: 14.2s\n",
      "944:\tlearn: 1.7197036\ttotal: 52.2s\tremaining: 14.1s\n",
      "945:\tlearn: 1.7196550\ttotal: 52.3s\tremaining: 14s\n",
      "946:\tlearn: 1.7195827\ttotal: 52.4s\tremaining: 14s\n",
      "947:\tlearn: 1.7195060\ttotal: 52.4s\tremaining: 13.9s\n",
      "948:\tlearn: 1.7193695\ttotal: 52.5s\tremaining: 13.9s\n",
      "949:\tlearn: 1.7193202\ttotal: 52.5s\tremaining: 13.8s\n",
      "950:\tlearn: 1.7192758\ttotal: 52.6s\tremaining: 13.8s\n",
      "951:\tlearn: 1.7192321\ttotal: 52.7s\tremaining: 13.7s\n",
      "952:\tlearn: 1.7191448\ttotal: 52.7s\tremaining: 13.7s\n",
      "953:\tlearn: 1.7190892\ttotal: 52.8s\tremaining: 13.6s\n",
      "954:\tlearn: 1.7190075\ttotal: 52.8s\tremaining: 13.6s\n",
      "955:\tlearn: 1.7189188\ttotal: 52.9s\tremaining: 13.5s\n",
      "956:\tlearn: 1.7188373\ttotal: 53s\tremaining: 13.4s\n",
      "957:\tlearn: 1.7187787\ttotal: 53s\tremaining: 13.4s\n",
      "958:\tlearn: 1.7187041\ttotal: 53.1s\tremaining: 13.3s\n",
      "959:\tlearn: 1.7186556\ttotal: 53.1s\tremaining: 13.3s\n",
      "960:\tlearn: 1.7185954\ttotal: 53.2s\tremaining: 13.2s\n",
      "961:\tlearn: 1.7185356\ttotal: 53.3s\tremaining: 13.2s\n",
      "962:\tlearn: 1.7184474\ttotal: 53.3s\tremaining: 13.1s\n",
      "963:\tlearn: 1.7183172\ttotal: 53.4s\tremaining: 13.1s\n",
      "964:\tlearn: 1.7182117\ttotal: 53.4s\tremaining: 13s\n",
      "965:\tlearn: 1.7181368\ttotal: 53.5s\tremaining: 13s\n",
      "966:\tlearn: 1.7180963\ttotal: 53.6s\tremaining: 12.9s\n",
      "967:\tlearn: 1.7180329\ttotal: 53.6s\tremaining: 12.8s\n",
      "968:\tlearn: 1.7179408\ttotal: 53.7s\tremaining: 12.8s\n",
      "969:\tlearn: 1.7178928\ttotal: 53.7s\tremaining: 12.7s\n",
      "970:\tlearn: 1.7177836\ttotal: 53.8s\tremaining: 12.7s\n",
      "971:\tlearn: 1.7176877\ttotal: 53.9s\tremaining: 12.6s\n",
      "972:\tlearn: 1.7176271\ttotal: 53.9s\tremaining: 12.6s\n",
      "973:\tlearn: 1.7175631\ttotal: 54s\tremaining: 12.5s\n",
      "974:\tlearn: 1.7174916\ttotal: 54s\tremaining: 12.5s\n",
      "975:\tlearn: 1.7174053\ttotal: 54.1s\tremaining: 12.4s\n",
      "976:\tlearn: 1.7173622\ttotal: 54.2s\tremaining: 12.4s\n",
      "977:\tlearn: 1.7172973\ttotal: 54.2s\tremaining: 12.3s\n",
      "978:\tlearn: 1.7172029\ttotal: 54.3s\tremaining: 12.3s\n",
      "979:\tlearn: 1.7171806\ttotal: 54.3s\tremaining: 12.2s\n",
      "980:\tlearn: 1.7170825\ttotal: 54.4s\tremaining: 12.1s\n",
      "981:\tlearn: 1.7170092\ttotal: 54.5s\tremaining: 12.1s\n",
      "982:\tlearn: 1.7169481\ttotal: 54.5s\tremaining: 12s\n",
      "983:\tlearn: 1.7169262\ttotal: 54.6s\tremaining: 12s\n",
      "984:\tlearn: 1.7168575\ttotal: 54.6s\tremaining: 11.9s\n",
      "985:\tlearn: 1.7167582\ttotal: 54.7s\tremaining: 11.9s\n",
      "986:\tlearn: 1.7166337\ttotal: 54.8s\tremaining: 11.8s\n",
      "987:\tlearn: 1.7165783\ttotal: 54.8s\tremaining: 11.8s\n",
      "988:\tlearn: 1.7165228\ttotal: 54.9s\tremaining: 11.7s\n",
      "989:\tlearn: 1.7164769\ttotal: 54.9s\tremaining: 11.7s\n",
      "990:\tlearn: 1.7164197\ttotal: 55s\tremaining: 11.6s\n",
      "991:\tlearn: 1.7163637\ttotal: 55.1s\tremaining: 11.5s\n",
      "992:\tlearn: 1.7163452\ttotal: 55.1s\tremaining: 11.5s\n",
      "993:\tlearn: 1.7162820\ttotal: 55.2s\tremaining: 11.4s\n",
      "994:\tlearn: 1.7161736\ttotal: 55.2s\tremaining: 11.4s\n",
      "995:\tlearn: 1.7161022\ttotal: 55.3s\tremaining: 11.3s\n",
      "996:\tlearn: 1.7160330\ttotal: 55.4s\tremaining: 11.3s\n",
      "997:\tlearn: 1.7159408\ttotal: 55.4s\tremaining: 11.2s\n",
      "998:\tlearn: 1.7158723\ttotal: 55.5s\tremaining: 11.2s\n",
      "999:\tlearn: 1.7158190\ttotal: 55.5s\tremaining: 11.1s\n",
      "1000:\tlearn: 1.7157588\ttotal: 55.6s\tremaining: 11.1s\n",
      "1001:\tlearn: 1.7157074\ttotal: 55.6s\tremaining: 11s\n",
      "1002:\tlearn: 1.7156261\ttotal: 55.7s\tremaining: 10.9s\n",
      "1003:\tlearn: 1.7155584\ttotal: 55.8s\tremaining: 10.9s\n",
      "1004:\tlearn: 1.7154823\ttotal: 55.8s\tremaining: 10.8s\n",
      "1005:\tlearn: 1.7154352\ttotal: 55.9s\tremaining: 10.8s\n",
      "1006:\tlearn: 1.7153648\ttotal: 56s\tremaining: 10.7s\n",
      "1007:\tlearn: 1.7152906\ttotal: 56s\tremaining: 10.7s\n",
      "1008:\tlearn: 1.7152322\ttotal: 56.1s\tremaining: 10.6s\n",
      "1009:\tlearn: 1.7151424\ttotal: 56.1s\tremaining: 10.6s\n",
      "1010:\tlearn: 1.7150842\ttotal: 56.2s\tremaining: 10.5s\n",
      "1011:\tlearn: 1.7150424\ttotal: 56.3s\tremaining: 10.4s\n",
      "1012:\tlearn: 1.7149704\ttotal: 56.3s\tremaining: 10.4s\n",
      "1013:\tlearn: 1.7148987\ttotal: 56.4s\tremaining: 10.3s\n",
      "1014:\tlearn: 1.7148207\ttotal: 56.4s\tremaining: 10.3s\n",
      "1015:\tlearn: 1.7147181\ttotal: 56.5s\tremaining: 10.2s\n",
      "1016:\tlearn: 1.7146571\ttotal: 56.6s\tremaining: 10.2s\n",
      "1017:\tlearn: 1.7146103\ttotal: 56.6s\tremaining: 10.1s\n",
      "1018:\tlearn: 1.7145214\ttotal: 56.7s\tremaining: 10.1s\n",
      "1019:\tlearn: 1.7144332\ttotal: 56.7s\tremaining: 10s\n",
      "1020:\tlearn: 1.7143569\ttotal: 56.8s\tremaining: 9.96s\n",
      "1021:\tlearn: 1.7143083\ttotal: 56.9s\tremaining: 9.9s\n",
      "1022:\tlearn: 1.7142571\ttotal: 56.9s\tremaining: 9.85s\n",
      "1023:\tlearn: 1.7141731\ttotal: 57s\tremaining: 9.79s\n",
      "1024:\tlearn: 1.7141035\ttotal: 57s\tremaining: 9.74s\n",
      "1025:\tlearn: 1.7140504\ttotal: 57.1s\tremaining: 9.68s\n",
      "1026:\tlearn: 1.7139631\ttotal: 57.2s\tremaining: 9.63s\n",
      "1027:\tlearn: 1.7139298\ttotal: 57.2s\tremaining: 9.57s\n",
      "1028:\tlearn: 1.7138738\ttotal: 57.3s\tremaining: 9.52s\n",
      "1029:\tlearn: 1.7138097\ttotal: 57.3s\tremaining: 9.46s\n",
      "1030:\tlearn: 1.7137221\ttotal: 57.4s\tremaining: 9.41s\n",
      "1031:\tlearn: 1.7136722\ttotal: 57.4s\tremaining: 9.35s\n",
      "1032:\tlearn: 1.7135945\ttotal: 57.5s\tremaining: 9.3s\n",
      "1033:\tlearn: 1.7135269\ttotal: 57.6s\tremaining: 9.24s\n",
      "1034:\tlearn: 1.7134449\ttotal: 57.6s\tremaining: 9.19s\n",
      "1035:\tlearn: 1.7134042\ttotal: 57.7s\tremaining: 9.13s\n",
      "1036:\tlearn: 1.7133375\ttotal: 57.8s\tremaining: 9.08s\n",
      "1037:\tlearn: 1.7132559\ttotal: 57.8s\tremaining: 9.02s\n",
      "1038:\tlearn: 1.7132145\ttotal: 57.9s\tremaining: 8.97s\n",
      "1039:\tlearn: 1.7131511\ttotal: 57.9s\tremaining: 8.91s\n",
      "1040:\tlearn: 1.7130663\ttotal: 58s\tremaining: 8.86s\n",
      "1041:\tlearn: 1.7130198\ttotal: 58s\tremaining: 8.8s\n",
      "1042:\tlearn: 1.7129250\ttotal: 58.1s\tremaining: 8.75s\n",
      "1043:\tlearn: 1.7128927\ttotal: 58.2s\tremaining: 8.69s\n",
      "1044:\tlearn: 1.7128187\ttotal: 58.2s\tremaining: 8.64s\n",
      "1045:\tlearn: 1.7127629\ttotal: 58.3s\tremaining: 8.58s\n",
      "1046:\tlearn: 1.7126871\ttotal: 58.4s\tremaining: 8.53s\n",
      "1047:\tlearn: 1.7126072\ttotal: 58.4s\tremaining: 8.47s\n",
      "1048:\tlearn: 1.7125576\ttotal: 58.5s\tremaining: 8.42s\n",
      "1049:\tlearn: 1.7124881\ttotal: 58.5s\tremaining: 8.36s\n",
      "1050:\tlearn: 1.7124064\ttotal: 58.6s\tremaining: 8.31s\n",
      "1051:\tlearn: 1.7123714\ttotal: 58.7s\tremaining: 8.25s\n",
      "1052:\tlearn: 1.7123484\ttotal: 58.7s\tremaining: 8.2s\n",
      "1053:\tlearn: 1.7122612\ttotal: 58.8s\tremaining: 8.14s\n",
      "1054:\tlearn: 1.7121708\ttotal: 58.8s\tremaining: 8.09s\n",
      "1055:\tlearn: 1.7121367\ttotal: 58.9s\tremaining: 8.03s\n",
      "1056:\tlearn: 1.7120908\ttotal: 59s\tremaining: 7.98s\n",
      "1057:\tlearn: 1.7120471\ttotal: 59s\tremaining: 7.92s\n",
      "1058:\tlearn: 1.7119428\ttotal: 59.1s\tremaining: 7.87s\n",
      "1059:\tlearn: 1.7118439\ttotal: 59.1s\tremaining: 7.81s\n",
      "1060:\tlearn: 1.7117914\ttotal: 59.2s\tremaining: 7.75s\n",
      "1061:\tlearn: 1.7117302\ttotal: 59.3s\tremaining: 7.7s\n",
      "1062:\tlearn: 1.7116837\ttotal: 59.3s\tremaining: 7.64s\n",
      "1063:\tlearn: 1.7116286\ttotal: 59.4s\tremaining: 7.59s\n",
      "1064:\tlearn: 1.7115144\ttotal: 59.4s\tremaining: 7.53s\n",
      "1065:\tlearn: 1.7114331\ttotal: 59.5s\tremaining: 7.48s\n",
      "1066:\tlearn: 1.7113864\ttotal: 59.6s\tremaining: 7.42s\n",
      "1067:\tlearn: 1.7113222\ttotal: 59.6s\tremaining: 7.37s\n",
      "1068:\tlearn: 1.7112520\ttotal: 59.7s\tremaining: 7.31s\n",
      "1069:\tlearn: 1.7111995\ttotal: 59.7s\tremaining: 7.26s\n",
      "1070:\tlearn: 1.7111558\ttotal: 59.8s\tremaining: 7.2s\n",
      "1071:\tlearn: 1.7111091\ttotal: 59.9s\tremaining: 7.15s\n",
      "1072:\tlearn: 1.7110668\ttotal: 59.9s\tremaining: 7.09s\n",
      "1073:\tlearn: 1.7110031\ttotal: 60s\tremaining: 7.04s\n",
      "1074:\tlearn: 1.7109463\ttotal: 1m\tremaining: 6.98s\n",
      "1075:\tlearn: 1.7108480\ttotal: 1m\tremaining: 6.92s\n",
      "1076:\tlearn: 1.7107787\ttotal: 1m\tremaining: 6.87s\n",
      "1077:\tlearn: 1.7107499\ttotal: 1m\tremaining: 6.82s\n",
      "1078:\tlearn: 1.7106722\ttotal: 1m\tremaining: 6.76s\n",
      "1079:\tlearn: 1.7106066\ttotal: 1m\tremaining: 6.7s\n",
      "1080:\tlearn: 1.7105112\ttotal: 1m\tremaining: 6.65s\n",
      "1081:\tlearn: 1.7104525\ttotal: 1m\tremaining: 6.59s\n",
      "1082:\tlearn: 1.7103854\ttotal: 1m\tremaining: 6.54s\n",
      "1083:\tlearn: 1.7103538\ttotal: 1m\tremaining: 6.48s\n",
      "1084:\tlearn: 1.7102778\ttotal: 1m\tremaining: 6.43s\n",
      "1085:\tlearn: 1.7102020\ttotal: 1m\tremaining: 6.37s\n",
      "1086:\tlearn: 1.7101480\ttotal: 1m\tremaining: 6.32s\n",
      "1087:\tlearn: 1.7100920\ttotal: 1m\tremaining: 6.26s\n",
      "1088:\tlearn: 1.7100355\ttotal: 1m\tremaining: 6.21s\n",
      "1089:\tlearn: 1.7099646\ttotal: 1m\tremaining: 6.15s\n",
      "1090:\tlearn: 1.7098944\ttotal: 1m 1s\tremaining: 6.09s\n",
      "1091:\tlearn: 1.7098606\ttotal: 1m 1s\tremaining: 6.04s\n",
      "1092:\tlearn: 1.7097933\ttotal: 1m 1s\tremaining: 5.98s\n",
      "1093:\tlearn: 1.7097482\ttotal: 1m 1s\tremaining: 5.93s\n",
      "1094:\tlearn: 1.7096335\ttotal: 1m 1s\tremaining: 5.87s\n",
      "1095:\tlearn: 1.7095659\ttotal: 1m 1s\tremaining: 5.82s\n",
      "1096:\tlearn: 1.7094786\ttotal: 1m 1s\tremaining: 5.76s\n",
      "1097:\tlearn: 1.7094336\ttotal: 1m 1s\tremaining: 5.71s\n",
      "1098:\tlearn: 1.7093923\ttotal: 1m 1s\tremaining: 5.65s\n",
      "1099:\tlearn: 1.7093367\ttotal: 1m 1s\tremaining: 5.6s\n",
      "1100:\tlearn: 1.7093088\ttotal: 1m 1s\tremaining: 5.54s\n",
      "1101:\tlearn: 1.7092359\ttotal: 1m 1s\tremaining: 5.49s\n",
      "1102:\tlearn: 1.7091703\ttotal: 1m 1s\tremaining: 5.43s\n",
      "1103:\tlearn: 1.7091069\ttotal: 1m 1s\tremaining: 5.37s\n",
      "1104:\tlearn: 1.7090223\ttotal: 1m 1s\tremaining: 5.32s\n",
      "1105:\tlearn: 1.7089594\ttotal: 1m 1s\tremaining: 5.26s\n",
      "1106:\tlearn: 1.7089012\ttotal: 1m 1s\tremaining: 5.21s\n",
      "1107:\tlearn: 1.7088822\ttotal: 1m 2s\tremaining: 5.15s\n",
      "1108:\tlearn: 1.7088391\ttotal: 1m 2s\tremaining: 5.1s\n",
      "1109:\tlearn: 1.7087888\ttotal: 1m 2s\tremaining: 5.04s\n",
      "1110:\tlearn: 1.7087092\ttotal: 1m 2s\tremaining: 4.98s\n",
      "1111:\tlearn: 1.7086654\ttotal: 1m 2s\tremaining: 4.93s\n",
      "1112:\tlearn: 1.7086185\ttotal: 1m 2s\tremaining: 4.87s\n",
      "1113:\tlearn: 1.7085667\ttotal: 1m 2s\tremaining: 4.82s\n",
      "1114:\tlearn: 1.7085321\ttotal: 1m 2s\tremaining: 4.76s\n",
      "1115:\tlearn: 1.7084674\ttotal: 1m 2s\tremaining: 4.71s\n",
      "1116:\tlearn: 1.7084102\ttotal: 1m 2s\tremaining: 4.65s\n",
      "1117:\tlearn: 1.7083666\ttotal: 1m 2s\tremaining: 4.59s\n",
      "1118:\tlearn: 1.7083114\ttotal: 1m 2s\tremaining: 4.54s\n",
      "1119:\tlearn: 1.7082408\ttotal: 1m 2s\tremaining: 4.48s\n",
      "1120:\tlearn: 1.7081875\ttotal: 1m 2s\tremaining: 4.43s\n",
      "1121:\tlearn: 1.7081341\ttotal: 1m 2s\tremaining: 4.37s\n",
      "1122:\tlearn: 1.7080848\ttotal: 1m 2s\tremaining: 4.32s\n",
      "1123:\tlearn: 1.7080293\ttotal: 1m 3s\tremaining: 4.26s\n",
      "1124:\tlearn: 1.7079389\ttotal: 1m 3s\tremaining: 4.2s\n",
      "1125:\tlearn: 1.7078600\ttotal: 1m 3s\tremaining: 4.15s\n",
      "1126:\tlearn: 1.7078108\ttotal: 1m 3s\tremaining: 4.09s\n",
      "1127:\tlearn: 1.7077521\ttotal: 1m 3s\tremaining: 4.04s\n",
      "1128:\tlearn: 1.7076674\ttotal: 1m 3s\tremaining: 3.98s\n",
      "1129:\tlearn: 1.7076225\ttotal: 1m 3s\tremaining: 3.92s\n",
      "1130:\tlearn: 1.7075632\ttotal: 1m 3s\tremaining: 3.87s\n",
      "1131:\tlearn: 1.7074691\ttotal: 1m 3s\tremaining: 3.81s\n",
      "1132:\tlearn: 1.7073868\ttotal: 1m 3s\tremaining: 3.76s\n",
      "1133:\tlearn: 1.7073632\ttotal: 1m 3s\tremaining: 3.7s\n",
      "1134:\tlearn: 1.7072857\ttotal: 1m 3s\tremaining: 3.65s\n",
      "1135:\tlearn: 1.7072570\ttotal: 1m 3s\tremaining: 3.59s\n",
      "1136:\tlearn: 1.7071684\ttotal: 1m 3s\tremaining: 3.53s\n",
      "1137:\tlearn: 1.7071287\ttotal: 1m 3s\tremaining: 3.48s\n",
      "1138:\tlearn: 1.7070518\ttotal: 1m 3s\tremaining: 3.42s\n",
      "1139:\tlearn: 1.7069983\ttotal: 1m 3s\tremaining: 3.37s\n",
      "1140:\tlearn: 1.7069305\ttotal: 1m 4s\tremaining: 3.31s\n",
      "1141:\tlearn: 1.7068993\ttotal: 1m 4s\tremaining: 3.25s\n",
      "1142:\tlearn: 1.7068622\ttotal: 1m 4s\tremaining: 3.2s\n",
      "1143:\tlearn: 1.7068285\ttotal: 1m 4s\tremaining: 3.14s\n",
      "1144:\tlearn: 1.7067854\ttotal: 1m 4s\tremaining: 3.09s\n",
      "1145:\tlearn: 1.7066898\ttotal: 1m 4s\tremaining: 3.03s\n",
      "1146:\tlearn: 1.7066393\ttotal: 1m 4s\tremaining: 2.98s\n",
      "1147:\tlearn: 1.7066126\ttotal: 1m 4s\tremaining: 2.92s\n",
      "1148:\tlearn: 1.7065597\ttotal: 1m 4s\tremaining: 2.86s\n",
      "1149:\tlearn: 1.7064738\ttotal: 1m 4s\tremaining: 2.81s\n",
      "1150:\tlearn: 1.7064037\ttotal: 1m 4s\tremaining: 2.75s\n",
      "1151:\tlearn: 1.7063213\ttotal: 1m 4s\tremaining: 2.69s\n",
      "1152:\tlearn: 1.7062556\ttotal: 1m 4s\tremaining: 2.64s\n",
      "1153:\tlearn: 1.7061946\ttotal: 1m 4s\tremaining: 2.58s\n",
      "1154:\tlearn: 1.7061168\ttotal: 1m 4s\tremaining: 2.53s\n",
      "1155:\tlearn: 1.7060560\ttotal: 1m 4s\tremaining: 2.47s\n",
      "1156:\tlearn: 1.7060123\ttotal: 1m 5s\tremaining: 2.42s\n",
      "1157:\tlearn: 1.7059300\ttotal: 1m 5s\tremaining: 2.36s\n",
      "1158:\tlearn: 1.7058638\ttotal: 1m 5s\tremaining: 2.3s\n",
      "1159:\tlearn: 1.7058047\ttotal: 1m 5s\tremaining: 2.25s\n",
      "1160:\tlearn: 1.7057716\ttotal: 1m 5s\tremaining: 2.19s\n",
      "1161:\tlearn: 1.7057232\ttotal: 1m 5s\tremaining: 2.13s\n",
      "1162:\tlearn: 1.7056705\ttotal: 1m 5s\tremaining: 2.08s\n",
      "1163:\tlearn: 1.7056078\ttotal: 1m 5s\tremaining: 2.02s\n",
      "1164:\tlearn: 1.7055569\ttotal: 1m 5s\tremaining: 1.97s\n",
      "1165:\tlearn: 1.7054907\ttotal: 1m 5s\tremaining: 1.91s\n",
      "1166:\tlearn: 1.7054557\ttotal: 1m 5s\tremaining: 1.85s\n",
      "1167:\tlearn: 1.7054221\ttotal: 1m 5s\tremaining: 1.8s\n",
      "1168:\tlearn: 1.7054073\ttotal: 1m 5s\tremaining: 1.74s\n",
      "1169:\tlearn: 1.7053592\ttotal: 1m 5s\tremaining: 1.69s\n",
      "1170:\tlearn: 1.7053344\ttotal: 1m 5s\tremaining: 1.63s\n",
      "1171:\tlearn: 1.7053066\ttotal: 1m 5s\tremaining: 1.57s\n",
      "1172:\tlearn: 1.7052062\ttotal: 1m 5s\tremaining: 1.52s\n",
      "1173:\tlearn: 1.7051454\ttotal: 1m 6s\tremaining: 1.46s\n",
      "1174:\tlearn: 1.7050645\ttotal: 1m 6s\tremaining: 1.41s\n",
      "1175:\tlearn: 1.7049936\ttotal: 1m 6s\tremaining: 1.35s\n",
      "1176:\tlearn: 1.7049419\ttotal: 1m 6s\tremaining: 1.29s\n",
      "1177:\tlearn: 1.7048389\ttotal: 1m 6s\tremaining: 1.24s\n",
      "1178:\tlearn: 1.7047712\ttotal: 1m 6s\tremaining: 1.18s\n",
      "1179:\tlearn: 1.7046976\ttotal: 1m 6s\tremaining: 1.13s\n",
      "1180:\tlearn: 1.7046372\ttotal: 1m 6s\tremaining: 1.07s\n",
      "1181:\tlearn: 1.7045719\ttotal: 1m 6s\tremaining: 1.01s\n",
      "1182:\tlearn: 1.7045291\ttotal: 1m 6s\tremaining: 957ms\n",
      "1183:\tlearn: 1.7044759\ttotal: 1m 6s\tremaining: 901ms\n",
      "1184:\tlearn: 1.7044322\ttotal: 1m 6s\tremaining: 844ms\n",
      "1185:\tlearn: 1.7043356\ttotal: 1m 6s\tremaining: 788ms\n",
      "1186:\tlearn: 1.7042794\ttotal: 1m 6s\tremaining: 732ms\n",
      "1187:\tlearn: 1.7042238\ttotal: 1m 6s\tremaining: 676ms\n",
      "1188:\tlearn: 1.7041165\ttotal: 1m 6s\tremaining: 619ms\n",
      "1189:\tlearn: 1.7040250\ttotal: 1m 7s\tremaining: 563ms\n",
      "1190:\tlearn: 1.7040067\ttotal: 1m 7s\tremaining: 507ms\n",
      "1191:\tlearn: 1.7039610\ttotal: 1m 7s\tremaining: 451ms\n",
      "1192:\tlearn: 1.7039102\ttotal: 1m 7s\tremaining: 394ms\n",
      "1193:\tlearn: 1.7038569\ttotal: 1m 7s\tremaining: 338ms\n",
      "1194:\tlearn: 1.7038035\ttotal: 1m 7s\tremaining: 282ms\n",
      "1195:\tlearn: 1.7037728\ttotal: 1m 7s\tremaining: 225ms\n",
      "1196:\tlearn: 1.7037517\ttotal: 1m 7s\tremaining: 169ms\n",
      "1197:\tlearn: 1.7036610\ttotal: 1m 7s\tremaining: 113ms\n",
      "1198:\tlearn: 1.7036073\ttotal: 1m 7s\tremaining: 56.3ms\n",
      "1199:\tlearn: 1.7035527\ttotal: 1m 7s\tremaining: 0us\n",
      "0.3117\n"
     ]
    }
   ],
   "source": [
    "wildcat.fit(X_train, y_train)\n",
    "y_pred = wildcat.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'hospital_cat_final.model'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(wildcat, archivo_salida)"
   ]
  },
  {
   "source": [
    "## 3. XGBoosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer()),\n",
    "    ('grad', XGBClassifier(eta=0.1, min_child_weight=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jgnsa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[17:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3117\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "y_pred = wildcat.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "## 4. Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_gump = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100, min_samples_split=10, random_state=42, min_samples_leaf=2, max_depth=20))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2943\n"
     ]
    }
   ],
   "source": [
    "forest_gump.fit(X_train, y_train)\n",
    "y_pred = forest_gump.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "## 6. Voting Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('grad', grad), ('cat', wildcat), ('xgb', xgb)]\n",
    "voting = VotingClassifier(estimators=estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "280733\ttotal: 45.2s\tremaining: 20s\n",
      "832:\tlearn: 1.7279583\ttotal: 45.2s\tremaining: 19.9s\n",
      "833:\tlearn: 1.7278547\ttotal: 45.3s\tremaining: 19.9s\n",
      "834:\tlearn: 1.7277705\ttotal: 45.3s\tremaining: 19.8s\n",
      "835:\tlearn: 1.7276851\ttotal: 45.4s\tremaining: 19.8s\n",
      "836:\tlearn: 1.7275815\ttotal: 45.4s\tremaining: 19.7s\n",
      "837:\tlearn: 1.7274873\ttotal: 45.5s\tremaining: 19.6s\n",
      "838:\tlearn: 1.7273559\ttotal: 45.5s\tremaining: 19.6s\n",
      "839:\tlearn: 1.7272660\ttotal: 45.6s\tremaining: 19.5s\n",
      "840:\tlearn: 1.7272140\ttotal: 45.6s\tremaining: 19.5s\n",
      "841:\tlearn: 1.7271330\ttotal: 45.7s\tremaining: 19.4s\n",
      "842:\tlearn: 1.7271033\ttotal: 45.8s\tremaining: 19.4s\n",
      "843:\tlearn: 1.7270310\ttotal: 45.8s\tremaining: 19.3s\n",
      "844:\tlearn: 1.7269776\ttotal: 45.9s\tremaining: 19.3s\n",
      "845:\tlearn: 1.7269194\ttotal: 45.9s\tremaining: 19.2s\n",
      "846:\tlearn: 1.7268354\ttotal: 46s\tremaining: 19.2s\n",
      "847:\tlearn: 1.7266822\ttotal: 46s\tremaining: 19.1s\n",
      "848:\tlearn: 1.7266109\ttotal: 46.1s\tremaining: 19.1s\n",
      "849:\tlearn: 1.7265313\ttotal: 46.1s\tremaining: 19s\n",
      "850:\tlearn: 1.7264516\ttotal: 46.2s\tremaining: 18.9s\n",
      "851:\tlearn: 1.7263893\ttotal: 46.2s\tremaining: 18.9s\n",
      "852:\tlearn: 1.7263264\ttotal: 46.3s\tremaining: 18.8s\n",
      "853:\tlearn: 1.7262320\ttotal: 46.4s\tremaining: 18.8s\n",
      "854:\tlearn: 1.7261433\ttotal: 46.4s\tremaining: 18.7s\n",
      "855:\tlearn: 1.7260323\ttotal: 46.5s\tremaining: 18.7s\n",
      "856:\tlearn: 1.7259375\ttotal: 46.5s\tremaining: 18.6s\n",
      "857:\tlearn: 1.7258502\ttotal: 46.6s\tremaining: 18.6s\n",
      "858:\tlearn: 1.7257846\ttotal: 46.6s\tremaining: 18.5s\n",
      "859:\tlearn: 1.7257320\ttotal: 46.7s\tremaining: 18.5s\n",
      "860:\tlearn: 1.7256840\ttotal: 46.7s\tremaining: 18.4s\n",
      "861:\tlearn: 1.7256315\ttotal: 46.8s\tremaining: 18.3s\n",
      "862:\tlearn: 1.7255382\ttotal: 46.8s\tremaining: 18.3s\n",
      "863:\tlearn: 1.7254572\ttotal: 46.9s\tremaining: 18.2s\n",
      "864:\tlearn: 1.7253875\ttotal: 47s\tremaining: 18.2s\n",
      "865:\tlearn: 1.7252963\ttotal: 47s\tremaining: 18.1s\n",
      "866:\tlearn: 1.7252345\ttotal: 47.1s\tremaining: 18.1s\n",
      "867:\tlearn: 1.7251502\ttotal: 47.2s\tremaining: 18s\n",
      "868:\tlearn: 1.7250493\ttotal: 47.2s\tremaining: 18s\n",
      "869:\tlearn: 1.7250014\ttotal: 47.3s\tremaining: 17.9s\n",
      "870:\tlearn: 1.7249044\ttotal: 47.3s\tremaining: 17.9s\n",
      "871:\tlearn: 1.7248355\ttotal: 47.4s\tremaining: 17.8s\n",
      "872:\tlearn: 1.7247419\ttotal: 47.4s\tremaining: 17.8s\n",
      "873:\tlearn: 1.7246293\ttotal: 47.5s\tremaining: 17.7s\n",
      "874:\tlearn: 1.7245665\ttotal: 47.5s\tremaining: 17.6s\n",
      "875:\tlearn: 1.7245011\ttotal: 47.6s\tremaining: 17.6s\n",
      "876:\tlearn: 1.7244674\ttotal: 47.6s\tremaining: 17.5s\n",
      "877:\tlearn: 1.7243564\ttotal: 47.6s\tremaining: 17.5s\n",
      "878:\tlearn: 1.7243063\ttotal: 47.7s\tremaining: 17.4s\n",
      "879:\tlearn: 1.7242424\ttotal: 47.7s\tremaining: 17.4s\n",
      "880:\tlearn: 1.7241756\ttotal: 47.8s\tremaining: 17.3s\n",
      "881:\tlearn: 1.7241073\ttotal: 47.9s\tremaining: 17.3s\n",
      "882:\tlearn: 1.7240226\ttotal: 47.9s\tremaining: 17.2s\n",
      "883:\tlearn: 1.7239590\ttotal: 48s\tremaining: 17.1s\n",
      "884:\tlearn: 1.7238781\ttotal: 48s\tremaining: 17.1s\n",
      "885:\tlearn: 1.7238121\ttotal: 48s\tremaining: 17s\n",
      "886:\tlearn: 1.7237313\ttotal: 48.1s\tremaining: 17s\n",
      "887:\tlearn: 1.7236719\ttotal: 48.1s\tremaining: 16.9s\n",
      "888:\tlearn: 1.7235870\ttotal: 48.2s\tremaining: 16.9s\n",
      "889:\tlearn: 1.7235163\ttotal: 48.2s\tremaining: 16.8s\n",
      "890:\tlearn: 1.7234357\ttotal: 48.3s\tremaining: 16.7s\n",
      "891:\tlearn: 1.7233794\ttotal: 48.3s\tremaining: 16.7s\n",
      "892:\tlearn: 1.7233115\ttotal: 48.4s\tremaining: 16.6s\n",
      "893:\tlearn: 1.7232249\ttotal: 48.4s\tremaining: 16.6s\n",
      "894:\tlearn: 1.7231485\ttotal: 48.5s\tremaining: 16.5s\n",
      "895:\tlearn: 1.7230707\ttotal: 48.5s\tremaining: 16.5s\n",
      "896:\tlearn: 1.7229850\ttotal: 48.6s\tremaining: 16.4s\n",
      "897:\tlearn: 1.7228900\ttotal: 48.6s\tremaining: 16.4s\n",
      "898:\tlearn: 1.7227879\ttotal: 48.7s\tremaining: 16.3s\n",
      "899:\tlearn: 1.7226675\ttotal: 48.7s\tremaining: 16.2s\n",
      "900:\tlearn: 1.7226212\ttotal: 48.8s\tremaining: 16.2s\n",
      "901:\tlearn: 1.7225713\ttotal: 48.8s\tremaining: 16.1s\n",
      "902:\tlearn: 1.7225050\ttotal: 48.9s\tremaining: 16.1s\n",
      "903:\tlearn: 1.7224370\ttotal: 48.9s\tremaining: 16s\n",
      "904:\tlearn: 1.7223881\ttotal: 49s\tremaining: 16s\n",
      "905:\tlearn: 1.7223244\ttotal: 49s\tremaining: 15.9s\n",
      "906:\tlearn: 1.7222043\ttotal: 49.1s\tremaining: 15.9s\n",
      "907:\tlearn: 1.7221384\ttotal: 49.1s\tremaining: 15.8s\n",
      "908:\tlearn: 1.7220677\ttotal: 49.2s\tremaining: 15.7s\n",
      "909:\tlearn: 1.7220030\ttotal: 49.2s\tremaining: 15.7s\n",
      "910:\tlearn: 1.7219552\ttotal: 49.3s\tremaining: 15.6s\n",
      "911:\tlearn: 1.7218739\ttotal: 49.3s\tremaining: 15.6s\n",
      "912:\tlearn: 1.7218247\ttotal: 49.4s\tremaining: 15.5s\n",
      "913:\tlearn: 1.7217312\ttotal: 49.4s\tremaining: 15.5s\n",
      "914:\tlearn: 1.7216498\ttotal: 49.5s\tremaining: 15.4s\n",
      "915:\tlearn: 1.7215393\ttotal: 49.5s\tremaining: 15.4s\n",
      "916:\tlearn: 1.7215046\ttotal: 49.6s\tremaining: 15.3s\n",
      "917:\tlearn: 1.7214580\ttotal: 49.6s\tremaining: 15.2s\n",
      "918:\tlearn: 1.7214387\ttotal: 49.7s\tremaining: 15.2s\n",
      "919:\tlearn: 1.7213451\ttotal: 49.7s\tremaining: 15.1s\n",
      "920:\tlearn: 1.7212791\ttotal: 49.8s\tremaining: 15.1s\n",
      "921:\tlearn: 1.7212143\ttotal: 49.8s\tremaining: 15s\n",
      "922:\tlearn: 1.7211231\ttotal: 49.9s\tremaining: 15s\n",
      "923:\tlearn: 1.7210209\ttotal: 49.9s\tremaining: 14.9s\n",
      "924:\tlearn: 1.7209699\ttotal: 50s\tremaining: 14.9s\n",
      "925:\tlearn: 1.7208792\ttotal: 50s\tremaining: 14.8s\n",
      "926:\tlearn: 1.7208175\ttotal: 50.1s\tremaining: 14.7s\n",
      "927:\tlearn: 1.7207413\ttotal: 50.1s\tremaining: 14.7s\n",
      "928:\tlearn: 1.7206728\ttotal: 50.2s\tremaining: 14.6s\n",
      "929:\tlearn: 1.7206013\ttotal: 50.2s\tremaining: 14.6s\n",
      "930:\tlearn: 1.7205357\ttotal: 50.3s\tremaining: 14.5s\n",
      "931:\tlearn: 1.7204407\ttotal: 50.3s\tremaining: 14.5s\n",
      "932:\tlearn: 1.7203978\ttotal: 50.4s\tremaining: 14.4s\n",
      "933:\tlearn: 1.7202886\ttotal: 50.4s\tremaining: 14.4s\n",
      "934:\tlearn: 1.7202520\ttotal: 50.5s\tremaining: 14.3s\n",
      "935:\tlearn: 1.7202305\ttotal: 50.5s\tremaining: 14.3s\n",
      "936:\tlearn: 1.7201805\ttotal: 50.6s\tremaining: 14.2s\n",
      "937:\tlearn: 1.7201309\ttotal: 50.6s\tremaining: 14.1s\n",
      "938:\tlearn: 1.7200684\ttotal: 50.7s\tremaining: 14.1s\n",
      "939:\tlearn: 1.7200070\ttotal: 50.7s\tremaining: 14s\n",
      "940:\tlearn: 1.7199636\ttotal: 50.8s\tremaining: 14s\n",
      "941:\tlearn: 1.7198966\ttotal: 50.9s\tremaining: 13.9s\n",
      "942:\tlearn: 1.7198355\ttotal: 50.9s\tremaining: 13.9s\n",
      "943:\tlearn: 1.7197721\ttotal: 51s\tremaining: 13.8s\n",
      "944:\tlearn: 1.7197036\ttotal: 51s\tremaining: 13.8s\n",
      "945:\tlearn: 1.7196550\ttotal: 51.1s\tremaining: 13.7s\n",
      "946:\tlearn: 1.7195827\ttotal: 51.1s\tremaining: 13.7s\n",
      "947:\tlearn: 1.7195060\ttotal: 51.2s\tremaining: 13.6s\n",
      "948:\tlearn: 1.7193695\ttotal: 51.2s\tremaining: 13.6s\n",
      "949:\tlearn: 1.7193202\ttotal: 51.3s\tremaining: 13.5s\n",
      "950:\tlearn: 1.7192758\ttotal: 51.4s\tremaining: 13.4s\n",
      "951:\tlearn: 1.7192321\ttotal: 51.4s\tremaining: 13.4s\n",
      "952:\tlearn: 1.7191448\ttotal: 51.5s\tremaining: 13.3s\n",
      "953:\tlearn: 1.7190892\ttotal: 51.5s\tremaining: 13.3s\n",
      "954:\tlearn: 1.7190075\ttotal: 51.6s\tremaining: 13.2s\n",
      "955:\tlearn: 1.7189188\ttotal: 51.6s\tremaining: 13.2s\n",
      "956:\tlearn: 1.7188373\ttotal: 51.7s\tremaining: 13.1s\n",
      "957:\tlearn: 1.7187787\ttotal: 51.8s\tremaining: 13.1s\n",
      "958:\tlearn: 1.7187041\ttotal: 51.8s\tremaining: 13s\n",
      "959:\tlearn: 1.7186556\ttotal: 51.9s\tremaining: 13s\n",
      "960:\tlearn: 1.7185954\ttotal: 51.9s\tremaining: 12.9s\n",
      "961:\tlearn: 1.7185356\ttotal: 52s\tremaining: 12.9s\n",
      "962:\tlearn: 1.7184474\ttotal: 52.1s\tremaining: 12.8s\n",
      "963:\tlearn: 1.7183172\ttotal: 52.1s\tremaining: 12.8s\n",
      "964:\tlearn: 1.7182117\ttotal: 52.2s\tremaining: 12.7s\n",
      "965:\tlearn: 1.7181368\ttotal: 52.2s\tremaining: 12.7s\n",
      "966:\tlearn: 1.7180963\ttotal: 52.3s\tremaining: 12.6s\n",
      "967:\tlearn: 1.7180329\ttotal: 52.4s\tremaining: 12.5s\n",
      "968:\tlearn: 1.7179408\ttotal: 52.4s\tremaining: 12.5s\n",
      "969:\tlearn: 1.7178928\ttotal: 52.5s\tremaining: 12.4s\n",
      "970:\tlearn: 1.7177836\ttotal: 52.5s\tremaining: 12.4s\n",
      "971:\tlearn: 1.7176877\ttotal: 52.6s\tremaining: 12.3s\n",
      "972:\tlearn: 1.7176271\ttotal: 52.6s\tremaining: 12.3s\n",
      "973:\tlearn: 1.7175631\ttotal: 52.7s\tremaining: 12.2s\n",
      "974:\tlearn: 1.7174916\ttotal: 52.7s\tremaining: 12.2s\n",
      "975:\tlearn: 1.7174053\ttotal: 52.8s\tremaining: 12.1s\n",
      "976:\tlearn: 1.7173622\ttotal: 52.8s\tremaining: 12.1s\n",
      "977:\tlearn: 1.7172973\ttotal: 52.9s\tremaining: 12s\n",
      "978:\tlearn: 1.7172029\ttotal: 53s\tremaining: 12s\n",
      "979:\tlearn: 1.7171806\ttotal: 53s\tremaining: 11.9s\n",
      "980:\tlearn: 1.7170825\ttotal: 53.1s\tremaining: 11.9s\n",
      "981:\tlearn: 1.7170092\ttotal: 53.2s\tremaining: 11.8s\n",
      "982:\tlearn: 1.7169481\ttotal: 53.2s\tremaining: 11.7s\n",
      "983:\tlearn: 1.7169262\ttotal: 53.3s\tremaining: 11.7s\n",
      "984:\tlearn: 1.7168575\ttotal: 53.3s\tremaining: 11.6s\n",
      "985:\tlearn: 1.7167582\ttotal: 53.4s\tremaining: 11.6s\n",
      "986:\tlearn: 1.7166337\ttotal: 53.5s\tremaining: 11.5s\n",
      "987:\tlearn: 1.7165783\ttotal: 53.5s\tremaining: 11.5s\n",
      "988:\tlearn: 1.7165228\ttotal: 53.5s\tremaining: 11.4s\n",
      "989:\tlearn: 1.7164769\ttotal: 53.6s\tremaining: 11.4s\n",
      "990:\tlearn: 1.7164197\ttotal: 53.6s\tremaining: 11.3s\n",
      "991:\tlearn: 1.7163637\ttotal: 53.7s\tremaining: 11.3s\n",
      "992:\tlearn: 1.7163452\ttotal: 53.7s\tremaining: 11.2s\n",
      "993:\tlearn: 1.7162820\ttotal: 53.8s\tremaining: 11.1s\n",
      "994:\tlearn: 1.7161736\ttotal: 53.8s\tremaining: 11.1s\n",
      "995:\tlearn: 1.7161022\ttotal: 53.9s\tremaining: 11s\n",
      "996:\tlearn: 1.7160330\ttotal: 54s\tremaining: 11s\n",
      "997:\tlearn: 1.7159408\ttotal: 54s\tremaining: 10.9s\n",
      "998:\tlearn: 1.7158723\ttotal: 54.1s\tremaining: 10.9s\n",
      "999:\tlearn: 1.7158190\ttotal: 54.1s\tremaining: 10.8s\n",
      "1000:\tlearn: 1.7157588\ttotal: 54.2s\tremaining: 10.8s\n",
      "1001:\tlearn: 1.7157074\ttotal: 54.2s\tremaining: 10.7s\n",
      "1002:\tlearn: 1.7156261\ttotal: 54.3s\tremaining: 10.7s\n",
      "1003:\tlearn: 1.7155584\ttotal: 54.3s\tremaining: 10.6s\n",
      "1004:\tlearn: 1.7154823\ttotal: 54.4s\tremaining: 10.5s\n",
      "1005:\tlearn: 1.7154352\ttotal: 54.4s\tremaining: 10.5s\n",
      "1006:\tlearn: 1.7153648\ttotal: 54.5s\tremaining: 10.4s\n",
      "1007:\tlearn: 1.7152906\ttotal: 54.5s\tremaining: 10.4s\n",
      "1008:\tlearn: 1.7152322\ttotal: 54.6s\tremaining: 10.3s\n",
      "1009:\tlearn: 1.7151424\ttotal: 54.6s\tremaining: 10.3s\n",
      "1010:\tlearn: 1.7150842\ttotal: 54.7s\tremaining: 10.2s\n",
      "1011:\tlearn: 1.7150424\ttotal: 54.7s\tremaining: 10.2s\n",
      "1012:\tlearn: 1.7149704\ttotal: 54.7s\tremaining: 10.1s\n",
      "1013:\tlearn: 1.7148987\ttotal: 54.8s\tremaining: 10.1s\n",
      "1014:\tlearn: 1.7148207\ttotal: 54.8s\tremaining: 10s\n",
      "1015:\tlearn: 1.7147181\ttotal: 54.9s\tremaining: 9.94s\n",
      "1016:\tlearn: 1.7146571\ttotal: 54.9s\tremaining: 9.89s\n",
      "1017:\tlearn: 1.7146103\ttotal: 55s\tremaining: 9.83s\n",
      "1018:\tlearn: 1.7145214\ttotal: 55s\tremaining: 9.78s\n",
      "1019:\tlearn: 1.7144332\ttotal: 55.1s\tremaining: 9.72s\n",
      "1020:\tlearn: 1.7143569\ttotal: 55.1s\tremaining: 9.67s\n",
      "1021:\tlearn: 1.7143083\ttotal: 55.2s\tremaining: 9.61s\n",
      "1022:\tlearn: 1.7142571\ttotal: 55.2s\tremaining: 9.56s\n",
      "1023:\tlearn: 1.7141731\ttotal: 55.3s\tremaining: 9.5s\n",
      "1024:\tlearn: 1.7141035\ttotal: 55.3s\tremaining: 9.45s\n",
      "1025:\tlearn: 1.7140504\ttotal: 55.4s\tremaining: 9.39s\n",
      "1026:\tlearn: 1.7139631\ttotal: 55.4s\tremaining: 9.34s\n",
      "1027:\tlearn: 1.7139298\ttotal: 55.5s\tremaining: 9.28s\n",
      "1028:\tlearn: 1.7138738\ttotal: 55.5s\tremaining: 9.23s\n",
      "1029:\tlearn: 1.7138097\ttotal: 55.6s\tremaining: 9.17s\n",
      "1030:\tlearn: 1.7137221\ttotal: 55.6s\tremaining: 9.12s\n",
      "1031:\tlearn: 1.7136722\ttotal: 55.7s\tremaining: 9.06s\n",
      "1032:\tlearn: 1.7135945\ttotal: 55.7s\tremaining: 9.01s\n",
      "1033:\tlearn: 1.7135269\ttotal: 55.8s\tremaining: 8.95s\n",
      "1034:\tlearn: 1.7134449\ttotal: 55.8s\tremaining: 8.9s\n",
      "1035:\tlearn: 1.7134042\ttotal: 55.9s\tremaining: 8.85s\n",
      "1036:\tlearn: 1.7133375\ttotal: 55.9s\tremaining: 8.79s\n",
      "1037:\tlearn: 1.7132559\ttotal: 56s\tremaining: 8.73s\n",
      "1038:\tlearn: 1.7132145\ttotal: 56s\tremaining: 8.68s\n",
      "1039:\tlearn: 1.7131511\ttotal: 56.1s\tremaining: 8.63s\n",
      "1040:\tlearn: 1.7130663\ttotal: 56.1s\tremaining: 8.57s\n",
      "1041:\tlearn: 1.7130198\ttotal: 56.2s\tremaining: 8.52s\n",
      "1042:\tlearn: 1.7129250\ttotal: 56.2s\tremaining: 8.46s\n",
      "1043:\tlearn: 1.7128927\ttotal: 56.3s\tremaining: 8.41s\n",
      "1044:\tlearn: 1.7128187\ttotal: 56.3s\tremaining: 8.35s\n",
      "1045:\tlearn: 1.7127629\ttotal: 56.4s\tremaining: 8.3s\n",
      "1046:\tlearn: 1.7126871\ttotal: 56.4s\tremaining: 8.24s\n",
      "1047:\tlearn: 1.7126072\ttotal: 56.5s\tremaining: 8.19s\n",
      "1048:\tlearn: 1.7125576\ttotal: 56.5s\tremaining: 8.13s\n",
      "1049:\tlearn: 1.7124881\ttotal: 56.6s\tremaining: 8.08s\n",
      "1050:\tlearn: 1.7124064\ttotal: 56.6s\tremaining: 8.03s\n",
      "1051:\tlearn: 1.7123714\ttotal: 56.7s\tremaining: 7.97s\n",
      "1052:\tlearn: 1.7123484\ttotal: 56.7s\tremaining: 7.92s\n",
      "1053:\tlearn: 1.7122612\ttotal: 56.8s\tremaining: 7.86s\n",
      "1054:\tlearn: 1.7121708\ttotal: 56.8s\tremaining: 7.81s\n",
      "1055:\tlearn: 1.7121367\ttotal: 56.9s\tremaining: 7.75s\n",
      "1056:\tlearn: 1.7120908\ttotal: 56.9s\tremaining: 7.7s\n",
      "1057:\tlearn: 1.7120471\ttotal: 57s\tremaining: 7.64s\n",
      "1058:\tlearn: 1.7119428\ttotal: 57s\tremaining: 7.59s\n",
      "1059:\tlearn: 1.7118439\ttotal: 57.1s\tremaining: 7.54s\n",
      "1060:\tlearn: 1.7117914\ttotal: 57.1s\tremaining: 7.48s\n",
      "1061:\tlearn: 1.7117302\ttotal: 57.2s\tremaining: 7.43s\n",
      "1062:\tlearn: 1.7116837\ttotal: 57.2s\tremaining: 7.37s\n",
      "1063:\tlearn: 1.7116286\ttotal: 57.3s\tremaining: 7.32s\n",
      "1064:\tlearn: 1.7115144\ttotal: 57.3s\tremaining: 7.26s\n",
      "1065:\tlearn: 1.7114331\ttotal: 57.4s\tremaining: 7.21s\n",
      "1066:\tlearn: 1.7113864\ttotal: 57.4s\tremaining: 7.16s\n",
      "1067:\tlearn: 1.7113222\ttotal: 57.5s\tremaining: 7.1s\n",
      "1068:\tlearn: 1.7112520\ttotal: 57.5s\tremaining: 7.05s\n",
      "1069:\tlearn: 1.7111995\ttotal: 57.6s\tremaining: 6.99s\n",
      "1070:\tlearn: 1.7111558\ttotal: 57.6s\tremaining: 6.94s\n",
      "1071:\tlearn: 1.7111091\ttotal: 57.7s\tremaining: 6.88s\n",
      "1072:\tlearn: 1.7110668\ttotal: 57.7s\tremaining: 6.83s\n",
      "1073:\tlearn: 1.7110031\ttotal: 57.8s\tremaining: 6.78s\n",
      "1074:\tlearn: 1.7109463\ttotal: 57.8s\tremaining: 6.72s\n",
      "1075:\tlearn: 1.7108480\ttotal: 57.9s\tremaining: 6.67s\n",
      "1076:\tlearn: 1.7107787\ttotal: 57.9s\tremaining: 6.61s\n",
      "1077:\tlearn: 1.7107499\ttotal: 57.9s\tremaining: 6.56s\n",
      "1078:\tlearn: 1.7106722\ttotal: 58s\tremaining: 6.5s\n",
      "1079:\tlearn: 1.7106066\ttotal: 58s\tremaining: 6.45s\n",
      "1080:\tlearn: 1.7105112\ttotal: 58.1s\tremaining: 6.39s\n",
      "1081:\tlearn: 1.7104525\ttotal: 58.1s\tremaining: 6.34s\n",
      "1082:\tlearn: 1.7103854\ttotal: 58.2s\tremaining: 6.29s\n",
      "1083:\tlearn: 1.7103538\ttotal: 58.2s\tremaining: 6.23s\n",
      "1084:\tlearn: 1.7102778\ttotal: 58.3s\tremaining: 6.18s\n",
      "1085:\tlearn: 1.7102020\ttotal: 58.3s\tremaining: 6.12s\n",
      "1086:\tlearn: 1.7101480\ttotal: 58.4s\tremaining: 6.07s\n",
      "1087:\tlearn: 1.7100920\ttotal: 58.4s\tremaining: 6.02s\n",
      "1088:\tlearn: 1.7100355\ttotal: 58.5s\tremaining: 5.96s\n",
      "1089:\tlearn: 1.7099646\ttotal: 58.5s\tremaining: 5.91s\n",
      "1090:\tlearn: 1.7098944\ttotal: 58.6s\tremaining: 5.85s\n",
      "1091:\tlearn: 1.7098606\ttotal: 58.6s\tremaining: 5.8s\n",
      "1092:\tlearn: 1.7097933\ttotal: 58.7s\tremaining: 5.75s\n",
      "1093:\tlearn: 1.7097482\ttotal: 58.7s\tremaining: 5.69s\n",
      "1094:\tlearn: 1.7096335\ttotal: 58.8s\tremaining: 5.64s\n",
      "1095:\tlearn: 1.7095659\ttotal: 58.8s\tremaining: 5.58s\n",
      "1096:\tlearn: 1.7094786\ttotal: 58.9s\tremaining: 5.53s\n",
      "1097:\tlearn: 1.7094336\ttotal: 58.9s\tremaining: 5.47s\n",
      "1098:\tlearn: 1.7093923\ttotal: 59s\tremaining: 5.42s\n",
      "1099:\tlearn: 1.7093367\ttotal: 59s\tremaining: 5.37s\n",
      "1100:\tlearn: 1.7093088\ttotal: 59.1s\tremaining: 5.31s\n",
      "1101:\tlearn: 1.7092359\ttotal: 59.1s\tremaining: 5.26s\n",
      "1102:\tlearn: 1.7091703\ttotal: 59.2s\tremaining: 5.21s\n",
      "1103:\tlearn: 1.7091069\ttotal: 59.2s\tremaining: 5.15s\n",
      "1104:\tlearn: 1.7090223\ttotal: 59.3s\tremaining: 5.1s\n",
      "1105:\tlearn: 1.7089594\ttotal: 59.3s\tremaining: 5.04s\n",
      "1106:\tlearn: 1.7089012\ttotal: 59.4s\tremaining: 4.99s\n",
      "1107:\tlearn: 1.7088822\ttotal: 59.4s\tremaining: 4.93s\n",
      "1108:\tlearn: 1.7088391\ttotal: 59.5s\tremaining: 4.88s\n",
      "1109:\tlearn: 1.7087888\ttotal: 59.5s\tremaining: 4.83s\n",
      "1110:\tlearn: 1.7087092\ttotal: 59.6s\tremaining: 4.77s\n",
      "1111:\tlearn: 1.7086654\ttotal: 59.6s\tremaining: 4.72s\n",
      "1112:\tlearn: 1.7086185\ttotal: 59.7s\tremaining: 4.67s\n",
      "1113:\tlearn: 1.7085667\ttotal: 59.7s\tremaining: 4.61s\n",
      "1114:\tlearn: 1.7085321\ttotal: 59.8s\tremaining: 4.56s\n",
      "1115:\tlearn: 1.7084674\ttotal: 59.8s\tremaining: 4.5s\n",
      "1116:\tlearn: 1.7084102\ttotal: 59.9s\tremaining: 4.45s\n",
      "1117:\tlearn: 1.7083666\ttotal: 59.9s\tremaining: 4.39s\n",
      "1118:\tlearn: 1.7083114\ttotal: 60s\tremaining: 4.34s\n",
      "1119:\tlearn: 1.7082408\ttotal: 1m\tremaining: 4.29s\n",
      "1120:\tlearn: 1.7081875\ttotal: 1m\tremaining: 4.23s\n",
      "1121:\tlearn: 1.7081341\ttotal: 1m\tremaining: 4.18s\n",
      "1122:\tlearn: 1.7080848\ttotal: 1m\tremaining: 4.13s\n",
      "1123:\tlearn: 1.7080293\ttotal: 1m\tremaining: 4.07s\n",
      "1124:\tlearn: 1.7079389\ttotal: 1m\tremaining: 4.02s\n",
      "1125:\tlearn: 1.7078600\ttotal: 1m\tremaining: 3.96s\n",
      "1126:\tlearn: 1.7078108\ttotal: 1m\tremaining: 3.91s\n",
      "1127:\tlearn: 1.7077521\ttotal: 1m\tremaining: 3.86s\n",
      "1128:\tlearn: 1.7076674\ttotal: 1m\tremaining: 3.8s\n",
      "1129:\tlearn: 1.7076225\ttotal: 1m\tremaining: 3.75s\n",
      "1130:\tlearn: 1.7075632\ttotal: 1m\tremaining: 3.69s\n",
      "1131:\tlearn: 1.7074691\ttotal: 1m\tremaining: 3.64s\n",
      "1132:\tlearn: 1.7073868\ttotal: 1m\tremaining: 3.59s\n",
      "1133:\tlearn: 1.7073632\ttotal: 1m\tremaining: 3.53s\n",
      "1134:\tlearn: 1.7072857\ttotal: 1m\tremaining: 3.48s\n",
      "1135:\tlearn: 1.7072570\ttotal: 1m\tremaining: 3.43s\n",
      "1136:\tlearn: 1.7071684\ttotal: 1m\tremaining: 3.37s\n",
      "1137:\tlearn: 1.7071287\ttotal: 1m\tremaining: 3.32s\n",
      "1138:\tlearn: 1.7070518\ttotal: 1m\tremaining: 3.27s\n",
      "1139:\tlearn: 1.7069983\ttotal: 1m 1s\tremaining: 3.21s\n",
      "1140:\tlearn: 1.7069305\ttotal: 1m 1s\tremaining: 3.16s\n",
      "1141:\tlearn: 1.7068993\ttotal: 1m 1s\tremaining: 3.1s\n",
      "1142:\tlearn: 1.7068622\ttotal: 1m 1s\tremaining: 3.05s\n",
      "1143:\tlearn: 1.7068285\ttotal: 1m 1s\tremaining: 3s\n",
      "1144:\tlearn: 1.7067854\ttotal: 1m 1s\tremaining: 2.94s\n",
      "1145:\tlearn: 1.7066898\ttotal: 1m 1s\tremaining: 2.89s\n",
      "1146:\tlearn: 1.7066393\ttotal: 1m 1s\tremaining: 2.83s\n",
      "1147:\tlearn: 1.7066126\ttotal: 1m 1s\tremaining: 2.78s\n",
      "1148:\tlearn: 1.7065597\ttotal: 1m 1s\tremaining: 2.73s\n",
      "1149:\tlearn: 1.7064738\ttotal: 1m 1s\tremaining: 2.67s\n",
      "1150:\tlearn: 1.7064037\ttotal: 1m 1s\tremaining: 2.62s\n",
      "1151:\tlearn: 1.7063213\ttotal: 1m 1s\tremaining: 2.57s\n",
      "1152:\tlearn: 1.7062556\ttotal: 1m 1s\tremaining: 2.51s\n",
      "1153:\tlearn: 1.7061946\ttotal: 1m 1s\tremaining: 2.46s\n",
      "1154:\tlearn: 1.7061168\ttotal: 1m 1s\tremaining: 2.4s\n",
      "1155:\tlearn: 1.7060560\ttotal: 1m 1s\tremaining: 2.35s\n",
      "1156:\tlearn: 1.7060123\ttotal: 1m 1s\tremaining: 2.3s\n",
      "1157:\tlearn: 1.7059300\ttotal: 1m 1s\tremaining: 2.24s\n",
      "1158:\tlearn: 1.7058638\ttotal: 1m 1s\tremaining: 2.19s\n",
      "1159:\tlearn: 1.7058047\ttotal: 1m 1s\tremaining: 2.14s\n",
      "1160:\tlearn: 1.7057716\ttotal: 1m 2s\tremaining: 2.08s\n",
      "1161:\tlearn: 1.7057232\ttotal: 1m 2s\tremaining: 2.03s\n",
      "1162:\tlearn: 1.7056705\ttotal: 1m 2s\tremaining: 1.98s\n",
      "1163:\tlearn: 1.7056078\ttotal: 1m 2s\tremaining: 1.92s\n",
      "1164:\tlearn: 1.7055569\ttotal: 1m 2s\tremaining: 1.87s\n",
      "1165:\tlearn: 1.7054907\ttotal: 1m 2s\tremaining: 1.82s\n",
      "1166:\tlearn: 1.7054557\ttotal: 1m 2s\tremaining: 1.76s\n",
      "1167:\tlearn: 1.7054221\ttotal: 1m 2s\tremaining: 1.71s\n",
      "1168:\tlearn: 1.7054073\ttotal: 1m 2s\tremaining: 1.66s\n",
      "1169:\tlearn: 1.7053592\ttotal: 1m 2s\tremaining: 1.6s\n",
      "1170:\tlearn: 1.7053344\ttotal: 1m 2s\tremaining: 1.55s\n",
      "1171:\tlearn: 1.7053066\ttotal: 1m 2s\tremaining: 1.49s\n",
      "1172:\tlearn: 1.7052062\ttotal: 1m 2s\tremaining: 1.44s\n",
      "1173:\tlearn: 1.7051454\ttotal: 1m 2s\tremaining: 1.39s\n",
      "1174:\tlearn: 1.7050645\ttotal: 1m 2s\tremaining: 1.33s\n",
      "1175:\tlearn: 1.7049936\ttotal: 1m 2s\tremaining: 1.28s\n",
      "1176:\tlearn: 1.7049419\ttotal: 1m 2s\tremaining: 1.23s\n",
      "1177:\tlearn: 1.7048389\ttotal: 1m 2s\tremaining: 1.17s\n",
      "1178:\tlearn: 1.7047712\ttotal: 1m 2s\tremaining: 1.12s\n",
      "1179:\tlearn: 1.7046976\ttotal: 1m 2s\tremaining: 1.07s\n",
      "1180:\tlearn: 1.7046372\ttotal: 1m 3s\tremaining: 1.01s\n",
      "1181:\tlearn: 1.7045719\ttotal: 1m 3s\tremaining: 960ms\n",
      "1182:\tlearn: 1.7045291\ttotal: 1m 3s\tremaining: 907ms\n",
      "1183:\tlearn: 1.7044759\ttotal: 1m 3s\tremaining: 853ms\n",
      "1184:\tlearn: 1.7044322\ttotal: 1m 3s\tremaining: 800ms\n",
      "1185:\tlearn: 1.7043356\ttotal: 1m 3s\tremaining: 747ms\n",
      "1186:\tlearn: 1.7042794\ttotal: 1m 3s\tremaining: 693ms\n",
      "1187:\tlearn: 1.7042238\ttotal: 1m 3s\tremaining: 640ms\n",
      "1188:\tlearn: 1.7041165\ttotal: 1m 3s\tremaining: 587ms\n",
      "1189:\tlearn: 1.7040250\ttotal: 1m 3s\tremaining: 533ms\n",
      "1190:\tlearn: 1.7040067\ttotal: 1m 3s\tremaining: 480ms\n",
      "1191:\tlearn: 1.7039610\ttotal: 1m 3s\tremaining: 427ms\n",
      "1192:\tlearn: 1.7039102\ttotal: 1m 3s\tremaining: 373ms\n",
      "1193:\tlearn: 1.7038569\ttotal: 1m 3s\tremaining: 320ms\n",
      "1194:\tlearn: 1.7038035\ttotal: 1m 3s\tremaining: 267ms\n",
      "1195:\tlearn: 1.7037728\ttotal: 1m 3s\tremaining: 213ms\n",
      "1196:\tlearn: 1.7037517\ttotal: 1m 3s\tremaining: 160ms\n",
      "1197:\tlearn: 1.7036610\ttotal: 1m 3s\tremaining: 107ms\n",
      "1198:\tlearn: 1.7036073\ttotal: 1m 3s\tremaining: 53.3ms\n",
      "1199:\tlearn: 1.7035527\ttotal: 1m 3s\tremaining: 0us\n",
      "C:\\Users\\jgnsa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[17:14:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3149\n"
     ]
    }
   ],
   "source": [
    "voting.fit(X_train, y_train)\n",
    "y_pred = voting.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "## 7. Final Transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta funciÃ³n se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es asÃ­, se guardarÃ¡ el dataframe en un `csv` y estarÃ¡ listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aÃºn no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. TambiÃ©n tÃº.\n",
    "    \"\"\"\n",
    "    sample = pd.read_csv(\"sample_submission.csv\")\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id.all() == sample.id.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                df_to_submit.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que despuÃ©s de todo este notebook hayas hecho algÃºn cambio en las filas de `diamonds_test.csv`. Lloro.\")\n",
    "\n",
    "filepath = 'hospital_test.csv'\n",
    "\n",
    "def prepare_test(model, filepath):\n",
    "    df = pd.read_csv(filepath, index_col=0)\n",
    "    # Operaciones de transformaciÃ³n.\n",
    "    # Quitamos las columnas no relevantes\n",
    "    filtered = df.drop(['1', '3', '4', '7', '8', '9','10', '11', '14','16'], axis=1)\n",
    "\n",
    "    # Aplicamos los encoders\n",
    "    filtered['12'] = filtered['12'].apply(HospitalEncoder.encode_admission)\n",
    "    filtered['13'] = filtered['13'].apply(HospitalEncoder.encode_severity)\n",
    "    filtered['15'] = filtered['15'].apply(HospitalEncoder.encode_age)\n",
    "\n",
    "    # Get dummies\n",
    "    features = filtered[['2', '6']]\n",
    "    features = pd.get_dummies(features)\n",
    "    filtered.drop(['2', '6'], axis=1, inplace=True)\n",
    "    test = pd.concat([filtered, features], axis=1)\n",
    "\n",
    "    # Creamos X\n",
    "    X = np.array(test)\n",
    "\n",
    "    # Cambiamos Nan por la media\n",
    "    sim = SimpleImputer()\n",
    "    X = sim.fit_transform(X)\n",
    "\n",
    "    # Cogemos Ã­ndice de sample_submission.csv\n",
    "    sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    # Preparamos dataframe de test.\n",
    "    predictions_submit = model.predict(X)\n",
    "    submission = pd.DataFrame({\"id\": sample.id, \"days\": predictions_submit.ravel()})\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.8996            3.71m\n",
      "         2           1.8987            3.56m\n",
      "         3           1.8979            3.49m\n",
      "         4           1.8970            3.51m\n",
      "         5           1.8962            3.46m\n",
      "         6           1.8954            3.41m\n",
      "         7           1.8947            3.38m\n",
      "         8           1.8939            3.35m\n",
      "         9           1.8931            3.32m\n",
      "        10           1.8924            3.30m\n",
      "        11           1.8917            3.27m\n",
      "        12           1.8910            3.25m\n",
      "        13           1.8903            3.23m\n",
      "        14           1.8896            3.20m\n",
      "        15           1.8890            3.18m\n",
      "        16           1.8883            3.16m\n",
      "        17           1.8877            3.14m\n",
      "        18           1.8871            3.13m\n",
      "        19           1.8865            3.11m\n",
      "        20           1.8859            3.09m\n",
      "        21           1.8853            3.07m\n",
      "        22           1.8847            3.05m\n",
      "        23           1.8841            3.03m\n",
      "        24           1.8836            3.01m\n",
      "        25           1.8830            2.99m\n",
      "        26           1.8825            2.98m\n",
      "        27           1.8819            2.96m\n",
      "        28           1.8814            2.95m\n",
      "        29           1.8809            2.93m\n",
      "        30           1.8804            2.91m\n",
      "        31           1.8799            2.89m\n",
      "        32           1.8794            2.87m\n",
      "        33           1.8789            2.85m\n",
      "        34           1.8785            2.84m\n",
      "        35           1.8780            2.83m\n",
      "        36           1.8776            2.82m\n",
      "        37           1.8771            2.80m\n",
      "        38           1.8766            2.78m\n",
      "        39           1.8762            2.77m\n",
      "        40           1.8758            2.75m\n",
      "        41           1.8754            2.73m\n",
      "        42           1.8750            2.71m\n",
      "        43           1.8746            2.70m\n",
      "        44           1.8742            2.68m\n",
      "        45           1.8738            2.66m\n",
      "        46           1.8734            2.64m\n",
      "        47           1.8730            2.62m\n",
      "        48           1.8727            2.61m\n",
      "        49           1.8723            2.59m\n",
      "        50           1.8719            2.57m\n",
      "        51           1.8716            2.55m\n",
      "        52           1.8712            2.54m\n",
      "        53           1.8709            2.52m\n",
      "        54           1.8706            2.50m\n",
      "        55           1.8702            2.49m\n",
      "        56           1.8699            2.47m\n",
      "        57           1.8696            2.45m\n",
      "        58           1.8693            2.43m\n",
      "        59           1.8690            2.41m\n",
      "        60           1.8687            2.40m\n",
      "        61           1.8684            2.38m\n",
      "        62           1.8681            2.36m\n",
      "        63           1.8678            2.35m\n",
      "        64           1.8675            2.33m\n",
      "        65           1.8672            2.31m\n",
      "        66           1.8669            2.29m\n",
      "        67           1.8667            2.28m\n",
      "        68           1.8664            2.26m\n",
      "        69           1.8661            2.24m\n",
      "        70           1.8658            2.22m\n",
      "        71           1.8656            2.20m\n",
      "        72           1.8653            2.19m\n",
      "        73           1.8651            2.17m\n",
      "        74           1.8648            2.15m\n",
      "        75           1.8646            2.13m\n",
      "        76           1.8643            2.12m\n",
      "        77           1.8641            2.10m\n",
      "        78           1.8638            2.08m\n",
      "        79           1.8636            2.06m\n",
      "        80           1.8633            2.05m\n",
      "        81           1.8631            2.03m\n",
      "        82           1.8629            2.01m\n",
      "        83           1.8627            1.99m\n",
      "        84           1.8624            1.98m\n",
      "        85           1.8622            1.96m\n",
      "        86           1.8620            1.94m\n",
      "        87           1.8618            1.92m\n",
      "        88           1.8616            1.91m\n",
      "        89           1.8614            1.89m\n",
      "        90           1.8612            1.87m\n",
      "        91           1.8610            1.85m\n",
      "        92           1.8608            1.84m\n",
      "        93           1.8606            1.82m\n",
      "        94           1.8604            1.80m\n",
      "        95           1.8602            1.79m\n",
      "        96           1.8600            1.77m\n",
      "        97           1.8599            1.75m\n",
      "        98           1.8597            1.73m\n",
      "        99           1.8595            1.72m\n",
      "       100           1.8593            1.70m\n",
      "       101           1.8591            1.68m\n",
      "       102           1.8590            1.66m\n",
      "       103           1.8588            1.65m\n",
      "       104           1.8586            1.63m\n",
      "       105           1.8585            1.61m\n",
      "       106           1.8583            1.60m\n",
      "       107           1.8581            1.58m\n",
      "       108           1.8580            1.56m\n",
      "       109           1.8578            1.54m\n",
      "       110           1.8577            1.53m\n",
      "       111           1.8575            1.51m\n",
      "       112           1.8574            1.49m\n",
      "       113           1.8572            1.48m\n",
      "       114           1.8571            1.46m\n",
      "       115           1.8570            1.44m\n",
      "       116           1.8568            1.43m\n",
      "       117           1.8567            1.41m\n",
      "       118           1.8565            1.39m\n",
      "       119           1.8564            1.37m\n",
      "       120           1.8563            1.36m\n",
      "       121           1.8561            1.34m\n",
      "       122           1.8560            1.32m\n",
      "       123           1.8559            1.30m\n",
      "       124           1.8557            1.29m\n",
      "       125           1.8556            1.27m\n",
      "       126           1.8555            1.25m\n",
      "       127           1.8553            1.24m\n",
      "       128           1.8552            1.22m\n",
      "       129           1.8551            1.20m\n",
      "       130           1.8550            1.19m\n",
      "       131           1.8549            1.17m\n",
      "       132           1.8547            1.15m\n",
      "       133           1.8546            1.13m\n",
      "       134           1.8545            1.12m\n",
      "       135           1.8544            1.10m\n",
      "       136           1.8543            1.08m\n",
      "       137           1.8542            1.07m\n",
      "       138           1.8540            1.05m\n",
      "       139           1.8539            1.03m\n",
      "       140           1.8538            1.01m\n",
      "       141           1.8537           59.88s\n",
      "       142           1.8536           58.86s\n",
      "       143           1.8535           57.83s\n",
      "       144           1.8534           56.81s\n",
      "       145           1.8533           55.78s\n",
      "       146           1.8532           54.77s\n",
      "       147           1.8531           53.74s\n",
      "       148           1.8530           52.72s\n",
      "       149           1.8529           51.70s\n",
      "       150           1.8528           50.68s\n",
      "       151           1.8527           49.66s\n",
      "       152           1.8526           48.64s\n",
      "       153           1.8525           47.64s\n",
      "       154           1.8524           46.62s\n",
      "       155           1.8523           45.60s\n",
      "       156           1.8522           44.59s\n",
      "       157           1.8521           43.57s\n",
      "       158           1.8520           42.56s\n",
      "       159           1.8519           41.54s\n",
      "       160           1.8518           40.53s\n",
      "       161           1.8517           39.52s\n",
      "       162           1.8517           38.50s\n",
      "       163           1.8516           37.49s\n",
      "       164           1.8515           36.47s\n",
      "       165           1.8514           35.46s\n",
      "       166           1.8513           34.44s\n",
      "       167           1.8512           33.43s\n",
      "       168           1.8511           32.41s\n",
      "       169           1.8511           31.39s\n",
      "       170           1.8510           30.38s\n",
      "       171           1.8509           29.37s\n",
      "       172           1.8508           28.35s\n",
      "       173           1.8507           27.34s\n",
      "       174           1.8507           26.32s\n",
      "       175           1.8506           25.31s\n",
      "       176           1.8505           24.30s\n",
      "       177           1.8504           23.28s\n",
      "       178           1.8503           22.27s\n",
      "       179           1.8503           21.26s\n",
      "       180           1.8502           20.24s\n",
      "       181           1.8501           19.24s\n",
      "       182           1.8500           18.27s\n",
      "       183           1.8500           17.31s\n",
      "       184           1.8499           16.33s\n",
      "       185           1.8498           15.35s\n",
      "       186           1.8498           14.37s\n",
      "       187           1.8497           13.38s\n",
      "       188           1.8496           12.39s\n",
      "       189           1.8495           11.38s\n",
      "       190           1.8495           10.38s\n",
      "       191           1.8494            9.36s\n",
      "       192           1.8493            8.34s\n",
      "       193           1.8493            7.32s\n",
      "       194           1.8492            6.29s\n",
      "       195           1.8491            5.25s\n",
      "       196           1.8490            4.21s\n",
      "       197           1.8490            3.17s\n",
      "       198           1.8489            2.12s\n",
      "       199           1.8488            1.06s\n",
      "       200           1.8488            0.00s\n",
      "You're ready to submit!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] Se produjo un error durante el intento de conexiÃ³n ya que la parte conectada no respondiÃ³ adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexiÃ³n establecida ya que el host conectado no ha podido responder>",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1317\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1243\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    937\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 938\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    939\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] Se produjo un error durante el intento de conexiÃ³n ya que la parte conectada no respondiÃ³ adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexiÃ³n establecida ya que el host conectado no ha podido responder",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-df62835f0d03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mchequeator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-ae6e8bca7282>\u001b[0m in \u001b[0;36mchequeator\u001b[1;34m(df_to_submit)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You're ready to submit!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mdf_to_submit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#muy importante el index = False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gfg.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gfg.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1360\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1319\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] Se produjo un error durante el intento de conexiÃ³n ya que la parte conectada no respondiÃ³ adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexiÃ³n establecida ya que el host conectado no ha podido responder>"
     ]
    }
   ],
   "source": [
    "grad.fit(X, y)\n",
    "submission = prepare_test(grad, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "submission = prepare_test(grad, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "otal: 55.5s\tremaining: 25.7s\n",
      "820:\tlearn: 1.7416068\ttotal: 55.6s\tremaining: 25.6s\n",
      "821:\tlearn: 1.7415192\ttotal: 55.6s\tremaining: 25.6s\n",
      "822:\tlearn: 1.7414533\ttotal: 55.7s\tremaining: 25.5s\n",
      "823:\tlearn: 1.7413479\ttotal: 55.7s\tremaining: 25.4s\n",
      "824:\tlearn: 1.7413008\ttotal: 55.8s\tremaining: 25.4s\n",
      "825:\tlearn: 1.7412532\ttotal: 55.9s\tremaining: 25.3s\n",
      "826:\tlearn: 1.7411332\ttotal: 55.9s\tremaining: 25.2s\n",
      "827:\tlearn: 1.7410443\ttotal: 56s\tremaining: 25.2s\n",
      "828:\tlearn: 1.7409631\ttotal: 56.1s\tremaining: 25.1s\n",
      "829:\tlearn: 1.7409158\ttotal: 56.1s\tremaining: 25s\n",
      "830:\tlearn: 1.7408286\ttotal: 56.2s\tremaining: 25s\n",
      "831:\tlearn: 1.7407665\ttotal: 56.3s\tremaining: 24.9s\n",
      "832:\tlearn: 1.7407211\ttotal: 56.3s\tremaining: 24.8s\n",
      "833:\tlearn: 1.7406648\ttotal: 56.4s\tremaining: 24.7s\n",
      "834:\tlearn: 1.7405666\ttotal: 56.4s\tremaining: 24.7s\n",
      "835:\tlearn: 1.7405095\ttotal: 56.5s\tremaining: 24.6s\n",
      "836:\tlearn: 1.7404500\ttotal: 56.6s\tremaining: 24.5s\n",
      "837:\tlearn: 1.7403568\ttotal: 56.6s\tremaining: 24.5s\n",
      "838:\tlearn: 1.7403139\ttotal: 56.7s\tremaining: 24.4s\n",
      "839:\tlearn: 1.7402645\ttotal: 56.8s\tremaining: 24.3s\n",
      "840:\tlearn: 1.7402218\ttotal: 56.8s\tremaining: 24.3s\n",
      "841:\tlearn: 1.7401449\ttotal: 56.9s\tremaining: 24.2s\n",
      "842:\tlearn: 1.7401066\ttotal: 57s\tremaining: 24.1s\n",
      "843:\tlearn: 1.7400677\ttotal: 57s\tremaining: 24.1s\n",
      "844:\tlearn: 1.7399974\ttotal: 57.1s\tremaining: 24s\n",
      "845:\tlearn: 1.7399590\ttotal: 57.1s\tremaining: 23.9s\n",
      "846:\tlearn: 1.7399252\ttotal: 57.2s\tremaining: 23.8s\n",
      "847:\tlearn: 1.7398809\ttotal: 57.3s\tremaining: 23.8s\n",
      "848:\tlearn: 1.7398101\ttotal: 57.3s\tremaining: 23.7s\n",
      "849:\tlearn: 1.7397571\ttotal: 57.4s\tremaining: 23.6s\n",
      "850:\tlearn: 1.7397135\ttotal: 57.5s\tremaining: 23.6s\n",
      "851:\tlearn: 1.7396315\ttotal: 57.5s\tremaining: 23.5s\n",
      "852:\tlearn: 1.7395712\ttotal: 57.6s\tremaining: 23.4s\n",
      "853:\tlearn: 1.7394877\ttotal: 57.7s\tremaining: 23.4s\n",
      "854:\tlearn: 1.7394419\ttotal: 57.7s\tremaining: 23.3s\n",
      "855:\tlearn: 1.7393575\ttotal: 57.8s\tremaining: 23.2s\n",
      "856:\tlearn: 1.7392992\ttotal: 57.9s\tremaining: 23.2s\n",
      "857:\tlearn: 1.7392508\ttotal: 57.9s\tremaining: 23.1s\n",
      "858:\tlearn: 1.7391718\ttotal: 58s\tremaining: 23s\n",
      "859:\tlearn: 1.7391190\ttotal: 58s\tremaining: 22.9s\n",
      "860:\tlearn: 1.7390725\ttotal: 58.1s\tremaining: 22.9s\n",
      "861:\tlearn: 1.7390272\ttotal: 58.2s\tremaining: 22.8s\n",
      "862:\tlearn: 1.7389783\ttotal: 58.2s\tremaining: 22.7s\n",
      "863:\tlearn: 1.7388896\ttotal: 58.3s\tremaining: 22.7s\n",
      "864:\tlearn: 1.7388311\ttotal: 58.4s\tremaining: 22.6s\n",
      "865:\tlearn: 1.7387593\ttotal: 58.4s\tremaining: 22.5s\n",
      "866:\tlearn: 1.7387144\ttotal: 58.5s\tremaining: 22.5s\n",
      "867:\tlearn: 1.7386213\ttotal: 58.6s\tremaining: 22.4s\n",
      "868:\tlearn: 1.7385289\ttotal: 58.6s\tremaining: 22.3s\n",
      "869:\tlearn: 1.7384933\ttotal: 58.7s\tremaining: 22.3s\n",
      "870:\tlearn: 1.7384562\ttotal: 58.8s\tremaining: 22.2s\n",
      "871:\tlearn: 1.7384142\ttotal: 58.8s\tremaining: 22.1s\n",
      "872:\tlearn: 1.7383645\ttotal: 58.9s\tremaining: 22.1s\n",
      "873:\tlearn: 1.7382896\ttotal: 58.9s\tremaining: 22s\n",
      "874:\tlearn: 1.7382479\ttotal: 59s\tremaining: 21.9s\n",
      "875:\tlearn: 1.7381806\ttotal: 59.1s\tremaining: 21.8s\n",
      "876:\tlearn: 1.7381404\ttotal: 59.1s\tremaining: 21.8s\n",
      "877:\tlearn: 1.7380432\ttotal: 59.2s\tremaining: 21.7s\n",
      "878:\tlearn: 1.7379820\ttotal: 59.3s\tremaining: 21.6s\n",
      "879:\tlearn: 1.7379437\ttotal: 59.3s\tremaining: 21.6s\n",
      "880:\tlearn: 1.7379064\ttotal: 59.4s\tremaining: 21.5s\n",
      "881:\tlearn: 1.7378364\ttotal: 59.5s\tremaining: 21.4s\n",
      "882:\tlearn: 1.7377466\ttotal: 59.5s\tremaining: 21.4s\n",
      "883:\tlearn: 1.7376950\ttotal: 59.6s\tremaining: 21.3s\n",
      "884:\tlearn: 1.7376461\ttotal: 59.7s\tremaining: 21.2s\n",
      "885:\tlearn: 1.7375851\ttotal: 59.7s\tremaining: 21.2s\n",
      "886:\tlearn: 1.7375516\ttotal: 59.8s\tremaining: 21.1s\n",
      "887:\tlearn: 1.7375102\ttotal: 59.9s\tremaining: 21s\n",
      "888:\tlearn: 1.7374798\ttotal: 59.9s\tremaining: 21s\n",
      "889:\tlearn: 1.7373910\ttotal: 60s\tremaining: 20.9s\n",
      "890:\tlearn: 1.7373448\ttotal: 1m\tremaining: 20.8s\n",
      "891:\tlearn: 1.7372489\ttotal: 1m\tremaining: 20.8s\n",
      "892:\tlearn: 1.7371933\ttotal: 1m\tremaining: 20.7s\n",
      "893:\tlearn: 1.7371567\ttotal: 1m\tremaining: 20.6s\n",
      "894:\tlearn: 1.7370945\ttotal: 1m\tremaining: 20.6s\n",
      "895:\tlearn: 1.7370363\ttotal: 1m\tremaining: 20.5s\n",
      "896:\tlearn: 1.7370025\ttotal: 1m\tremaining: 20.4s\n",
      "897:\tlearn: 1.7369760\ttotal: 1m\tremaining: 20.3s\n",
      "898:\tlearn: 1.7369285\ttotal: 1m\tremaining: 20.3s\n",
      "899:\tlearn: 1.7368669\ttotal: 1m\tremaining: 20.2s\n",
      "900:\tlearn: 1.7367814\ttotal: 1m\tremaining: 20.1s\n",
      "901:\tlearn: 1.7366995\ttotal: 1m\tremaining: 20.1s\n",
      "902:\tlearn: 1.7366344\ttotal: 1m\tremaining: 20s\n",
      "903:\tlearn: 1.7365844\ttotal: 1m\tremaining: 19.9s\n",
      "904:\tlearn: 1.7365112\ttotal: 1m\tremaining: 19.9s\n",
      "905:\tlearn: 1.7364157\ttotal: 1m 1s\tremaining: 19.8s\n",
      "906:\tlearn: 1.7363292\ttotal: 1m 1s\tremaining: 19.7s\n",
      "907:\tlearn: 1.7362830\ttotal: 1m 1s\tremaining: 19.7s\n",
      "908:\tlearn: 1.7362171\ttotal: 1m 1s\tremaining: 19.6s\n",
      "909:\tlearn: 1.7361474\ttotal: 1m 1s\tremaining: 19.5s\n",
      "910:\tlearn: 1.7360870\ttotal: 1m 1s\tremaining: 19.5s\n",
      "911:\tlearn: 1.7360352\ttotal: 1m 1s\tremaining: 19.4s\n",
      "912:\tlearn: 1.7359753\ttotal: 1m 1s\tremaining: 19.3s\n",
      "913:\tlearn: 1.7359177\ttotal: 1m 1s\tremaining: 19.2s\n",
      "914:\tlearn: 1.7358142\ttotal: 1m 1s\tremaining: 19.2s\n",
      "915:\tlearn: 1.7357485\ttotal: 1m 1s\tremaining: 19.1s\n",
      "916:\tlearn: 1.7357120\ttotal: 1m 1s\tremaining: 19s\n",
      "917:\tlearn: 1.7356742\ttotal: 1m 1s\tremaining: 19s\n",
      "918:\tlearn: 1.7356121\ttotal: 1m 1s\tremaining: 18.9s\n",
      "919:\tlearn: 1.7355417\ttotal: 1m 1s\tremaining: 18.8s\n",
      "920:\tlearn: 1.7354654\ttotal: 1m 1s\tremaining: 18.8s\n",
      "921:\tlearn: 1.7353876\ttotal: 1m 2s\tremaining: 18.7s\n",
      "922:\tlearn: 1.7353052\ttotal: 1m 2s\tremaining: 18.6s\n",
      "923:\tlearn: 1.7352361\ttotal: 1m 2s\tremaining: 18.6s\n",
      "924:\tlearn: 1.7351479\ttotal: 1m 2s\tremaining: 18.5s\n",
      "925:\tlearn: 1.7350638\ttotal: 1m 2s\tremaining: 18.4s\n",
      "926:\tlearn: 1.7350019\ttotal: 1m 2s\tremaining: 18.4s\n",
      "927:\tlearn: 1.7349565\ttotal: 1m 2s\tremaining: 18.3s\n",
      "928:\tlearn: 1.7348693\ttotal: 1m 2s\tremaining: 18.2s\n",
      "929:\tlearn: 1.7348081\ttotal: 1m 2s\tremaining: 18.2s\n",
      "930:\tlearn: 1.7347721\ttotal: 1m 2s\tremaining: 18.1s\n",
      "931:\tlearn: 1.7347004\ttotal: 1m 2s\tremaining: 18s\n",
      "932:\tlearn: 1.7346005\ttotal: 1m 2s\tremaining: 17.9s\n",
      "933:\tlearn: 1.7345366\ttotal: 1m 2s\tremaining: 17.9s\n",
      "934:\tlearn: 1.7344537\ttotal: 1m 2s\tremaining: 17.8s\n",
      "935:\tlearn: 1.7343899\ttotal: 1m 2s\tremaining: 17.7s\n",
      "936:\tlearn: 1.7343215\ttotal: 1m 2s\tremaining: 17.7s\n",
      "937:\tlearn: 1.7342619\ttotal: 1m 3s\tremaining: 17.6s\n",
      "938:\tlearn: 1.7342029\ttotal: 1m 3s\tremaining: 17.5s\n",
      "939:\tlearn: 1.7341411\ttotal: 1m 3s\tremaining: 17.5s\n",
      "940:\tlearn: 1.7341051\ttotal: 1m 3s\tremaining: 17.4s\n",
      "941:\tlearn: 1.7340721\ttotal: 1m 3s\tremaining: 17.3s\n",
      "942:\tlearn: 1.7340017\ttotal: 1m 3s\tremaining: 17.3s\n",
      "943:\tlearn: 1.7339504\ttotal: 1m 3s\tremaining: 17.2s\n",
      "944:\tlearn: 1.7338561\ttotal: 1m 3s\tremaining: 17.1s\n",
      "945:\tlearn: 1.7338020\ttotal: 1m 3s\tremaining: 17.1s\n",
      "946:\tlearn: 1.7337217\ttotal: 1m 3s\tremaining: 17s\n",
      "947:\tlearn: 1.7336300\ttotal: 1m 3s\tremaining: 16.9s\n",
      "948:\tlearn: 1.7335496\ttotal: 1m 3s\tremaining: 16.9s\n",
      "949:\tlearn: 1.7335058\ttotal: 1m 3s\tremaining: 16.8s\n",
      "950:\tlearn: 1.7334680\ttotal: 1m 3s\tremaining: 16.7s\n",
      "951:\tlearn: 1.7334004\ttotal: 1m 3s\tremaining: 16.7s\n",
      "952:\tlearn: 1.7333657\ttotal: 1m 3s\tremaining: 16.6s\n",
      "953:\tlearn: 1.7333071\ttotal: 1m 4s\tremaining: 16.5s\n",
      "954:\tlearn: 1.7332678\ttotal: 1m 4s\tremaining: 16.5s\n",
      "955:\tlearn: 1.7332139\ttotal: 1m 4s\tremaining: 16.4s\n",
      "956:\tlearn: 1.7331721\ttotal: 1m 4s\tremaining: 16.3s\n",
      "957:\tlearn: 1.7330992\ttotal: 1m 4s\tremaining: 16.2s\n",
      "958:\tlearn: 1.7330667\ttotal: 1m 4s\tremaining: 16.2s\n",
      "959:\tlearn: 1.7329863\ttotal: 1m 4s\tremaining: 16.1s\n",
      "960:\tlearn: 1.7329428\ttotal: 1m 4s\tremaining: 16s\n",
      "961:\tlearn: 1.7329005\ttotal: 1m 4s\tremaining: 16s\n",
      "962:\tlearn: 1.7328341\ttotal: 1m 4s\tremaining: 15.9s\n",
      "963:\tlearn: 1.7327996\ttotal: 1m 4s\tremaining: 15.8s\n",
      "964:\tlearn: 1.7327555\ttotal: 1m 4s\tremaining: 15.8s\n",
      "965:\tlearn: 1.7327044\ttotal: 1m 4s\tremaining: 15.7s\n",
      "966:\tlearn: 1.7326459\ttotal: 1m 4s\tremaining: 15.6s\n",
      "967:\tlearn: 1.7325850\ttotal: 1m 4s\tremaining: 15.6s\n",
      "968:\tlearn: 1.7324970\ttotal: 1m 5s\tremaining: 15.5s\n",
      "969:\tlearn: 1.7324436\ttotal: 1m 5s\tremaining: 15.4s\n",
      "970:\tlearn: 1.7323652\ttotal: 1m 5s\tremaining: 15.4s\n",
      "971:\tlearn: 1.7323029\ttotal: 1m 5s\tremaining: 15.3s\n",
      "972:\tlearn: 1.7322489\ttotal: 1m 5s\tremaining: 15.2s\n",
      "973:\tlearn: 1.7322115\ttotal: 1m 5s\tremaining: 15.2s\n",
      "974:\tlearn: 1.7321728\ttotal: 1m 5s\tremaining: 15.1s\n",
      "975:\tlearn: 1.7320711\ttotal: 1m 5s\tremaining: 15s\n",
      "976:\tlearn: 1.7319981\ttotal: 1m 5s\tremaining: 15s\n",
      "977:\tlearn: 1.7319274\ttotal: 1m 5s\tremaining: 14.9s\n",
      "978:\tlearn: 1.7318697\ttotal: 1m 5s\tremaining: 14.8s\n",
      "979:\tlearn: 1.7318029\ttotal: 1m 5s\tremaining: 14.8s\n",
      "980:\tlearn: 1.7317310\ttotal: 1m 5s\tremaining: 14.7s\n",
      "981:\tlearn: 1.7316841\ttotal: 1m 5s\tremaining: 14.6s\n",
      "982:\tlearn: 1.7316423\ttotal: 1m 5s\tremaining: 14.6s\n",
      "983:\tlearn: 1.7315980\ttotal: 1m 5s\tremaining: 14.5s\n",
      "984:\tlearn: 1.7315420\ttotal: 1m 6s\tremaining: 14.4s\n",
      "985:\tlearn: 1.7314958\ttotal: 1m 6s\tremaining: 14.3s\n",
      "986:\tlearn: 1.7314478\ttotal: 1m 6s\tremaining: 14.3s\n",
      "987:\tlearn: 1.7313957\ttotal: 1m 6s\tremaining: 14.2s\n",
      "988:\tlearn: 1.7313449\ttotal: 1m 6s\tremaining: 14.1s\n",
      "989:\tlearn: 1.7312784\ttotal: 1m 6s\tremaining: 14.1s\n",
      "990:\tlearn: 1.7312236\ttotal: 1m 6s\tremaining: 14s\n",
      "991:\tlearn: 1.7311284\ttotal: 1m 6s\tremaining: 13.9s\n",
      "992:\tlearn: 1.7310554\ttotal: 1m 6s\tremaining: 13.9s\n",
      "993:\tlearn: 1.7310106\ttotal: 1m 6s\tremaining: 13.8s\n",
      "994:\tlearn: 1.7309620\ttotal: 1m 6s\tremaining: 13.7s\n",
      "995:\tlearn: 1.7308741\ttotal: 1m 6s\tremaining: 13.7s\n",
      "996:\tlearn: 1.7308216\ttotal: 1m 6s\tremaining: 13.6s\n",
      "997:\tlearn: 1.7307731\ttotal: 1m 6s\tremaining: 13.5s\n",
      "998:\tlearn: 1.7307275\ttotal: 1m 6s\tremaining: 13.5s\n",
      "999:\tlearn: 1.7306519\ttotal: 1m 6s\tremaining: 13.4s\n",
      "1000:\tlearn: 1.7306163\ttotal: 1m 7s\tremaining: 13.3s\n",
      "1001:\tlearn: 1.7305773\ttotal: 1m 7s\tremaining: 13.3s\n",
      "1002:\tlearn: 1.7305024\ttotal: 1m 7s\tremaining: 13.2s\n",
      "1003:\tlearn: 1.7304060\ttotal: 1m 7s\tremaining: 13.1s\n",
      "1004:\tlearn: 1.7303338\ttotal: 1m 7s\tremaining: 13.1s\n",
      "1005:\tlearn: 1.7302770\ttotal: 1m 7s\tremaining: 13s\n",
      "1006:\tlearn: 1.7302498\ttotal: 1m 7s\tremaining: 12.9s\n",
      "1007:\tlearn: 1.7301947\ttotal: 1m 7s\tremaining: 12.9s\n",
      "1008:\tlearn: 1.7301142\ttotal: 1m 7s\tremaining: 12.8s\n",
      "1009:\tlearn: 1.7300521\ttotal: 1m 7s\tremaining: 12.7s\n",
      "1010:\tlearn: 1.7299779\ttotal: 1m 7s\tremaining: 12.7s\n",
      "1011:\tlearn: 1.7298889\ttotal: 1m 7s\tremaining: 12.6s\n",
      "1012:\tlearn: 1.7298222\ttotal: 1m 7s\tremaining: 12.5s\n",
      "1013:\tlearn: 1.7297790\ttotal: 1m 7s\tremaining: 12.5s\n",
      "1014:\tlearn: 1.7297148\ttotal: 1m 7s\tremaining: 12.4s\n",
      "1015:\tlearn: 1.7296525\ttotal: 1m 8s\tremaining: 12.3s\n",
      "1016:\tlearn: 1.7296053\ttotal: 1m 8s\tremaining: 12.3s\n",
      "1017:\tlearn: 1.7295359\ttotal: 1m 8s\tremaining: 12.2s\n",
      "1018:\tlearn: 1.7294885\ttotal: 1m 8s\tremaining: 12.1s\n",
      "1019:\tlearn: 1.7294424\ttotal: 1m 8s\tremaining: 12s\n",
      "1020:\tlearn: 1.7293572\ttotal: 1m 8s\tremaining: 12s\n",
      "1021:\tlearn: 1.7292931\ttotal: 1m 8s\tremaining: 11.9s\n",
      "1022:\tlearn: 1.7292625\ttotal: 1m 8s\tremaining: 11.8s\n",
      "1023:\tlearn: 1.7291860\ttotal: 1m 8s\tremaining: 11.8s\n",
      "1024:\tlearn: 1.7291029\ttotal: 1m 8s\tremaining: 11.7s\n",
      "1025:\tlearn: 1.7290622\ttotal: 1m 8s\tremaining: 11.6s\n",
      "1026:\tlearn: 1.7289991\ttotal: 1m 8s\tremaining: 11.6s\n",
      "1027:\tlearn: 1.7289615\ttotal: 1m 8s\tremaining: 11.5s\n",
      "1028:\tlearn: 1.7288907\ttotal: 1m 8s\tremaining: 11.4s\n",
      "1029:\tlearn: 1.7288279\ttotal: 1m 8s\tremaining: 11.4s\n",
      "1030:\tlearn: 1.7287761\ttotal: 1m 8s\tremaining: 11.3s\n",
      "1031:\tlearn: 1.7286907\ttotal: 1m 9s\tremaining: 11.2s\n",
      "1032:\tlearn: 1.7286065\ttotal: 1m 9s\tremaining: 11.2s\n",
      "1033:\tlearn: 1.7285566\ttotal: 1m 9s\tremaining: 11.1s\n",
      "1034:\tlearn: 1.7284688\ttotal: 1m 9s\tremaining: 11s\n",
      "1035:\tlearn: 1.7284252\ttotal: 1m 9s\tremaining: 11s\n",
      "1036:\tlearn: 1.7283792\ttotal: 1m 9s\tremaining: 10.9s\n",
      "1037:\tlearn: 1.7283640\ttotal: 1m 9s\tremaining: 10.8s\n",
      "1038:\tlearn: 1.7283239\ttotal: 1m 9s\tremaining: 10.8s\n",
      "1039:\tlearn: 1.7282369\ttotal: 1m 9s\tremaining: 10.7s\n",
      "1040:\tlearn: 1.7281928\ttotal: 1m 9s\tremaining: 10.6s\n",
      "1041:\tlearn: 1.7281537\ttotal: 1m 9s\tremaining: 10.6s\n",
      "1042:\tlearn: 1.7280988\ttotal: 1m 9s\tremaining: 10.5s\n",
      "1043:\tlearn: 1.7280290\ttotal: 1m 9s\tremaining: 10.4s\n",
      "1044:\tlearn: 1.7279705\ttotal: 1m 9s\tremaining: 10.4s\n",
      "1045:\tlearn: 1.7279037\ttotal: 1m 9s\tremaining: 10.3s\n",
      "1046:\tlearn: 1.7278375\ttotal: 1m 10s\tremaining: 10.2s\n",
      "1047:\tlearn: 1.7277590\ttotal: 1m 10s\tremaining: 10.2s\n",
      "1048:\tlearn: 1.7277232\ttotal: 1m 10s\tremaining: 10.1s\n",
      "1049:\tlearn: 1.7276641\ttotal: 1m 10s\tremaining: 10s\n",
      "1050:\tlearn: 1.7276351\ttotal: 1m 10s\tremaining: 9.96s\n",
      "1051:\tlearn: 1.7275689\ttotal: 1m 10s\tremaining: 9.89s\n",
      "1052:\tlearn: 1.7275188\ttotal: 1m 10s\tremaining: 9.83s\n",
      "1053:\tlearn: 1.7274432\ttotal: 1m 10s\tremaining: 9.76s\n",
      "1054:\tlearn: 1.7273722\ttotal: 1m 10s\tremaining: 9.69s\n",
      "1055:\tlearn: 1.7273194\ttotal: 1m 10s\tremaining: 9.63s\n",
      "1056:\tlearn: 1.7272709\ttotal: 1m 10s\tremaining: 9.56s\n",
      "1057:\tlearn: 1.7271893\ttotal: 1m 10s\tremaining: 9.49s\n",
      "1058:\tlearn: 1.7271422\ttotal: 1m 10s\tremaining: 9.42s\n",
      "1059:\tlearn: 1.7270728\ttotal: 1m 10s\tremaining: 9.36s\n",
      "1060:\tlearn: 1.7270421\ttotal: 1m 10s\tremaining: 9.29s\n",
      "1061:\tlearn: 1.7269720\ttotal: 1m 10s\tremaining: 9.22s\n",
      "1062:\tlearn: 1.7269182\ttotal: 1m 11s\tremaining: 9.15s\n",
      "1063:\tlearn: 1.7268938\ttotal: 1m 11s\tremaining: 9.09s\n",
      "1064:\tlearn: 1.7268357\ttotal: 1m 11s\tremaining: 9.02s\n",
      "1065:\tlearn: 1.7267577\ttotal: 1m 11s\tremaining: 8.95s\n",
      "1066:\tlearn: 1.7267037\ttotal: 1m 11s\tremaining: 8.89s\n",
      "1067:\tlearn: 1.7266542\ttotal: 1m 11s\tremaining: 8.82s\n",
      "1068:\tlearn: 1.7266193\ttotal: 1m 11s\tremaining: 8.75s\n",
      "1069:\tlearn: 1.7265822\ttotal: 1m 11s\tremaining: 8.69s\n",
      "1070:\tlearn: 1.7265481\ttotal: 1m 11s\tremaining: 8.62s\n",
      "1071:\tlearn: 1.7264880\ttotal: 1m 11s\tremaining: 8.55s\n",
      "1072:\tlearn: 1.7264299\ttotal: 1m 11s\tremaining: 8.48s\n",
      "1073:\tlearn: 1.7263854\ttotal: 1m 11s\tremaining: 8.42s\n",
      "1074:\tlearn: 1.7263647\ttotal: 1m 11s\tremaining: 8.35s\n",
      "1075:\tlearn: 1.7262941\ttotal: 1m 11s\tremaining: 8.28s\n",
      "1076:\tlearn: 1.7262496\ttotal: 1m 11s\tremaining: 8.21s\n",
      "1077:\tlearn: 1.7262103\ttotal: 1m 11s\tremaining: 8.15s\n",
      "1078:\tlearn: 1.7261489\ttotal: 1m 12s\tremaining: 8.08s\n",
      "1079:\tlearn: 1.7261082\ttotal: 1m 12s\tremaining: 8.01s\n",
      "1080:\tlearn: 1.7260787\ttotal: 1m 12s\tremaining: 7.95s\n",
      "1081:\tlearn: 1.7260326\ttotal: 1m 12s\tremaining: 7.88s\n",
      "1082:\tlearn: 1.7259762\ttotal: 1m 12s\tremaining: 7.81s\n",
      "1083:\tlearn: 1.7259246\ttotal: 1m 12s\tremaining: 7.74s\n",
      "1084:\tlearn: 1.7258809\ttotal: 1m 12s\tremaining: 7.68s\n",
      "1085:\tlearn: 1.7258031\ttotal: 1m 12s\tremaining: 7.61s\n",
      "1086:\tlearn: 1.7257479\ttotal: 1m 12s\tremaining: 7.54s\n",
      "1087:\tlearn: 1.7257011\ttotal: 1m 12s\tremaining: 7.48s\n",
      "1088:\tlearn: 1.7256635\ttotal: 1m 12s\tremaining: 7.41s\n",
      "1089:\tlearn: 1.7256190\ttotal: 1m 12s\tremaining: 7.34s\n",
      "1090:\tlearn: 1.7255756\ttotal: 1m 12s\tremaining: 7.28s\n",
      "1091:\tlearn: 1.7254989\ttotal: 1m 12s\tremaining: 7.21s\n",
      "1092:\tlearn: 1.7254315\ttotal: 1m 12s\tremaining: 7.14s\n",
      "1093:\tlearn: 1.7253929\ttotal: 1m 13s\tremaining: 7.07s\n",
      "1094:\tlearn: 1.7253481\ttotal: 1m 13s\tremaining: 7.01s\n",
      "1095:\tlearn: 1.7252993\ttotal: 1m 13s\tremaining: 6.94s\n",
      "1096:\tlearn: 1.7252350\ttotal: 1m 13s\tremaining: 6.87s\n",
      "1097:\tlearn: 1.7252085\ttotal: 1m 13s\tremaining: 6.81s\n",
      "1098:\tlearn: 1.7251304\ttotal: 1m 13s\tremaining: 6.74s\n",
      "1099:\tlearn: 1.7250712\ttotal: 1m 13s\tremaining: 6.67s\n",
      "1100:\tlearn: 1.7250359\ttotal: 1m 13s\tremaining: 6.61s\n",
      "1101:\tlearn: 1.7249389\ttotal: 1m 13s\tremaining: 6.54s\n",
      "1102:\tlearn: 1.7249021\ttotal: 1m 13s\tremaining: 6.47s\n",
      "1103:\tlearn: 1.7248673\ttotal: 1m 13s\tremaining: 6.4s\n",
      "1104:\tlearn: 1.7248089\ttotal: 1m 13s\tremaining: 6.34s\n",
      "1105:\tlearn: 1.7247730\ttotal: 1m 13s\tremaining: 6.27s\n",
      "1106:\tlearn: 1.7247041\ttotal: 1m 13s\tremaining: 6.2s\n",
      "1107:\tlearn: 1.7246596\ttotal: 1m 13s\tremaining: 6.14s\n",
      "1108:\tlearn: 1.7246229\ttotal: 1m 13s\tremaining: 6.07s\n",
      "1109:\tlearn: 1.7245909\ttotal: 1m 14s\tremaining: 6s\n",
      "1110:\tlearn: 1.7245448\ttotal: 1m 14s\tremaining: 5.94s\n",
      "1111:\tlearn: 1.7244900\ttotal: 1m 14s\tremaining: 5.87s\n",
      "1112:\tlearn: 1.7244416\ttotal: 1m 14s\tremaining: 5.8s\n",
      "1113:\tlearn: 1.7243831\ttotal: 1m 14s\tremaining: 5.74s\n",
      "1114:\tlearn: 1.7243267\ttotal: 1m 14s\tremaining: 5.67s\n",
      "1115:\tlearn: 1.7242587\ttotal: 1m 14s\tremaining: 5.6s\n",
      "1116:\tlearn: 1.7241664\ttotal: 1m 14s\tremaining: 5.53s\n",
      "1117:\tlearn: 1.7240775\ttotal: 1m 14s\tremaining: 5.47s\n",
      "1118:\tlearn: 1.7240146\ttotal: 1m 14s\tremaining: 5.4s\n",
      "1119:\tlearn: 1.7239278\ttotal: 1m 14s\tremaining: 5.33s\n",
      "1120:\tlearn: 1.7238853\ttotal: 1m 14s\tremaining: 5.27s\n",
      "1121:\tlearn: 1.7238127\ttotal: 1m 14s\tremaining: 5.2s\n",
      "1122:\tlearn: 1.7237774\ttotal: 1m 14s\tremaining: 5.13s\n",
      "1123:\tlearn: 1.7237208\ttotal: 1m 14s\tremaining: 5.07s\n",
      "1124:\tlearn: 1.7236789\ttotal: 1m 14s\tremaining: 5s\n",
      "1125:\tlearn: 1.7236141\ttotal: 1m 15s\tremaining: 4.93s\n",
      "1126:\tlearn: 1.7235677\ttotal: 1m 15s\tremaining: 4.87s\n",
      "1127:\tlearn: 1.7235267\ttotal: 1m 15s\tremaining: 4.8s\n",
      "1128:\tlearn: 1.7234607\ttotal: 1m 15s\tremaining: 4.73s\n",
      "1129:\tlearn: 1.7234299\ttotal: 1m 15s\tremaining: 4.67s\n",
      "1130:\tlearn: 1.7233800\ttotal: 1m 15s\tremaining: 4.6s\n",
      "1131:\tlearn: 1.7233124\ttotal: 1m 15s\tremaining: 4.53s\n",
      "1132:\tlearn: 1.7232681\ttotal: 1m 15s\tremaining: 4.46s\n",
      "1133:\tlearn: 1.7232113\ttotal: 1m 15s\tremaining: 4.4s\n",
      "1134:\tlearn: 1.7231215\ttotal: 1m 15s\tremaining: 4.33s\n",
      "1135:\tlearn: 1.7230653\ttotal: 1m 15s\tremaining: 4.26s\n",
      "1136:\tlearn: 1.7229883\ttotal: 1m 15s\tremaining: 4.2s\n",
      "1137:\tlearn: 1.7229350\ttotal: 1m 15s\tremaining: 4.13s\n",
      "1138:\tlearn: 1.7228493\ttotal: 1m 15s\tremaining: 4.06s\n",
      "1139:\tlearn: 1.7227899\ttotal: 1m 15s\tremaining: 4s\n",
      "1140:\tlearn: 1.7227172\ttotal: 1m 16s\tremaining: 3.93s\n",
      "1141:\tlearn: 1.7226219\ttotal: 1m 16s\tremaining: 3.86s\n",
      "1142:\tlearn: 1.7225502\ttotal: 1m 16s\tremaining: 3.8s\n",
      "1143:\tlearn: 1.7224984\ttotal: 1m 16s\tremaining: 3.73s\n",
      "1144:\tlearn: 1.7224847\ttotal: 1m 16s\tremaining: 3.66s\n",
      "1145:\tlearn: 1.7224506\ttotal: 1m 16s\tremaining: 3.6s\n",
      "1146:\tlearn: 1.7224072\ttotal: 1m 16s\tremaining: 3.53s\n",
      "1147:\tlearn: 1.7223651\ttotal: 1m 16s\tremaining: 3.46s\n",
      "1148:\tlearn: 1.7223175\ttotal: 1m 16s\tremaining: 3.4s\n",
      "1149:\tlearn: 1.7222519\ttotal: 1m 16s\tremaining: 3.33s\n",
      "1150:\tlearn: 1.7221983\ttotal: 1m 16s\tremaining: 3.26s\n",
      "1151:\tlearn: 1.7221321\ttotal: 1m 16s\tremaining: 3.2s\n",
      "1152:\tlearn: 1.7220946\ttotal: 1m 16s\tremaining: 3.13s\n",
      "1153:\tlearn: 1.7220425\ttotal: 1m 16s\tremaining: 3.06s\n",
      "1154:\tlearn: 1.7220080\ttotal: 1m 16s\tremaining: 3s\n",
      "1155:\tlearn: 1.7219392\ttotal: 1m 16s\tremaining: 2.93s\n",
      "1156:\tlearn: 1.7218892\ttotal: 1m 17s\tremaining: 2.86s\n",
      "1157:\tlearn: 1.7218251\ttotal: 1m 17s\tremaining: 2.8s\n",
      "1158:\tlearn: 1.7217640\ttotal: 1m 17s\tremaining: 2.73s\n",
      "1159:\tlearn: 1.7217131\ttotal: 1m 17s\tremaining: 2.66s\n",
      "1160:\tlearn: 1.7216712\ttotal: 1m 17s\tremaining: 2.6s\n",
      "1161:\tlearn: 1.7215973\ttotal: 1m 17s\tremaining: 2.53s\n",
      "1162:\tlearn: 1.7215499\ttotal: 1m 17s\tremaining: 2.46s\n",
      "1163:\tlearn: 1.7215077\ttotal: 1m 17s\tremaining: 2.4s\n",
      "1164:\tlearn: 1.7214402\ttotal: 1m 17s\tremaining: 2.33s\n",
      "1165:\tlearn: 1.7214044\ttotal: 1m 17s\tremaining: 2.26s\n",
      "1166:\tlearn: 1.7213193\ttotal: 1m 17s\tremaining: 2.2s\n",
      "1167:\tlearn: 1.7212812\ttotal: 1m 17s\tremaining: 2.13s\n",
      "1168:\tlearn: 1.7212263\ttotal: 1m 17s\tremaining: 2.06s\n",
      "1169:\tlearn: 1.7211647\ttotal: 1m 17s\tremaining: 2s\n",
      "1170:\tlearn: 1.7210647\ttotal: 1m 17s\tremaining: 1.93s\n",
      "1171:\tlearn: 1.7210474\ttotal: 1m 17s\tremaining: 1.86s\n",
      "1172:\tlearn: 1.7210071\ttotal: 1m 18s\tremaining: 1.8s\n",
      "1173:\tlearn: 1.7209745\ttotal: 1m 18s\tremaining: 1.73s\n",
      "1174:\tlearn: 1.7208768\ttotal: 1m 18s\tremaining: 1.66s\n",
      "1175:\tlearn: 1.7207891\ttotal: 1m 18s\tremaining: 1.6s\n",
      "1176:\tlearn: 1.7207172\ttotal: 1m 18s\tremaining: 1.53s\n",
      "1177:\tlearn: 1.7206689\ttotal: 1m 18s\tremaining: 1.46s\n",
      "1178:\tlearn: 1.7206312\ttotal: 1m 18s\tremaining: 1.4s\n",
      "1179:\tlearn: 1.7205637\ttotal: 1m 18s\tremaining: 1.33s\n",
      "1180:\tlearn: 1.7205219\ttotal: 1m 18s\tremaining: 1.26s\n",
      "1181:\tlearn: 1.7204506\ttotal: 1m 18s\tremaining: 1.2s\n",
      "1182:\tlearn: 1.7204078\ttotal: 1m 18s\tremaining: 1.13s\n",
      "1183:\tlearn: 1.7203732\ttotal: 1m 18s\tremaining: 1.06s\n",
      "1184:\tlearn: 1.7203376\ttotal: 1m 18s\tremaining: 998ms\n",
      "1185:\tlearn: 1.7202737\ttotal: 1m 18s\tremaining: 931ms\n",
      "1186:\tlearn: 1.7202294\ttotal: 1m 18s\tremaining: 865ms\n",
      "1187:\tlearn: 1.7201704\ttotal: 1m 19s\tremaining: 798ms\n",
      "1188:\tlearn: 1.7201054\ttotal: 1m 19s\tremaining: 732ms\n",
      "1189:\tlearn: 1.7200577\ttotal: 1m 19s\tremaining: 665ms\n",
      "1190:\tlearn: 1.7200237\ttotal: 1m 19s\tremaining: 598ms\n",
      "1191:\tlearn: 1.7199894\ttotal: 1m 19s\tremaining: 532ms\n",
      "1192:\tlearn: 1.7199224\ttotal: 1m 19s\tremaining: 465ms\n",
      "1193:\tlearn: 1.7198427\ttotal: 1m 19s\tremaining: 399ms\n",
      "1194:\tlearn: 1.7198005\ttotal: 1m 19s\tremaining: 332ms\n",
      "1195:\tlearn: 1.7197699\ttotal: 1m 19s\tremaining: 266ms\n",
      "1196:\tlearn: 1.7197379\ttotal: 1m 19s\tremaining: 199ms\n",
      "1197:\tlearn: 1.7196649\ttotal: 1m 19s\tremaining: 133ms\n",
      "1198:\tlearn: 1.7196350\ttotal: 1m 19s\tremaining: 66.5ms\n",
      "1199:\tlearn: 1.7195961\ttotal: 1m 19s\tremaining: 0us\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'prepare_test' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f150ea1e3066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwildcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwildcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mchequeator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_test' is not defined"
     ]
    }
   ],
   "source": [
    "wildcat.fit(X, y)\n",
    "submission = prepare_test(wildcat, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "submission = prepare_test(wildcat, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jgnsa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[16:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X, y)\n",
    "submission = prepare_test(xgb, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "forest_gump.fit(X, y)\n",
    "submission = prepare_test(forest_gump, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tremaining: 32.5s\n",
      "841:\tlearn: 1.7401449\ttotal: 1m 16s\tremaining: 32.4s\n",
      "842:\tlearn: 1.7401066\ttotal: 1m 16s\tremaining: 32.3s\n",
      "843:\tlearn: 1.7400677\ttotal: 1m 16s\tremaining: 32.2s\n",
      "844:\tlearn: 1.7399974\ttotal: 1m 16s\tremaining: 32.1s\n",
      "845:\tlearn: 1.7399590\ttotal: 1m 16s\tremaining: 32s\n",
      "846:\tlearn: 1.7399252\ttotal: 1m 16s\tremaining: 31.9s\n",
      "847:\tlearn: 1.7398809\ttotal: 1m 16s\tremaining: 31.8s\n",
      "848:\tlearn: 1.7398101\ttotal: 1m 16s\tremaining: 31.7s\n",
      "849:\tlearn: 1.7397571\ttotal: 1m 16s\tremaining: 31.6s\n",
      "850:\tlearn: 1.7397135\ttotal: 1m 16s\tremaining: 31.5s\n",
      "851:\tlearn: 1.7396315\ttotal: 1m 16s\tremaining: 31.4s\n",
      "852:\tlearn: 1.7395712\ttotal: 1m 17s\tremaining: 31.4s\n",
      "853:\tlearn: 1.7394877\ttotal: 1m 17s\tremaining: 31.3s\n",
      "854:\tlearn: 1.7394419\ttotal: 1m 17s\tremaining: 31.2s\n",
      "855:\tlearn: 1.7393575\ttotal: 1m 17s\tremaining: 31.1s\n",
      "856:\tlearn: 1.7392992\ttotal: 1m 17s\tremaining: 31s\n",
      "857:\tlearn: 1.7392508\ttotal: 1m 17s\tremaining: 30.9s\n",
      "858:\tlearn: 1.7391718\ttotal: 1m 17s\tremaining: 30.8s\n",
      "859:\tlearn: 1.7391190\ttotal: 1m 17s\tremaining: 30.7s\n",
      "860:\tlearn: 1.7390725\ttotal: 1m 17s\tremaining: 30.6s\n",
      "861:\tlearn: 1.7390272\ttotal: 1m 17s\tremaining: 30.5s\n",
      "862:\tlearn: 1.7389783\ttotal: 1m 17s\tremaining: 30.4s\n",
      "863:\tlearn: 1.7388896\ttotal: 1m 17s\tremaining: 30.3s\n",
      "864:\tlearn: 1.7388311\ttotal: 1m 17s\tremaining: 30.2s\n",
      "865:\tlearn: 1.7387593\ttotal: 1m 18s\tremaining: 30.1s\n",
      "866:\tlearn: 1.7387144\ttotal: 1m 18s\tremaining: 30s\n",
      "867:\tlearn: 1.7386213\ttotal: 1m 18s\tremaining: 29.9s\n",
      "868:\tlearn: 1.7385289\ttotal: 1m 18s\tremaining: 29.8s\n",
      "869:\tlearn: 1.7384933\ttotal: 1m 18s\tremaining: 29.7s\n",
      "870:\tlearn: 1.7384562\ttotal: 1m 18s\tremaining: 29.6s\n",
      "871:\tlearn: 1.7384142\ttotal: 1m 18s\tremaining: 29.5s\n",
      "872:\tlearn: 1.7383645\ttotal: 1m 18s\tremaining: 29.4s\n",
      "873:\tlearn: 1.7382896\ttotal: 1m 18s\tremaining: 29.3s\n",
      "874:\tlearn: 1.7382479\ttotal: 1m 18s\tremaining: 29.2s\n",
      "875:\tlearn: 1.7381806\ttotal: 1m 18s\tremaining: 29.1s\n",
      "876:\tlearn: 1.7381404\ttotal: 1m 18s\tremaining: 29s\n",
      "877:\tlearn: 1.7380432\ttotal: 1m 18s\tremaining: 29s\n",
      "878:\tlearn: 1.7379820\ttotal: 1m 19s\tremaining: 28.9s\n",
      "879:\tlearn: 1.7379437\ttotal: 1m 19s\tremaining: 28.8s\n",
      "880:\tlearn: 1.7379064\ttotal: 1m 19s\tremaining: 28.7s\n",
      "881:\tlearn: 1.7378364\ttotal: 1m 19s\tremaining: 28.6s\n",
      "882:\tlearn: 1.7377466\ttotal: 1m 19s\tremaining: 28.5s\n",
      "883:\tlearn: 1.7376950\ttotal: 1m 19s\tremaining: 28.4s\n",
      "884:\tlearn: 1.7376461\ttotal: 1m 19s\tremaining: 28.3s\n",
      "885:\tlearn: 1.7375851\ttotal: 1m 19s\tremaining: 28.2s\n",
      "886:\tlearn: 1.7375516\ttotal: 1m 19s\tremaining: 28.1s\n",
      "887:\tlearn: 1.7375102\ttotal: 1m 19s\tremaining: 28s\n",
      "888:\tlearn: 1.7374798\ttotal: 1m 19s\tremaining: 27.9s\n",
      "889:\tlearn: 1.7373910\ttotal: 1m 19s\tremaining: 27.8s\n",
      "890:\tlearn: 1.7373448\ttotal: 1m 19s\tremaining: 27.7s\n",
      "891:\tlearn: 1.7372489\ttotal: 1m 19s\tremaining: 27.6s\n",
      "892:\tlearn: 1.7371933\ttotal: 1m 20s\tremaining: 27.5s\n",
      "893:\tlearn: 1.7371567\ttotal: 1m 20s\tremaining: 27.4s\n",
      "894:\tlearn: 1.7370945\ttotal: 1m 20s\tremaining: 27.3s\n",
      "895:\tlearn: 1.7370363\ttotal: 1m 20s\tremaining: 27.2s\n",
      "896:\tlearn: 1.7370025\ttotal: 1m 20s\tremaining: 27.1s\n",
      "897:\tlearn: 1.7369760\ttotal: 1m 20s\tremaining: 27.1s\n",
      "898:\tlearn: 1.7369285\ttotal: 1m 20s\tremaining: 27s\n",
      "899:\tlearn: 1.7368669\ttotal: 1m 20s\tremaining: 26.9s\n",
      "900:\tlearn: 1.7367814\ttotal: 1m 20s\tremaining: 26.8s\n",
      "901:\tlearn: 1.7366995\ttotal: 1m 20s\tremaining: 26.7s\n",
      "902:\tlearn: 1.7366344\ttotal: 1m 20s\tremaining: 26.6s\n",
      "903:\tlearn: 1.7365844\ttotal: 1m 20s\tremaining: 26.5s\n",
      "904:\tlearn: 1.7365112\ttotal: 1m 20s\tremaining: 26.4s\n",
      "905:\tlearn: 1.7364157\ttotal: 1m 21s\tremaining: 26.3s\n",
      "906:\tlearn: 1.7363292\ttotal: 1m 21s\tremaining: 26.2s\n",
      "907:\tlearn: 1.7362830\ttotal: 1m 21s\tremaining: 26.1s\n",
      "908:\tlearn: 1.7362171\ttotal: 1m 21s\tremaining: 26s\n",
      "909:\tlearn: 1.7361474\ttotal: 1m 21s\tremaining: 25.9s\n",
      "910:\tlearn: 1.7360870\ttotal: 1m 21s\tremaining: 25.8s\n",
      "911:\tlearn: 1.7360352\ttotal: 1m 21s\tremaining: 25.7s\n",
      "912:\tlearn: 1.7359753\ttotal: 1m 21s\tremaining: 25.6s\n",
      "913:\tlearn: 1.7359177\ttotal: 1m 21s\tremaining: 25.5s\n",
      "914:\tlearn: 1.7358142\ttotal: 1m 21s\tremaining: 25.5s\n",
      "915:\tlearn: 1.7357485\ttotal: 1m 21s\tremaining: 25.4s\n",
      "916:\tlearn: 1.7357120\ttotal: 1m 21s\tremaining: 25.3s\n",
      "917:\tlearn: 1.7356742\ttotal: 1m 21s\tremaining: 25.2s\n",
      "918:\tlearn: 1.7356121\ttotal: 1m 22s\tremaining: 25.1s\n",
      "919:\tlearn: 1.7355417\ttotal: 1m 22s\tremaining: 25s\n",
      "920:\tlearn: 1.7354654\ttotal: 1m 22s\tremaining: 24.9s\n",
      "921:\tlearn: 1.7353876\ttotal: 1m 22s\tremaining: 24.8s\n",
      "922:\tlearn: 1.7353052\ttotal: 1m 22s\tremaining: 24.7s\n",
      "923:\tlearn: 1.7352361\ttotal: 1m 22s\tremaining: 24.6s\n",
      "924:\tlearn: 1.7351479\ttotal: 1m 22s\tremaining: 24.5s\n",
      "925:\tlearn: 1.7350638\ttotal: 1m 22s\tremaining: 24.4s\n",
      "926:\tlearn: 1.7350019\ttotal: 1m 22s\tremaining: 24.3s\n",
      "927:\tlearn: 1.7349565\ttotal: 1m 22s\tremaining: 24.2s\n",
      "928:\tlearn: 1.7348693\ttotal: 1m 22s\tremaining: 24.1s\n",
      "929:\tlearn: 1.7348081\ttotal: 1m 22s\tremaining: 24.1s\n",
      "930:\tlearn: 1.7347721\ttotal: 1m 22s\tremaining: 24s\n",
      "931:\tlearn: 1.7347004\ttotal: 1m 22s\tremaining: 23.9s\n",
      "932:\tlearn: 1.7346005\ttotal: 1m 23s\tremaining: 23.8s\n",
      "933:\tlearn: 1.7345366\ttotal: 1m 23s\tremaining: 23.7s\n",
      "934:\tlearn: 1.7344537\ttotal: 1m 23s\tremaining: 23.6s\n",
      "935:\tlearn: 1.7343899\ttotal: 1m 23s\tremaining: 23.5s\n",
      "936:\tlearn: 1.7343215\ttotal: 1m 23s\tremaining: 23.4s\n",
      "937:\tlearn: 1.7342619\ttotal: 1m 23s\tremaining: 23.3s\n",
      "938:\tlearn: 1.7342029\ttotal: 1m 23s\tremaining: 23.2s\n",
      "939:\tlearn: 1.7341411\ttotal: 1m 23s\tremaining: 23.1s\n",
      "940:\tlearn: 1.7341051\ttotal: 1m 23s\tremaining: 23s\n",
      "941:\tlearn: 1.7340721\ttotal: 1m 23s\tremaining: 22.9s\n",
      "942:\tlearn: 1.7340017\ttotal: 1m 23s\tremaining: 22.8s\n",
      "943:\tlearn: 1.7339504\ttotal: 1m 23s\tremaining: 22.8s\n",
      "944:\tlearn: 1.7338561\ttotal: 1m 23s\tremaining: 22.7s\n",
      "945:\tlearn: 1.7338020\ttotal: 1m 24s\tremaining: 22.6s\n",
      "946:\tlearn: 1.7337217\ttotal: 1m 24s\tremaining: 22.5s\n",
      "947:\tlearn: 1.7336300\ttotal: 1m 24s\tremaining: 22.4s\n",
      "948:\tlearn: 1.7335496\ttotal: 1m 24s\tremaining: 22.3s\n",
      "949:\tlearn: 1.7335058\ttotal: 1m 24s\tremaining: 22.2s\n",
      "950:\tlearn: 1.7334680\ttotal: 1m 24s\tremaining: 22.1s\n",
      "951:\tlearn: 1.7334004\ttotal: 1m 24s\tremaining: 22s\n",
      "952:\tlearn: 1.7333657\ttotal: 1m 24s\tremaining: 21.9s\n",
      "953:\tlearn: 1.7333071\ttotal: 1m 24s\tremaining: 21.8s\n",
      "954:\tlearn: 1.7332678\ttotal: 1m 24s\tremaining: 21.7s\n",
      "955:\tlearn: 1.7332139\ttotal: 1m 24s\tremaining: 21.6s\n",
      "956:\tlearn: 1.7331721\ttotal: 1m 24s\tremaining: 21.6s\n",
      "957:\tlearn: 1.7330992\ttotal: 1m 24s\tremaining: 21.5s\n",
      "958:\tlearn: 1.7330667\ttotal: 1m 25s\tremaining: 21.4s\n",
      "959:\tlearn: 1.7329863\ttotal: 1m 25s\tremaining: 21.3s\n",
      "960:\tlearn: 1.7329428\ttotal: 1m 25s\tremaining: 21.2s\n",
      "961:\tlearn: 1.7329005\ttotal: 1m 25s\tremaining: 21.1s\n",
      "962:\tlearn: 1.7328341\ttotal: 1m 25s\tremaining: 21s\n",
      "963:\tlearn: 1.7327996\ttotal: 1m 25s\tremaining: 20.9s\n",
      "964:\tlearn: 1.7327555\ttotal: 1m 25s\tremaining: 20.8s\n",
      "965:\tlearn: 1.7327044\ttotal: 1m 25s\tremaining: 20.7s\n",
      "966:\tlearn: 1.7326459\ttotal: 1m 25s\tremaining: 20.6s\n",
      "967:\tlearn: 1.7325850\ttotal: 1m 25s\tremaining: 20.5s\n",
      "968:\tlearn: 1.7324970\ttotal: 1m 25s\tremaining: 20.5s\n",
      "969:\tlearn: 1.7324436\ttotal: 1m 25s\tremaining: 20.4s\n",
      "970:\tlearn: 1.7323652\ttotal: 1m 25s\tremaining: 20.3s\n",
      "971:\tlearn: 1.7323029\ttotal: 1m 26s\tremaining: 20.2s\n",
      "972:\tlearn: 1.7322489\ttotal: 1m 26s\tremaining: 20.1s\n",
      "973:\tlearn: 1.7322115\ttotal: 1m 26s\tremaining: 20s\n",
      "974:\tlearn: 1.7321728\ttotal: 1m 26s\tremaining: 19.9s\n",
      "975:\tlearn: 1.7320711\ttotal: 1m 26s\tremaining: 19.8s\n",
      "976:\tlearn: 1.7319981\ttotal: 1m 26s\tremaining: 19.7s\n",
      "977:\tlearn: 1.7319274\ttotal: 1m 26s\tremaining: 19.6s\n",
      "978:\tlearn: 1.7318697\ttotal: 1m 26s\tremaining: 19.5s\n",
      "979:\tlearn: 1.7318029\ttotal: 1m 26s\tremaining: 19.4s\n",
      "980:\tlearn: 1.7317310\ttotal: 1m 26s\tremaining: 19.4s\n",
      "981:\tlearn: 1.7316841\ttotal: 1m 26s\tremaining: 19.3s\n",
      "982:\tlearn: 1.7316423\ttotal: 1m 26s\tremaining: 19.2s\n",
      "983:\tlearn: 1.7315980\ttotal: 1m 26s\tremaining: 19.1s\n",
      "984:\tlearn: 1.7315420\ttotal: 1m 26s\tremaining: 19s\n",
      "985:\tlearn: 1.7314958\ttotal: 1m 27s\tremaining: 18.9s\n",
      "986:\tlearn: 1.7314478\ttotal: 1m 27s\tremaining: 18.8s\n",
      "987:\tlearn: 1.7313957\ttotal: 1m 27s\tremaining: 18.7s\n",
      "988:\tlearn: 1.7313449\ttotal: 1m 27s\tremaining: 18.6s\n",
      "989:\tlearn: 1.7312784\ttotal: 1m 27s\tremaining: 18.5s\n",
      "990:\tlearn: 1.7312236\ttotal: 1m 27s\tremaining: 18.4s\n",
      "991:\tlearn: 1.7311284\ttotal: 1m 27s\tremaining: 18.3s\n",
      "992:\tlearn: 1.7310554\ttotal: 1m 27s\tremaining: 18.3s\n",
      "993:\tlearn: 1.7310106\ttotal: 1m 27s\tremaining: 18.2s\n",
      "994:\tlearn: 1.7309620\ttotal: 1m 27s\tremaining: 18.1s\n",
      "995:\tlearn: 1.7308741\ttotal: 1m 27s\tremaining: 18s\n",
      "996:\tlearn: 1.7308216\ttotal: 1m 27s\tremaining: 17.9s\n",
      "997:\tlearn: 1.7307731\ttotal: 1m 27s\tremaining: 17.8s\n",
      "998:\tlearn: 1.7307275\ttotal: 1m 28s\tremaining: 17.7s\n",
      "999:\tlearn: 1.7306519\ttotal: 1m 28s\tremaining: 17.6s\n",
      "1000:\tlearn: 1.7306163\ttotal: 1m 28s\tremaining: 17.5s\n",
      "1001:\tlearn: 1.7305773\ttotal: 1m 28s\tremaining: 17.4s\n",
      "1002:\tlearn: 1.7305024\ttotal: 1m 28s\tremaining: 17.3s\n",
      "1003:\tlearn: 1.7304060\ttotal: 1m 28s\tremaining: 17.3s\n",
      "1004:\tlearn: 1.7303338\ttotal: 1m 28s\tremaining: 17.2s\n",
      "1005:\tlearn: 1.7302770\ttotal: 1m 28s\tremaining: 17.1s\n",
      "1006:\tlearn: 1.7302498\ttotal: 1m 28s\tremaining: 17s\n",
      "1007:\tlearn: 1.7301947\ttotal: 1m 28s\tremaining: 16.9s\n",
      "1008:\tlearn: 1.7301142\ttotal: 1m 28s\tremaining: 16.8s\n",
      "1009:\tlearn: 1.7300521\ttotal: 1m 28s\tremaining: 16.7s\n",
      "1010:\tlearn: 1.7299779\ttotal: 1m 28s\tremaining: 16.6s\n",
      "1011:\tlearn: 1.7298889\ttotal: 1m 29s\tremaining: 16.5s\n",
      "1012:\tlearn: 1.7298222\ttotal: 1m 29s\tremaining: 16.4s\n",
      "1013:\tlearn: 1.7297790\ttotal: 1m 29s\tremaining: 16.4s\n",
      "1014:\tlearn: 1.7297148\ttotal: 1m 29s\tremaining: 16.3s\n",
      "1015:\tlearn: 1.7296525\ttotal: 1m 29s\tremaining: 16.2s\n",
      "1016:\tlearn: 1.7296053\ttotal: 1m 29s\tremaining: 16.1s\n",
      "1017:\tlearn: 1.7295359\ttotal: 1m 29s\tremaining: 16s\n",
      "1018:\tlearn: 1.7294885\ttotal: 1m 29s\tremaining: 15.9s\n",
      "1019:\tlearn: 1.7294424\ttotal: 1m 29s\tremaining: 15.8s\n",
      "1020:\tlearn: 1.7293572\ttotal: 1m 29s\tremaining: 15.7s\n",
      "1021:\tlearn: 1.7292931\ttotal: 1m 29s\tremaining: 15.6s\n",
      "1022:\tlearn: 1.7292625\ttotal: 1m 29s\tremaining: 15.5s\n",
      "1023:\tlearn: 1.7291860\ttotal: 1m 29s\tremaining: 15.5s\n",
      "1024:\tlearn: 1.7291029\ttotal: 1m 29s\tremaining: 15.4s\n",
      "1025:\tlearn: 1.7290622\ttotal: 1m 30s\tremaining: 15.3s\n",
      "1026:\tlearn: 1.7289991\ttotal: 1m 30s\tremaining: 15.2s\n",
      "1027:\tlearn: 1.7289615\ttotal: 1m 30s\tremaining: 15.1s\n",
      "1028:\tlearn: 1.7288907\ttotal: 1m 30s\tremaining: 15s\n",
      "1029:\tlearn: 1.7288279\ttotal: 1m 30s\tremaining: 14.9s\n",
      "1030:\tlearn: 1.7287761\ttotal: 1m 30s\tremaining: 14.8s\n",
      "1031:\tlearn: 1.7286907\ttotal: 1m 30s\tremaining: 14.7s\n",
      "1032:\tlearn: 1.7286065\ttotal: 1m 30s\tremaining: 14.6s\n",
      "1033:\tlearn: 1.7285566\ttotal: 1m 30s\tremaining: 14.6s\n",
      "1034:\tlearn: 1.7284688\ttotal: 1m 30s\tremaining: 14.5s\n",
      "1035:\tlearn: 1.7284252\ttotal: 1m 30s\tremaining: 14.4s\n",
      "1036:\tlearn: 1.7283792\ttotal: 1m 30s\tremaining: 14.3s\n",
      "1037:\tlearn: 1.7283640\ttotal: 1m 30s\tremaining: 14.2s\n",
      "1038:\tlearn: 1.7283239\ttotal: 1m 31s\tremaining: 14.1s\n",
      "1039:\tlearn: 1.7282369\ttotal: 1m 31s\tremaining: 14s\n",
      "1040:\tlearn: 1.7281928\ttotal: 1m 31s\tremaining: 13.9s\n",
      "1041:\tlearn: 1.7281537\ttotal: 1m 31s\tremaining: 13.8s\n",
      "1042:\tlearn: 1.7280988\ttotal: 1m 31s\tremaining: 13.7s\n",
      "1043:\tlearn: 1.7280290\ttotal: 1m 31s\tremaining: 13.7s\n",
      "1044:\tlearn: 1.7279705\ttotal: 1m 31s\tremaining: 13.6s\n",
      "1045:\tlearn: 1.7279037\ttotal: 1m 31s\tremaining: 13.5s\n",
      "1046:\tlearn: 1.7278375\ttotal: 1m 31s\tremaining: 13.4s\n",
      "1047:\tlearn: 1.7277590\ttotal: 1m 31s\tremaining: 13.3s\n",
      "1048:\tlearn: 1.7277232\ttotal: 1m 31s\tremaining: 13.2s\n",
      "1049:\tlearn: 1.7276641\ttotal: 1m 31s\tremaining: 13.1s\n",
      "1050:\tlearn: 1.7276351\ttotal: 1m 31s\tremaining: 13s\n",
      "1051:\tlearn: 1.7275689\ttotal: 1m 31s\tremaining: 12.9s\n",
      "1052:\tlearn: 1.7275188\ttotal: 1m 32s\tremaining: 12.9s\n",
      "1053:\tlearn: 1.7274432\ttotal: 1m 32s\tremaining: 12.8s\n",
      "1054:\tlearn: 1.7273722\ttotal: 1m 32s\tremaining: 12.7s\n",
      "1055:\tlearn: 1.7273194\ttotal: 1m 32s\tremaining: 12.6s\n",
      "1056:\tlearn: 1.7272709\ttotal: 1m 32s\tremaining: 12.5s\n",
      "1057:\tlearn: 1.7271893\ttotal: 1m 32s\tremaining: 12.4s\n",
      "1058:\tlearn: 1.7271422\ttotal: 1m 32s\tremaining: 12.3s\n",
      "1059:\tlearn: 1.7270728\ttotal: 1m 32s\tremaining: 12.2s\n",
      "1060:\tlearn: 1.7270421\ttotal: 1m 32s\tremaining: 12.1s\n",
      "1061:\tlearn: 1.7269720\ttotal: 1m 32s\tremaining: 12s\n",
      "1062:\tlearn: 1.7269182\ttotal: 1m 32s\tremaining: 12s\n",
      "1063:\tlearn: 1.7268938\ttotal: 1m 32s\tremaining: 11.9s\n",
      "1064:\tlearn: 1.7268357\ttotal: 1m 32s\tremaining: 11.8s\n",
      "1065:\tlearn: 1.7267577\ttotal: 1m 33s\tremaining: 11.7s\n",
      "1066:\tlearn: 1.7267037\ttotal: 1m 33s\tremaining: 11.6s\n",
      "1067:\tlearn: 1.7266542\ttotal: 1m 33s\tremaining: 11.5s\n",
      "1068:\tlearn: 1.7266193\ttotal: 1m 33s\tremaining: 11.4s\n",
      "1069:\tlearn: 1.7265822\ttotal: 1m 33s\tremaining: 11.3s\n",
      "1070:\tlearn: 1.7265481\ttotal: 1m 33s\tremaining: 11.2s\n",
      "1071:\tlearn: 1.7264880\ttotal: 1m 33s\tremaining: 11.2s\n",
      "1072:\tlearn: 1.7264299\ttotal: 1m 33s\tremaining: 11.1s\n",
      "1073:\tlearn: 1.7263854\ttotal: 1m 33s\tremaining: 11s\n",
      "1074:\tlearn: 1.7263647\ttotal: 1m 33s\tremaining: 10.9s\n",
      "1075:\tlearn: 1.7262941\ttotal: 1m 33s\tremaining: 10.8s\n",
      "1076:\tlearn: 1.7262496\ttotal: 1m 33s\tremaining: 10.7s\n",
      "1077:\tlearn: 1.7262103\ttotal: 1m 33s\tremaining: 10.6s\n",
      "1078:\tlearn: 1.7261489\ttotal: 1m 33s\tremaining: 10.5s\n",
      "1079:\tlearn: 1.7261082\ttotal: 1m 34s\tremaining: 10.5s\n",
      "1080:\tlearn: 1.7260787\ttotal: 1m 34s\tremaining: 10.4s\n",
      "1081:\tlearn: 1.7260326\ttotal: 1m 34s\tremaining: 10.3s\n",
      "1082:\tlearn: 1.7259762\ttotal: 1m 34s\tremaining: 10.2s\n",
      "1083:\tlearn: 1.7259246\ttotal: 1m 34s\tremaining: 10.1s\n",
      "1084:\tlearn: 1.7258809\ttotal: 1m 34s\tremaining: 10s\n",
      "1085:\tlearn: 1.7258031\ttotal: 1m 34s\tremaining: 9.92s\n",
      "1086:\tlearn: 1.7257479\ttotal: 1m 34s\tremaining: 9.84s\n",
      "1087:\tlearn: 1.7257011\ttotal: 1m 34s\tremaining: 9.75s\n",
      "1088:\tlearn: 1.7256635\ttotal: 1m 34s\tremaining: 9.66s\n",
      "1089:\tlearn: 1.7256190\ttotal: 1m 34s\tremaining: 9.57s\n",
      "1090:\tlearn: 1.7255756\ttotal: 1m 34s\tremaining: 9.48s\n",
      "1091:\tlearn: 1.7254989\ttotal: 1m 35s\tremaining: 9.4s\n",
      "1092:\tlearn: 1.7254315\ttotal: 1m 35s\tremaining: 9.31s\n",
      "1093:\tlearn: 1.7253929\ttotal: 1m 35s\tremaining: 9.22s\n",
      "1094:\tlearn: 1.7253481\ttotal: 1m 35s\tremaining: 9.13s\n",
      "1095:\tlearn: 1.7252993\ttotal: 1m 35s\tremaining: 9.04s\n",
      "1096:\tlearn: 1.7252350\ttotal: 1m 35s\tremaining: 8.96s\n",
      "1097:\tlearn: 1.7252085\ttotal: 1m 35s\tremaining: 8.87s\n",
      "1098:\tlearn: 1.7251304\ttotal: 1m 35s\tremaining: 8.78s\n",
      "1099:\tlearn: 1.7250712\ttotal: 1m 35s\tremaining: 8.69s\n",
      "1100:\tlearn: 1.7250359\ttotal: 1m 35s\tremaining: 8.6s\n",
      "1101:\tlearn: 1.7249389\ttotal: 1m 35s\tremaining: 8.52s\n",
      "1102:\tlearn: 1.7249021\ttotal: 1m 35s\tremaining: 8.43s\n",
      "1103:\tlearn: 1.7248673\ttotal: 1m 35s\tremaining: 8.34s\n",
      "1104:\tlearn: 1.7248089\ttotal: 1m 36s\tremaining: 8.25s\n",
      "1105:\tlearn: 1.7247730\ttotal: 1m 36s\tremaining: 8.17s\n",
      "1106:\tlearn: 1.7247041\ttotal: 1m 36s\tremaining: 8.08s\n",
      "1107:\tlearn: 1.7246596\ttotal: 1m 36s\tremaining: 7.99s\n",
      "1108:\tlearn: 1.7246229\ttotal: 1m 36s\tremaining: 7.9s\n",
      "1109:\tlearn: 1.7245909\ttotal: 1m 36s\tremaining: 7.82s\n",
      "1110:\tlearn: 1.7245448\ttotal: 1m 36s\tremaining: 7.73s\n",
      "1111:\tlearn: 1.7244900\ttotal: 1m 36s\tremaining: 7.64s\n",
      "1112:\tlearn: 1.7244416\ttotal: 1m 36s\tremaining: 7.55s\n",
      "1113:\tlearn: 1.7243831\ttotal: 1m 36s\tremaining: 7.46s\n",
      "1114:\tlearn: 1.7243267\ttotal: 1m 36s\tremaining: 7.38s\n",
      "1115:\tlearn: 1.7242587\ttotal: 1m 36s\tremaining: 7.29s\n",
      "1116:\tlearn: 1.7241664\ttotal: 1m 36s\tremaining: 7.2s\n",
      "1117:\tlearn: 1.7240775\ttotal: 1m 37s\tremaining: 7.11s\n",
      "1118:\tlearn: 1.7240146\ttotal: 1m 37s\tremaining: 7.03s\n",
      "1119:\tlearn: 1.7239278\ttotal: 1m 37s\tremaining: 6.94s\n",
      "1120:\tlearn: 1.7238853\ttotal: 1m 37s\tremaining: 6.85s\n",
      "1121:\tlearn: 1.7238127\ttotal: 1m 37s\tremaining: 6.76s\n",
      "1122:\tlearn: 1.7237774\ttotal: 1m 37s\tremaining: 6.68s\n",
      "1123:\tlearn: 1.7237208\ttotal: 1m 37s\tremaining: 6.59s\n",
      "1124:\tlearn: 1.7236789\ttotal: 1m 37s\tremaining: 6.5s\n",
      "1125:\tlearn: 1.7236141\ttotal: 1m 37s\tremaining: 6.42s\n",
      "1126:\tlearn: 1.7235677\ttotal: 1m 37s\tremaining: 6.33s\n",
      "1127:\tlearn: 1.7235267\ttotal: 1m 37s\tremaining: 6.24s\n",
      "1128:\tlearn: 1.7234607\ttotal: 1m 37s\tremaining: 6.15s\n",
      "1129:\tlearn: 1.7234299\ttotal: 1m 37s\tremaining: 6.07s\n",
      "1130:\tlearn: 1.7233800\ttotal: 1m 38s\tremaining: 5.98s\n",
      "1131:\tlearn: 1.7233124\ttotal: 1m 38s\tremaining: 5.89s\n",
      "1132:\tlearn: 1.7232681\ttotal: 1m 38s\tremaining: 5.81s\n",
      "1133:\tlearn: 1.7232113\ttotal: 1m 38s\tremaining: 5.72s\n",
      "1134:\tlearn: 1.7231215\ttotal: 1m 38s\tremaining: 5.63s\n",
      "1135:\tlearn: 1.7230653\ttotal: 1m 38s\tremaining: 5.54s\n",
      "1136:\tlearn: 1.7229883\ttotal: 1m 38s\tremaining: 5.46s\n",
      "1137:\tlearn: 1.7229350\ttotal: 1m 38s\tremaining: 5.37s\n",
      "1138:\tlearn: 1.7228493\ttotal: 1m 38s\tremaining: 5.28s\n",
      "1139:\tlearn: 1.7227899\ttotal: 1m 38s\tremaining: 5.2s\n",
      "1140:\tlearn: 1.7227172\ttotal: 1m 38s\tremaining: 5.11s\n",
      "1141:\tlearn: 1.7226219\ttotal: 1m 38s\tremaining: 5.02s\n",
      "1142:\tlearn: 1.7225502\ttotal: 1m 38s\tremaining: 4.93s\n",
      "1143:\tlearn: 1.7224984\ttotal: 1m 39s\tremaining: 4.85s\n",
      "1144:\tlearn: 1.7224847\ttotal: 1m 39s\tremaining: 4.76s\n",
      "1145:\tlearn: 1.7224506\ttotal: 1m 39s\tremaining: 4.67s\n",
      "1146:\tlearn: 1.7224072\ttotal: 1m 39s\tremaining: 4.59s\n",
      "1147:\tlearn: 1.7223651\ttotal: 1m 39s\tremaining: 4.5s\n",
      "1148:\tlearn: 1.7223175\ttotal: 1m 39s\tremaining: 4.41s\n",
      "1149:\tlearn: 1.7222519\ttotal: 1m 39s\tremaining: 4.33s\n",
      "1150:\tlearn: 1.7221983\ttotal: 1m 39s\tremaining: 4.24s\n",
      "1151:\tlearn: 1.7221321\ttotal: 1m 39s\tremaining: 4.15s\n",
      "1152:\tlearn: 1.7220946\ttotal: 1m 39s\tremaining: 4.06s\n",
      "1153:\tlearn: 1.7220425\ttotal: 1m 39s\tremaining: 3.98s\n",
      "1154:\tlearn: 1.7220080\ttotal: 1m 39s\tremaining: 3.89s\n",
      "1155:\tlearn: 1.7219392\ttotal: 1m 39s\tremaining: 3.8s\n",
      "1156:\tlearn: 1.7218892\ttotal: 1m 40s\tremaining: 3.72s\n",
      "1157:\tlearn: 1.7218251\ttotal: 1m 40s\tremaining: 3.63s\n",
      "1158:\tlearn: 1.7217640\ttotal: 1m 40s\tremaining: 3.54s\n",
      "1159:\tlearn: 1.7217131\ttotal: 1m 40s\tremaining: 3.46s\n",
      "1160:\tlearn: 1.7216712\ttotal: 1m 40s\tremaining: 3.37s\n",
      "1161:\tlearn: 1.7215973\ttotal: 1m 40s\tremaining: 3.28s\n",
      "1162:\tlearn: 1.7215499\ttotal: 1m 40s\tremaining: 3.19s\n",
      "1163:\tlearn: 1.7215077\ttotal: 1m 40s\tremaining: 3.11s\n",
      "1164:\tlearn: 1.7214402\ttotal: 1m 40s\tremaining: 3.02s\n",
      "1165:\tlearn: 1.7214044\ttotal: 1m 40s\tremaining: 2.94s\n",
      "1166:\tlearn: 1.7213193\ttotal: 1m 40s\tremaining: 2.85s\n",
      "1167:\tlearn: 1.7212812\ttotal: 1m 40s\tremaining: 2.76s\n",
      "1168:\tlearn: 1.7212263\ttotal: 1m 40s\tremaining: 2.67s\n",
      "1169:\tlearn: 1.7211647\ttotal: 1m 40s\tremaining: 2.59s\n",
      "1170:\tlearn: 1.7210647\ttotal: 1m 41s\tremaining: 2.5s\n",
      "1171:\tlearn: 1.7210474\ttotal: 1m 41s\tremaining: 2.42s\n",
      "1172:\tlearn: 1.7210071\ttotal: 1m 41s\tremaining: 2.33s\n",
      "1173:\tlearn: 1.7209745\ttotal: 1m 41s\tremaining: 2.24s\n",
      "1174:\tlearn: 1.7208768\ttotal: 1m 41s\tremaining: 2.16s\n",
      "1175:\tlearn: 1.7207891\ttotal: 1m 41s\tremaining: 2.07s\n",
      "1176:\tlearn: 1.7207172\ttotal: 1m 41s\tremaining: 1.98s\n",
      "1177:\tlearn: 1.7206689\ttotal: 1m 41s\tremaining: 1.9s\n",
      "1178:\tlearn: 1.7206312\ttotal: 1m 41s\tremaining: 1.81s\n",
      "1179:\tlearn: 1.7205637\ttotal: 1m 41s\tremaining: 1.72s\n",
      "1180:\tlearn: 1.7205219\ttotal: 1m 41s\tremaining: 1.64s\n",
      "1181:\tlearn: 1.7204506\ttotal: 1m 41s\tremaining: 1.55s\n",
      "1182:\tlearn: 1.7204078\ttotal: 1m 41s\tremaining: 1.46s\n",
      "1183:\tlearn: 1.7203732\ttotal: 1m 42s\tremaining: 1.38s\n",
      "1184:\tlearn: 1.7203376\ttotal: 1m 42s\tremaining: 1.29s\n",
      "1185:\tlearn: 1.7202737\ttotal: 1m 42s\tremaining: 1.21s\n",
      "1186:\tlearn: 1.7202294\ttotal: 1m 42s\tremaining: 1.12s\n",
      "1187:\tlearn: 1.7201704\ttotal: 1m 42s\tremaining: 1.03s\n",
      "1188:\tlearn: 1.7201054\ttotal: 1m 42s\tremaining: 947ms\n",
      "1189:\tlearn: 1.7200577\ttotal: 1m 42s\tremaining: 861ms\n",
      "1190:\tlearn: 1.7200237\ttotal: 1m 42s\tremaining: 775ms\n",
      "1191:\tlearn: 1.7199894\ttotal: 1m 42s\tremaining: 689ms\n",
      "1192:\tlearn: 1.7199224\ttotal: 1m 42s\tremaining: 602ms\n",
      "1193:\tlearn: 1.7198427\ttotal: 1m 42s\tremaining: 516ms\n",
      "1194:\tlearn: 1.7198005\ttotal: 1m 42s\tremaining: 430ms\n",
      "1195:\tlearn: 1.7197699\ttotal: 1m 42s\tremaining: 344ms\n",
      "1196:\tlearn: 1.7197379\ttotal: 1m 42s\tremaining: 258ms\n",
      "1197:\tlearn: 1.7196649\ttotal: 1m 43s\tremaining: 172ms\n",
      "1198:\tlearn: 1.7196350\ttotal: 1m 43s\tremaining: 86ms\n",
      "1199:\tlearn: 1.7195961\ttotal: 1m 43s\tremaining: 0us\n",
      "C:\\Users\\jgnsa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[17:21:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "voting.fit(X, y)\n",
    "submission = prepare_test(voting, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}