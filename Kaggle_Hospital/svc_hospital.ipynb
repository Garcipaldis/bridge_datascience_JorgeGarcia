{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "674dfd6ded4398e0679ff4f65e9a10a54ff0d14801bec0126172cfc3973d1cf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hospital_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalEncoder:\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_admission(x):\n",
    "        data = {'Urgent': 2, 'Trauma': 1, 'Emergency': 3}\n",
    "        return data[x]\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_severity(x):\n",
    "        data = {'Moderate': 2, 'Extreme': 3, 'Minor': 1}\n",
    "        return data[x]\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_age(x):\n",
    "        data = {'21-30': 2, '51-60': 5, '71-80': 7, '11-20': 1, \n",
    "        '31-40': 3, '0-10': 0, '61-70': 6, '41-50': 4, '81-90': 4, '91-100': 9}\n",
    "        return data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos las columnas no relevantes\n",
    "filtered = df.drop(['1', '3', '4', '7', '8','9', '10', '11','14','16'], axis=1)\n",
    "\n",
    "# Aplicamos los encoders\n",
    "filtered['12'] = filtered['12'].apply(HospitalEncoder.encode_admission)\n",
    "filtered['13'] = filtered['13'].apply(HospitalEncoder.encode_severity)\n",
    "filtered['15'] = filtered['15'].apply(HospitalEncoder.encode_age)\n",
    "\n",
    "# Get dummies\n",
    "features = filtered[['2', '6']]\n",
    "features = pd.get_dummies(features)\n",
    "filtered.drop(['2', '6'], axis=1, inplace=True)\n",
    "train = pd.concat([filtered, features], axis=1)\n",
    "\n",
    "# Creamos X e y\n",
    "X = np.array(train.drop(['17'], axis=1))\n",
    "y = np.array(train['17'])\n",
    "\n",
    "# Conjuntos train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100000, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "p = PCA(0.95)\n",
    "p.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer()),\n",
    "    ('pca', PCA(0.95)),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "bilbo = BaggingClassifier(svc, n_estimators=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "bilbo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bilbo.predict(X_test)\n",
    "print('Test:', accuracy_score(y_test, y_pred))\n",
    "y_pred_train = bilbo.predict(X_train)\n",
    "print('Train:', accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aún no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\n",
    "    \"\"\"\n",
    "    sample = pd.read_csv(\"sample_submission.csv\")\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id.all() == sample.id.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                df_to_submit.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")\n",
    "\n",
    "filepath = 'hospital_test.csv'\n",
    "\n",
    "def prepare_test(model, filepath):\n",
    "    df = pd.read_csv(filepath, index_col=0)\n",
    "    # Operaciones de transformación.\n",
    "    # Quitamos las columnas no relevantes\n",
    "    filtered = df.drop(['1', '3', '4', '7', '8', '9','10', '11', '14','16'], axis=1)\n",
    "\n",
    "    # Aplicamos los encoders\n",
    "    filtered['12'] = filtered['12'].apply(HospitalEncoder.encode_admission)\n",
    "    filtered['13'] = filtered['13'].apply(HospitalEncoder.encode_severity)\n",
    "    filtered['15'] = filtered['15'].apply(HospitalEncoder.encode_age)\n",
    "\n",
    "    # Get dummies\n",
    "    features = filtered[['2', '6']]\n",
    "    features = pd.get_dummies(features)\n",
    "    filtered.drop(['2', '6'], axis=1, inplace=True)\n",
    "    test = pd.concat([filtered, features], axis=1)\n",
    "\n",
    "    # Creamos X\n",
    "    X = np.array(test)\n",
    "\n",
    "    # Cambiamos Nan por la media\n",
    "    sim = SimpleImputer()\n",
    "    X = sim.fit_transform(X)\n",
    "\n",
    "    # Reducción de Dimensiones\n",
    "    pc = PCA(0.95)\n",
    "    X = pc.fit_transform(X)\n",
    "\n",
    "    # Cogemos índice de sample_submission.csv\n",
    "    sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    # Preparamos dataframe de test.\n",
    "    predictions_submit = model.predict(X)\n",
    "    submission = pd.DataFrame({\"id\": sample.id, \"days\": predictions_submit.ravel()})\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilbo.fit(X, y)\n",
    "submission = prepare_test(bilbo, filepath)\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}