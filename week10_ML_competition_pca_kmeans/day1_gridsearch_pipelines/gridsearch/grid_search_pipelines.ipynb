{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch & Pipelines\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - One way\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                         'gamma': ('scale', 'auto'),\n",
       "                         'kernel': ('linear', 'rbf', 'sigmoid')},\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
    "    'gamma': ('scale', 'auto')\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator = svc,\n",
    "                  param_grid = parameters,\n",
    "                  n_jobs=-1,\n",
    "                  cv=10,\n",
    "                  verbose=2)\n",
    "\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC(C=0.5, kernel='linear')\n0.9866666666666667\n{'C': 0.5, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Almost-Pro way\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 53 candidates, totalling 530 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 530 out of 530 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('classifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': [0.01, 0.1, 0.5, 1],\n",
       "                          'classifier__penalty': ['l1', 'l2']},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__max_features': [1, 2, 3],\n",
       "                          'classifier__n_estimators': [10, 100, 1000]},\n",
       "                         {'classifier': [SVC(C=0.1, kernel='linear')],\n",
       "                          'classifier__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                          'classifier__gamma': ('scale', 'auto'),\n",
       "                          'classifier__kernel': ('linear', 'rbf', 'sigmoid')}],\n",
       "             verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    \"classifier__C\": [0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1,2,3]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'classifier': [SVC()],\n",
    "    'classifier__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'classifier__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
    "    'classifier__gamma': ('scale', 'auto')\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_params\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  cv = 10,\n",
    "                  verbose=1,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('classifier', SVC(C=0.1, kernel='linear'))])\n{'classifier': SVC(C=0.1, kernel='linear'), 'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"reglog\", LogisticRegression())\n",
    "])\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "svm = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"svm\", SVC())\n",
    "])\n",
    "\n",
    "reg_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "    \"reglog__penalty\": ['l1', 'l2'],\n",
    "    \"reglog__C\": [0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_features': [1,2,3]\n",
    "}\n",
    "\n",
    "svm_param = {\n",
    "    'selectkbest__k': [1,2,3],\n",
    "    'svm__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'svm__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
    "    'svm__gamma': ('scale', 'auto')\n",
    "    \n",
    "}\n",
    "\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                         reg_log_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(rand_forest,\n",
    "                         rand_forest_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gs_svm = GridSearchCV(svm, svm_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "grids = {\n",
    "    \"gs_reg_log\": gs_reg_log,\n",
    "    \"gs_rand_forest\": gs_rand_forest,\n",
    "    \"gs_svm\": gs_svm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n",
      "#################\n",
      "NOMBRE: gs_reg_log\n",
      "#################\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "#################\n",
      "NOMBRE: gs_rand_forest\n",
      "#################\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  90 | elapsed:    3.3s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    4.6s finished\n",
      "#################\n",
      "NOMBRE: gs_svm\n",
      "#################\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n",
      "Wall time: 6.61 s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for nombre, grid in grids.items():\n",
    "    print(\"#################\")\n",
    "    print(\"NOMBRE:\", nombre)\n",
    "    print(\"#################\")\n",
    "    grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Grid  Best score\n",
       "2          gs_svm    0.958333\n",
       "0      gs_reg_log    0.941667\n",
       "1  gs_rand_forest    0.933333"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grid</th>\n      <th>Best score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>gs_svm</td>\n      <td>0.958333</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gs_reg_log</td>\n      <td>0.941667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gs_rand_forest</td>\n      <td>0.933333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "import pandas as pd\n",
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids,\n",
    "                         columns = ['Grid', 'Best score']).sort_values(by = 'Best score', ascending=False)\n",
    "best_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'selectkbest__k': [1, 2, 3],\n",
       "                         'svm__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                         'svm__gamma': ('scale', 'auto'),\n",
       "                         'svm__kernel': ('linear', 'rbf', 'sigmoid')},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "best_model = grids['gs_svm']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=2)),\n                ('svm', SVC(C=0.5, kernel='sigmoid'))])\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "best_model.best_estimator_.fit(X_train, y_train)\n",
    "best_model.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=0.5, kernel='sigmoid')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "best_model.best_estimator_['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finished_model.model'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best_model.best_estimator_, archivo_salida)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=2)),\n",
       "                ('svm', SVC(C=0.5, kernel='sigmoid'))])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "with open(filename, 'rb') as archivo_entrada:\n",
    "    pipeline_importada = pickle.load(archivo_entrada)\n",
    "pipeline_importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "pipeline_importada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python36464bitc2077ed07ea84d23aa5b518d224882ab",
   "display_name": "Python 3.6.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "5c4d2f1fdcd3716c7a5eea90ad07be30193490dd4e63617705244f5fd89ea793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}