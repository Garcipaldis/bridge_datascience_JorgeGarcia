{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5c4d2f1fdcd3716c7a5eea90ad07be30193490dd4e63617705244f5fd89ea793"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![time_spent](time_spent.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow de un proyecto completo de aprendizaje supervisado de Data Science:\n",
    "\n",
    "----------------------------\n",
    "\n",
    "0. Aspectos de Ingeniería y Gestión: \n",
    "    - Definición de objetivos y necesidades ¿se precisa más velocidad que precisión? \n",
    "    - Limitaciones hardware, escalabilidad, etc. \n",
    "    - Complementación cloud, codificación para producción, entorno de desarrollo, etc\n",
    "    - (...)\n",
    "\n",
    "----------------------------\n",
    "\n",
    "**Recuerda que en una empresa normalmente trabajamos en un equipo multidisciplinar. Según las necesidades de los otros departamentos de una empresa, cada punto puede extenderse con más necesidades específicas.**\n",
    "\n",
    "*Es muy importante el tener en cuenta que si eligimos una semilla (seed), puede que nuestro algorimo no obtenga el resultado óptimo. Esto se debe a que cogerá partes de datos específicas y se harán reordenaciones específicas.*\n",
    "\n",
    "----------------------------\n",
    "\n",
    "1. ¿Existen datos? Si no tenemos datos, el primer objetivo es conseguirlos. \n",
    "\n",
    "----------------------------\n",
    "\n",
    "2. ¿Están etiquetados? si no, lo hacemos nosotros a mano (hay software que podría ayudarnos). \n",
    "\n",
    "    - Si no podemos hacerlo nosotros ni el software, entonces se trata de un problema no supervisado. \n",
    "    - Si hay labels pero no en todos los datos, entonces se trata de un problema semi-supervisado.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "3. Una vez tengamos los datos etiquetados, debemos empezar nuestra Exploración y Análisis de Datos(EDA):\n",
    "\n",
    "    - Sacamos nuestra \"X\" e \"y\" de los datos. \n",
    "    - Si tenemos datos categóricos, pasaremos un encoder a las columnas no numéricas para realizar la transformación.\n",
    "    - Realizamos la matriz de correlación y otras gráficas para visualizar y entender mejor nuestros datos. Podemos quitar las columnas que tengan menos correlación (cercanas al 0). Esa decisión alterará a la precisión de nuestro modelo ya que entrenará menos datos.\n",
    "    - Podemos realizar una normalización de los datos. Esto es opcional tanto para una como para todas las columnas numéricas (no categóricas). \n",
    "    - Realizamos otras modificaciones de nuestros datos: quitar columnas con un %NaN mayor a N, reemplazar NaN por media, agregar columnas que sean operaciones estadísticas entre columnas (media, mediana, varianza, etc), agrupar por datos categóricos, ...\n",
    "    - Podemos representar de nuevo la matriz de correlación y otras gráficas para ver si con las modificaciones realizadas se modifica y podemos sacar diferentes conclusiones.\n",
    "    - (...)\n",
    "\n",
    "----------------------------\n",
    "\n",
    "4. Realizamos el split de datos: \n",
    "\n",
    "    - Si los datos son demasiados para los recursos hardware que tenemos, podemos realizar un split más pequeño para trabajar con ellos en primera instancia. \n",
    "    - Obtenemos el conjunto de train y de test. \n",
    "\n",
    "----------------------------\n",
    "\n",
    "5. Elegimos el algoritmo a utilizar:\n",
    "\n",
    "    - Podemos realizar un GridSearch para encontrar el mejor modelo entre varios y las features adecuadas. \n",
    "        - Si no son muchos datos, podemos usar con el X_train completo. \n",
    "        - Si tenemos limitaciones, podemos usar el sample generado para ver qué algoritmo se comporta mejor. \n",
    "        - Aquí vamos a ver un primer score. Sería buena idea volver al punto 3 y realizar más cambios sobre nuestro conjunto de datos. \n",
    "\n",
    "----------------------------\n",
    "\n",
    "6. Entrenamos el modelo. Tenemos varias posibilidades:\n",
    "\n",
    "    - 6.1. Si nuestro algoritmo no nos permite validación cruzada:\n",
    "        - 6.1.1. Usar todos los datos si nuestro hardware lo permite y no necesitamos controlar lo que ocurre durante el entrenamiento.\n",
    "        - 6.1.2. Usar el sample de datos más pequeño para ver qué score puede ofrecer. Volver al punto 3 y realizar las modificaciones pertinentes. \n",
    "        - 6.1.3. Volveremos al punto 3 para realizar más cambios a nuestro dataset si lo vemos necesario.\n",
    "    - 6.2. Si nuestro algorimo nos permite validación cruzada: \n",
    "        - 6.2.1. Tenemos las mismas opciones que en la 6.1\n",
    "        - 6.2.2. Realizar validación cruzada con todos los datos.\n",
    "        - 6.2.2. Realizar validación cruzada con el sample de datos para ver qué score puede ofrecer. Volver al punto 3 y realizar las modificaciones pertinentes. \n",
    "        - 6.2.3. Realizar validación cruzada con todos los datos poco a poco (entrenamiento incremental, online, mini_batch, en caliente). Esta sería la opción óptima ya que nos permite controlar lo que va ocurriendo y ver cómo evoluciona el entrenamiento. \n",
    "\n",
    "----------------------------\n",
    "\n",
    "7. Sacar score de nuestros datos:\n",
    "\n",
    "    - 7.1. Si no son los deseados, debemos volver al punto 3, 4 o 5 dependiendo de las necesidades.\n",
    "    - 7.2. Si lo son, 8. \n",
    "\n",
    "----------------------------\n",
    "\n",
    "8. Realizar un entrenamiento completo de los datos. Es decir, ya no se utilizarán los datos del split, no habrá X_test. Aquí volvemos a realizar el análisis con todos los datos usando alguna opción del punto 6 (sin la parte del sample). Una vez realizado, guardamos el modelo con sus estadísticas anotadas.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "9. Partes de ingeniería y otras necesidades (Monitorización, ...)\n",
    "\n",
    "----------------------------\n"
   ]
  }
 ]
}