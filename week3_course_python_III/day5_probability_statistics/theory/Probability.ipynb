{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es la Probabilidad?\n",
    "\n",
    "La [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) mide la mayor o menor posibilidad de que se dé un determinado resultado (suceso o evento) cuando se realiza un experimento aleatorio.\n",
    "Para calcular la probabilidad de un evento se toma en cuenta todos los casos posibles de ocurrencia del mismo; es decir, de cuántas formas puede ocurrir determinada situación.Los casos favorables de ocurrencia de un evento serán los que cumplan con la condición que estamos buscando. La *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* toma valores entre 0 y 1 (o expresados en tanto por ciento, entre 0% y 100%).\n",
    "\n",
    "La *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* es a la vez el inverso y complemento para la *[estadística](http://es.wikipedia.org/wiki/Estad%C3%ADstica)*. Donde la *[estadística](http://es.wikipedia.org/wiki/Estad%C3%ADstica)* nos ayuda a ir desde los *[datos](https://es.wikipedia.org/wiki/Dato)* observados hasta hacer generalizaciones sobre como funcionan las cosas; la *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* funciona en la dirección inversa: si asumimos que sabemos como las cosas funcionan, entonces podemos averiguar la clase de *[datos](https://es.wikipedia.org/wiki/Dato)* que vamos a ver y cuan probable es que los veamos.\n",
    "\n",
    "La *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* también funciona como complemento de la *[estadística](http://es.wikipedia.org/wiki/Estad%C3%ADstica)* cuando nos proporciona una sólida base para la *[estadistica inferencial](https://es.wikipedia.org/wiki/Estad%C3%ADstica_inferencial)*. Cuando hay incertidumbre, no sabemos que puede pasar y hay alguna posibilidad de errores, utilizando *[probabilidades](https://es.wikipedia.org/wiki/Probabilidad)* podemos aprender formas de controlar la tasa de errores para reducirlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Calculando probabilidades\n",
    "\n",
    "Saber calcular la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de que un evento o varios eventos ocurran puede ser una habilidad valiosa al tomar decisiones, ya sea en la vida real o jugando juegos de azar. Cómo calcular la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad), sin embargo, cambia dependiendo del tipo de evento que se está observando. Por ejemplo, no calcularíamos nuestras posibilidades de ganar la lotería de la misma manera que calcularíamos nuestras posibilidades de obtener una [generala](https://es.wikipedia.org/wiki/Generala) servida en un juego de dados. Sin embargo, una vez que determinamos si los eventos son <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a>, [condicionales](https://es.wikipedia.org/wiki/Probabilidad_condicionada) o mutuamente excluyentes, calcular su probabilidad es relativamente simple.\n",
    "\n",
    "### Propiedades básicas de la probabilidad\n",
    "\n",
    "Antes de poder calcular las [probabilidades](https://es.wikipedia.org/wiki/Probabilidad), primero debemos conocer sus 3 propiedades fundamentales, ellas son:\n",
    "\n",
    "* La [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) se expresa como un ratio que será un valor positivo menor o igual a 1.\n",
    "\n",
    "$ 0 \\le p(A) \\le 1$\n",
    "\n",
    "* La [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de un evento del que tenemos total certeza es 1.\n",
    "\n",
    "$ p(S) = 1 $\n",
    "\n",
    "* Si el evento $A$ y el evento $B$ son *mutuamente excluyentes* (Si los eventos no pueden ocurrir juntos), entonces:\n",
    "\n",
    "$ p(A \\cup B ) = p(A) + p(B) $\n",
    "\n",
    "$\\cup = ó $\n",
    "\n",
    "Ejemplo: Sacar una carta roja o un trébol. (52 cartas)\n",
    "\n",
    "A partir de estas propiedades básicas, se pueden derivar muchas otras propiedades.\n",
    "\n",
    "### Teoría de conjuntos y probabilidades\n",
    "\n",
    "Antes de poder calcular  [probabilidades](https://es.wikipedia.org/wiki/Probabilidad), primero debemos discutir cómo se relacionan los eventos en términos de la [teoría de conjuntos](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_conjuntos). Las relaciones que podemos encontrar son:\n",
    "\n",
    "* **Unión:** La unión de varios eventos simples crea un evento compuesto que ocurre si uno o más de los eventos ocurren. La unión de $E$ y $F$ se escribe $E \\cup F$ y significa \"Ya sea $E$ o $F$, o ambos $E$ y $F$.\"\n",
    "\n",
    "* **Intersección:** La intersección de dos o más eventos simples crea un evento compuesto que ocurre sólo si ocurren todos los eventos simples. La intersección de $E$ y $F$ se escribe $E \\cap F$ y significa \"$E$ y $F$.\"\n",
    "\n",
    "$ \\cap $ = y\n",
    "\n",
    "* **Complemento:** El complemento de un evento significa todo en el [espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral) que no es ese evento. El complemento del evento $E$ se escribe varias veces como $\\sim{E}$, $E^c$, o $\\overline{E}$, y se lee como \"no $E$\" o \"complemento $E$\".\n",
    "\n",
    "* **Exclusión mutua:** Si los eventos no pueden ocurrir juntos, son *mutuamente excluyentes*. Siguiendo la misma línea de razonamiento, si dos conjuntos no tienen ningún evento en común, son mutuamente excluyentes.\n",
    "\n",
    "### Calculando la probabilidad de múltiples eventos\n",
    "\n",
    "Ahora sí, ya podemos calcular las [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) de los eventos. Recordemos que la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de un solo evento se expresa como un ratio entre el número de resultados favorables sobre el número de los posibles resultados. Pero ¿qué pasa cuando tenemos múltiples eventos?\n",
    "\n",
    "#### Unión de eventos mutuamente excluyentes\n",
    "Si los eventos son *mutuamente excluyentes* entonces para calcular la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de su unión, simplemente sumamos sus [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) individuales.\n",
    "\n",
    "$p(E \\cup F) = p(E) + p(F)$\n",
    "\n",
    "#### Unión de eventos que no son mutuamente excluyentes\n",
    "Si los eventos no son *mutuamente excluyentes* entonces debemos corregir la fórmula anterior para incluir el efecto de la superposición de los eventos. Esta superposición se da en el lugar de la *intersección* de los eventos; por lo tanto la formula para calcular la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de estos eventos es:\n",
    "\n",
    "$p(E \\cup F) = p(E) + p(F) - p(E \\cap F)$\n",
    "\n",
    "Ejemplo: Sacar una carta roja y que sea 4.\n",
    "\n",
    "#### Intersección de eventos independientes\n",
    "Para calcular la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de que ocurran varios eventos (la intersección de varios eventos), se multiplican sus [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) individuales. La fórmula específica utilizada dependerá de si los eventos son <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a> o no.\n",
    "Si son <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a>, la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de $E$ y $F$ se calcula como:\n",
    "\n",
    "$p(E \\cap F) = p(E) \\times p(F)$\n",
    "\n",
    "Ejemplo: Sacar una carta, volver a ponerla en la baraja y sacar otra vez la misma carta.\n",
    "\n",
    "#### Intersección de eventos no independientes\n",
    "Si dos eventos no son <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a>, debemos conocer su [probabilidad condicional](https://es.wikipedia.org/wiki/Probabilidad_condicionada) para poder calcular la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de que ambos se produzcan. La fórmula en este caso es:\n",
    "\n",
    "$p(E \\cap F) = p(E) \\times p(F|E)$\n",
    "\n",
    "Ejemplo: Sacar un AS y volver a sacar otro AS habiendo sacado el primero.\n",
    "\n",
    "### La probabilidad condicional\n",
    "\n",
    "Con frecuencia queremos conocer la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de algún evento, dado que otro evento ha ocurrido. Esto se expresa simbólicamente como $p(E | F)$ y se lee como \"la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de $E$ dado $F$\". El segundo evento se conoce como la *condición* y el proceso se refiere a veces como \"condicionamiento en F\". La [probabilidad condicional](https://es.wikipedia.org/wiki/Probabilidad_condicionada) es un concepto importante de estadística, porque a menudo estamos tratando de establecer que un factor tiene una relación con un resultado, como por ejemplo, que las personas que fuman cigarrillos tienen más [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) de desarrollar cáncer de pulmón. La [probabilidad condicional](https://es.wikipedia.org/wiki/Probabilidad_condicionada) también se puede usar para definir la <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independencia</a>. Dos variables se dice que son <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a> si la siguiente relación se cumple:\n",
    "\n",
    "$p(E | F) = p(E)$\n",
    "\n",
    "Probabilidad de ser fumador si eres asmático\n",
    "\n",
    "#### Calculando la probabilidad condicional\n",
    "Para calcular la probabilidad del evento $E$ dada la información de que el evento $F$ ha ocurrido utilizamos la siguiente formula:\n",
    "\n",
    "$p(E | F) = \\frac{p(E \\cap F)}{p(F)}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distintas interpretaciones de la probabilidad\n",
    "\n",
    "Las [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) pueden ser interpretadas generalmente de dos maneras distintas.\n",
    "La interpretación *frecuentista* u *objetivista* de la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) es una perspectiva en la que las [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) se consideran frecuencias relativas constantes a largo plazo. Este es el enfoque clásico de la [teoría de probabilidad](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_probabilidad). La interpretación *Bayesiana* o *subjetivista* de la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) es una perspectiva en la que las [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) son consideradas como *medidas de creencia* que pueden cambiar con el tiempo para reflejar nueva información. El *enfoque clásico* sostiene que los métodos *bayesianos* sufren de falta de objetividad, ya que diferentes individuos son libres de asignar diferentes [probabilidades](https://es.wikipedia.org/wiki/Probabilidad) al mismo evento según sus propias opiniones personales. Los *bayesianos* se oponen a los *clásicos* sosteniendo que la interpretación *frecuentista* de la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) tiene ya de por sí una subjetividad incorporada (por ejemplo, mediante la elección y el diseño del procedimiento de muestreo utilizado) y que la ventaja del *enfoque bayesiano* es que ya hace explícita esta subjetividad.\n",
    "En la actualidad, la mayoría de los problemas son abordados siguiendo un enfoque mixto entre ambas interpretaciones de la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad). \n",
    "\n",
    "## El poder de los números aleatorios\n",
    "\n",
    "Uno podría pensar que un comportamiento [aleatorio](https://es.wikipedia.org/wiki/Aleatoriedad) es caótico y totalmente opuesto a la razón, que sería una forma de renunciar a un problema, un último recurso. Pero lejos de esto, el sorprendente y cada vez más importante rol que viene desempeñando lo [aleatorio](https://es.wikipedia.org/wiki/Aleatoriedad) en las [ciencias de la computación](https://es.wikipedia.org/wiki/Ciencias_de_la_computaci%C3%B3n) nos enseña que el hacer un uso deliberado de lo [aleatorio](https://es.wikipedia.org/wiki/Aleatoriedad) puede ser una forma muy efectiva de abordar los problemas más difíciles; incluso en algunos casos, puede ser el único camino viable. Los [Algoritmos probabilísticos](https://es.wikipedia.org/wiki/Algoritmo_probabilista) como el método [Miller-Rabin](https://es.wikipedia.org/wiki/Test_de_primalidad_de_Miller-Rabin) para encontrar números primos y el [método de Monte Carlo](https://es.wikipedia.org/wiki/M%C3%A9todo_de_Montecarlo), nos demuestran lo poderoso que puede ser utilizar la [aleatoriedad](https://es.wikipedia.org/wiki/Aleatoriedad) para resolver problemas. Muchas veces, la mejor solución a un problema, puede ser simplemente dejarlo al azar en lugar de tratar de razonar totalmente su solución!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Probabilidad y sentido común\n",
    "\n",
    "La incertidumbre constituye una pieza fundamental del mundo en que vivimos. Una parte de nosotros querría predecir el futuro y que las cosas sean mucho más predecibles. Para poder lidiar con la incertidumbre que nos rodea, solemos aplicar lo que llamamos nuestro \"*sentido común*\". Por ejemplo, si al levantarnos por la mañana vemos que el día se encuentra nublado, este hecho no nos da la **certeza** de que comenzará a llover más tarde; sin embargo, nuestro *sentido común* puede inducirnos a cambiar nuestros planes y a actuar como si *creyéramos* que fuera a llover si las nubes son los suficientemente oscuras o si escuchamos truenos, ya que nuestra experiencia nos dice que estos signos indicarían una mayor *posibilidad* de que el hecho de que fuera a llover más tarde realmente ocurra. \n",
    "Nuestro *sentido común* es algo tan arraigado en nuestro pensamiento, que lo utilizamos automáticamente sin siquiera ponernos a pensar en ello; pero muchas veces, el *sentido común* también nos puede jugar una mala pasada y hacernos elegir una respuesta incorrecta.\n",
    "\n",
    "Tomemos por ejemplo alguna de las siguiente situaciones...\n",
    "\n",
    "* **Situación 1 - La coincidencia de cumpleaños:** Vamos a una fiesta a la que concurren un total de 50 personas. Allí un amigo nos desafía afirmando que en la fiesta debe haber por lo menos 2 personas que cumplen años el mismo día y nos apuesta 100 pesos a que está en lo correcto. Es decir, que si él acierta deberíamos pagarle los 100 pesos; o en caso contrario, el nos pagará los 100 pesos. ¿Deberíamos aceptar la apuesta? \n",
    "\n",
    "\n",
    "* **Situación 2 - ¿Qué puerta elegir?:** Estamos participando en un concurso en el cual se nos ofrece la posibilidad de elegir una entre tres puertas. Tras una de ellas se encuentra una ferrari ultimo modelo, y detrás de las otras dos hay una cabra; luego de elegir una puerta, el presentador del concurso abre una de las puertas restantes y muestra que hay una cabra (el presentador sabe que hay detrás de cada puerta). Luego de hacer esto, el presentador nos ofrece la posibilidad de cambiar nuestra elección inicial y quedarnos con la otra puerta que no habíamos elegido inicialmente. ¿Deberíamos cambiar o confiar en nuestra elección inicial?\n",
    "\n",
    "¿Qué les diría su *sentido común* que deberían hacer en cada una de estas situaciones?\n",
    "\n",
    "Para poder responder éstas y otras preguntas de una manera más rigurosa, primero deberíamos de alguna forma modelar matemáticamente nuestro *sentido común*, es aquí, como lo expresa la frase del comienzo del artículo, como surge la [teoría de probabilidad](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_probabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=BzAhrFrnpGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob = 1.0\n",
    "asistentes = 150\n",
    "\n",
    "for i in range(asistentes):\n",
    "    prob = prob * (365-i)/365\n",
    "\n",
    "probabilidad_coincidencia = 1-prob\n",
    "    \n",
    "print(\"La probabilidad de que compartan la misma fecha es:\\n\\n\", probabilidad_coincidencia*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### El Espacio de muestreo\n",
    "\n",
    "El *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)* hace referencia a la idea de que los posibles resultados de un [proceso aleatorio](https://es.wikipedia.org/wiki/Experimento_aleatorio) pueden ser pensados como puntos en el espacio. En los casos más simples, este espacio puede consistir en sólo algunos puntos, pero en casos más complejos puede estar representado por un *continuo*, como el espacio en que vivimos. El *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)* , en general se expresa con la letra $S$, y consiste en el conjunto de todos los resultados posibles de un *experimento*. Si el experimento consiste en el lanzamiento de una moneda, entonces el *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)* será $S = \\{cara, seca \\}$, ya que estas dos alternativas representan a todos los resultados posibles del *experimento*. En definitiva el *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)* no es más que una simple enumeración de todos los resultados posibles, aunque las cosas nunca suelen ser tan simples como aparentan. Si en lugar de considerar el lanzamiento de una moneda, lanzamos dos monedas; uno podría pensar que el *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)* para este caso será  $S = \\{\\text{ 2 caras}, \\text{2 secas}, \\text{cara y seca} \\}$; es decir que de acuerdo con este *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)* la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de que obtengamos dos caras es 1 en 3; pero la verdadera [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de obtener dos caras, confirmada por la experimentación, es 1 en 4; la cual se hace evidente si definimos correctamente el *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)*, que será el siguiente: $S = \\{\\text{ 2 caras}, \\text{2 secas}, \\text{cara y seca}, \\text{seca y cara} \\}$. Como este simple ejemplo nos enseña, debemos ser muy cuidadosos al definir el *[espacio de muestreo](https://es.wikipedia.org/wiki/Espacio_muestral)*, ya que una mala definición del mismo, puede inducir a cálculos totalmente errados de la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad).\n",
    "\n",
    "\n",
    "## Independencia, la ley de grandes números y el teorema del límite central\n",
    "\n",
    "Una de las cosas más fascinantes sobre el estudio de la [teoría de probabilidad](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_probabilidad) es que si bien el comportamiento de un evento individual es totalmente impredecible, el comportamiento de una cantidad suficientemente grande de eventos se puede predecir con un alto grado de certeza!.\n",
    "Si tomamos el caso clásico del lanzamiento de una moneda, no podemos predecir con exactitud cuantas caras podemos obtener luego de 10 tiradas, tal vez el azar haga que obtengamos 7, 10, o 3 caras, dependiendo de con cuanta suerte nos encontremos; pero si repetimos el lanzamiento un millón de veces, casi con seguridad que la cantidad de caras se aproximará a la verdadera *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* subyacente del experimento, es decir, al 50% de los lanzamientos. Este comportamiento es lo que en la [teoría de probabilidad](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_probabilidad) se conoce con el nombre de [ley de grandes números](https://es.wikipedia.org/wiki/Ley_de_los_grandes_n%C3%BAmeros); pero antes de poder definir esta ley, primero debemos describir otro concepto también muy importante, la <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independencia</a> de los [eventos](https://es.wikipedia.org/wiki/Evento_aleatorio) .\n",
    "\n",
    "### El concepto de independencia\n",
    "\n",
    "En [teoría de probabilidad](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_probabilidad), podemos decir que dos [eventos](https://es.wikipedia.org/wiki/Evento_aleatorio) son <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a> cuando la *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* de cada uno de ellos no se ve afecta porque el otro evento ocurra, es decir que no existe ninguna relación entre los [eventos](https://es.wikipedia.org/wiki/Evento_aleatorio). En el lanzamiento de la moneda; la moneda no sabe, ni le interesa saber si el resultado del lanzamiento anterior fue cara; cada lanzamiento es un suceso totalmente aislado el uno del otro y la *[probabilidad](https://es.wikipedia.org/wiki/Probabilidad)* del resultado va a ser siempre 50% en cada lanzamiento. \n",
    "\n",
    "### Definiendo la ley de grandes números\n",
    "\n",
    "Ahora que ya conocemos el concepto de <a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independencia</a>, estamos en condiciones de dar una definición más formal de la [ley de grandes números](https://es.wikipedia.org/wiki/Ley_de_los_grandes_n%C3%BAmeros), que junto con el [Teorema del límite central](https://es.wikipedia.org/wiki/Teorema_del_l%C3%ADmite_central), constituyen los cimientos de la [teoría de probabilidad](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_probabilidad). Podemos formular esta ley de la siguiente manera: **si se repite un [experimento aleatorio](https://es.wikipedia.org/wiki/Experimento_aleatorio), bajo las mismas condiciones, un número ilimitado de veces; y si estas repeticiones son *<a href=\"https://es.wikipedia.org/wiki/Independencia_(probabilidad)\">independientes</a>* la una de la otra, entonces la frecuencia  de veces que un evento $A$ ocurra, convergerá con [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) 1 a un número que es igual a la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de que $A$ ocurra en una sola repetición del experimento.** Lo que esta ley nos enseña, es que la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) subyacente de cualquier suceso aleatorio puede ser aprendido por medio de la experimentación, simplemente tendríamos que repetirlo una cantidad suficientemente grande de veces!. Un error que la gente suele cometer y asociar a esta ley, es la idea de que un evento tiene más posibilidades de ocurrir porque ha o no ha ocurrido recientemente. Esta idea de que las chances de un evento con una [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) fija, aumentan o disminuyen dependiendo de las ocurrencias recientes del evento, es un error que se conoce bajo el nombre de la [falacia del apostador](https://es.wikipedia.org/wiki/Falacia_del_apostador). \n",
    "\n",
    "Para entender mejor la [ley de grandes números](https://es.wikipedia.org/wiki/Ley_de_los_grandes_n%C3%BAmeros), experimentemos con algunos ejemplos en [Python](https://www.python.org/). Utilicemos nuevamente el ejemplo del lanzamiento de la moneda, en el primer ejemplo, la moneda va a tener la misma posibilidad de caer en cara o seca; mientras que en el segundo ejemplo, vamos a modificar la [probabilidad](https://es.wikipedia.org/wiki/Probabilidad) de la moneda para que caiga cara solo en 1 de 6 veces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "# Ejemplo ley de grandes números\n",
    "# moneda p=1/2 cara=1 seca=0\n",
    "resultados = []\n",
    "for lanzamientos in range(1,100000):\n",
    "    lanzamientos = np.random.choice([0,1], lanzamientos) \n",
    "    caras = lanzamientos.mean()\n",
    "    resultados.append(caras)\n",
    "\n",
    "# graficamente\n",
    "df = pd.DataFrame({ 'lanzamientos' : resultados})\n",
    "\n",
    "df.plot(title='Ley de grandes números',color='r',figsize=(8, 6))\n",
    "plt.axhline(0.5)\n",
    "plt.xlabel(\"Número de lanzamientos\")\n",
    "plt.ylabel(\"frecuencia caras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar la probabilidad de la moneda para que caiga cara solo en 1 de 6 veces.\n",
    "# moneda p=1/6 cara=1 seca=0\n",
    "resultados = []\n",
    "for lanzamientos in range(1,10000):\n",
    "    lanzamientos = np.random.choice([0,1], lanzamientos, p=[5/6, 1/6]) \n",
    "    caras = lanzamientos.mean()\n",
    "    resultados.append(caras)\n",
    "\n",
    "# graficamente\n",
    "df = pd.DataFrame({ 'lanzamientos' : resultados})\n",
    "\n",
    "df.plot(title='Ley de grandes números',color='r',figsize=(8, 6))\n",
    "plt.axhline(1/6)\n",
    "plt.xlabel(\"Número de lanzamientos\")\n",
    "plt.ylabel(\"frecuencia caras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### What's a p-value?\n",
    "\n",
    "In [statistical hypothesis testing][hypothesis_test] we have an idea that we want to test, but considering that it's very hard to prove something to be true beyond doubt, rather than test our hypothesis directly, we formulate a competing hypothesis, called a [null hypothesis][null_hypothesis], and then try to disprove it instead. The null hypothesis essentially assumes that the effect we're seeing in the data could just be due to chance. \n",
    "\n",
    "In our example, the null hypothesis assumes we have a fair coin, and the way we determine if this hypothesis is true or not is by calculating how often flipping this fair coin 30 times would result in 22 or more heads. If we then take the number of times that we got 22 or more heads and divide that number by the total of all possible permutations of 30 coin tosses, we get the probability of tossing 22 or more heads with a fair coin. This probability is what we call the [p-value][p_value]. \n",
    "\n",
    "The p-value is used to check the validity of the null hypothesis. The way this is done is by agreeing upon some predetermined upper limit for our p-value, below which we will assume that our null hypothesis is false. In other words, if our null hypothesis were true, and 22 heads in 30 flips could happen often enough by chance, we would expect to see it happen more often than the given threshold percentage of times. So, for example, if we chose 10% as our threshold, then we would expect to see 22 or more heads show up at least 10% of the time to determine that this is a chance occurrence and not due to some bias in the coin. Historically, the generally accepted threshold has been 5%, and so if our p-value is less than 5%, we can then make the assumption that our coin may not be fair.\n",
    "\n",
    "[null_hypothesis]: https://en.wikipedia.org/wiki/Null_hypothesis\n",
    "[hypothesis_test]: https://en.wikipedia.org/wiki/Statistical_hypothesis_testing\n",
    "[p_value]: https://www.statisticsdonewrong.com/data-analysis.html#the-power-of-p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an example of using the classic method for testing if our coin is fair or not. However, if you don't happen to have at least some background in statistics, it can be a little hard to follow at times, but luckily for us, there's an easier method...\n",
    "\n",
    "Simulation!\n",
    "\n",
    "The code below seeks to answer the same question of whether or not our coin is fair by running a large number of simulated coin flips and calculating the proportion of these experiments that resulted in at least 22 heads or more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiramos, en cada juego, la moneda 30 veces. Si sale más de 21 veces, sumamos uno. Repetimos el proceso n veces (50000).\n",
    "\n",
    "M = 0\n",
    "n = 50000\n",
    "for i in range(n):\n",
    "    trials = np.random.randint(2, size=30)\n",
    "    #print(trials)\n",
    "    if (trials.sum() >= 22):\n",
    "        M += 1\n",
    "p = M / n\n",
    "\n",
    "print(M)\n",
    "print(\"Simulated P-value: %0.1f%%\" % (p * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of our simulations is 0.8%, definitely looks like it's possible that we have a biased coin since the chances of seeing 22 or more heads in 30 tosses of a fair coin is less than 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    \"\"\"Calculates the factorial of `n`\n",
    "    \"\"\"\n",
    "    vals = list(range(1, n + 1))\n",
    "    if len(vals) <= 0:\n",
    "        return 1\n",
    "\n",
    "    prod = 1\n",
    "    for val in vals:\n",
    "        prod *= val\n",
    "        \n",
    "    return prod\n",
    "    \n",
    "    \n",
    "def n_choose_k(n, k):\n",
    "    \"\"\"Calculates the binomial coefficient\n",
    "    \"\"\"\n",
    "    return factorial(n) / (factorial(k) * factorial(n - k))\n",
    "\n",
    " \n",
    "def binom_prob(n, k, p):\n",
    "    \"\"\"Returns the probability of see `k` heads in `n` coin tosses\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    n - number of trials\n",
    "    k - number of trials in which an event took place\n",
    "    p - probability of an event happening\n",
    "    \n",
    "    \"\"\"\n",
    "    return n_choose_k(n, k) * p**k * (1 - p)**(n - k)\n",
    "\n",
    "def p_value(n, k, p):\n",
    "    \"\"\"Returns the p-value for the given the given set \n",
    "    \"\"\"\n",
    "    return sum(binom_prob(n, i, p) for i in range(k, n+1))\n",
    "\n",
    "print(\"P-value: %0.1f%%\" % (p_value(30, 22, 0.5) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above gives us a p-value of roughly 0.8%, which matches the value in our probability distribution above and is also less than the 5% threshold needed to reject our null hypothesis, so it does look like we may have a biased coin.\n",
    "\n",
    "The `binom_prob` function from above calculates the probability of a single event happening, so now all we need for calculating our p-value is a function that adds up the probabilities of a given event, or a more extreme event happening. So, as an example, we would need a function to add up the probabilities of getting 22 heads, 23 heads, 24 heads, and so on. The next bit of code creates that function and uses it to calculate our p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability for every possible outcome of tossing \n",
    "# a fair coin 30 times.\n",
    "probabilities = [binom_prob(30, k, 0.5) for k in range(1, 31)]\n",
    "\n",
    "# Plot the probability distribution using the probabilities list \n",
    "# we created above.\n",
    "plt.step(range(1, 31), probabilities, where='mid', color=\"blue\")\n",
    "plt.xlabel('number of heads')\n",
    "plt.ylabel('probability')\n",
    "plt.plot((22, 22), (0, 0.1599), color=\"red\");\n",
    "plt.annotate('0.8%', \n",
    "             xytext=(25, 0.08), \n",
    "             xy=(22, 0.08), \n",
    "             multialignment='right',\n",
    "             va='center',\n",
    "             color=\"red\",\n",
    "             size='large',\n",
    "             arrowprops={'arrowstyle': '<|-', \n",
    "                         'lw': 2, \n",
    "                         'color': \"red\", \n",
    "                         'shrinkA': 10});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Num. probabilidad')\n",
    "p = 1.0\n",
    "for i in range(1, 1000):\n",
    "    p = p * (366 - i) / 365\n",
    "    print ('%3d : %10.6f' % (i, 1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36464bitc2077ed07ea84d23aa5b518d224882ab",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}